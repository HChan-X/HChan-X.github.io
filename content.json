{"meta":{"title":"HCHAN","subtitle":"幸运","description":"学习与分享","author":"HCHAN","url":"http://mjean.life","root":"/"},"pages":[{"title":"关于本站","date":"2020-04-19T04:58:56.000Z","updated":"2022-04-18T12:22:24.192Z","comments":false,"path":"about/index.html","permalink":"http://mjean.life/about/index.html","excerpt":"","text":"九儿“ 看脚下，不断行，莫存顺逆 没有什么事情是不可能的，不可能的意思是 “不，可能” 。 只有一种 成功 ，那就是以自己喜欢的方式度过一生。 我们热爱这个世界时，才 真正 活在这个世界上。 联系我QQ：2698217197 座右铭：等你优秀了，你想要的都会来找你"},{"title":"分类","date":"2020-11-24T07:12:19.000Z","updated":"2021-07-26T14:44:28.785Z","comments":false,"path":"categories/index.html","permalink":"http://mjean.life/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2020-10-31T02:11:28.000Z","updated":"2021-11-23T10:50:01.880Z","comments":false,"path":"comments/index.html","permalink":"http://mjean.life/comments/index.html","excerpt":"","text":""},{"title":"archives","date":"2019-10-24T16:00:00.000Z","updated":"2021-06-27T12:40:24.587Z","comments":true,"path":"archives/index.html","permalink":"http://mjean.life/archives/index.html","excerpt":"","text":""},{"title":"留下你的想法~","date":"2020-12-12T08:24:16.000Z","updated":"2020-12-12T11:41:46.623Z","comments":true,"path":"messageboard/index.html","permalink":"http://mjean.life/messageboard/index.html","excerpt":"","text":""},{"title":"我的歌单","date":"2019-05-17T08:14:00.000Z","updated":"2021-07-26T13:06:52.537Z","comments":true,"path":"music/index.html","permalink":"http://mjean.life/music/index.html","excerpt":"","text":""},{"title":"标签","date":"2020-11-24T07:14:39.000Z","updated":"2021-07-26T14:44:42.337Z","comments":false,"path":"tags/index.html","permalink":"http://mjean.life/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2018-06-07T14:17:49.000Z","updated":"2021-07-27T07:31:10.990Z","comments":true,"path":"link/index.html","permalink":"http://mjean.life/link/index.html","excerpt":"","text":""},{"title":"相册","date":"2022-04-18T15:13:59.330Z","updated":"2022-04-18T15:13:59.330Z","comments":false,"path":"List/gallery/index.html","permalink":"http://mjean.life/List/gallery/index.html","excerpt":"","text":"壁紙 随取随用 MY CAT 關於喵喵的圖片"},{"title":"","date":"2019-08-10T08:41:10.000Z","updated":"2022-04-18T12:11:33.585Z","comments":false,"path":"List/movies/index.html","permalink":"http://mjean.life/List/movies/index.html","excerpt":"","text":"励志视频"},{"title":"Music-BBOX","date":"2020-04-23T04:58:56.000Z","updated":"2022-04-18T12:07:23.477Z","comments":false,"path":"List/music/index.html","permalink":"http://mjean.life/List/music/index.html","excerpt":"","text":""},{"title":"","date":"2021-09-28T14:56:14.000Z","updated":"2022-04-18T15:15:07.764Z","comments":false,"path":"List/gallery/mycat/index.html","permalink":"http://mjean.life/List/gallery/mycat/index.html","excerpt":"","text":""},{"title":"","date":"2021-09-28T14:56:13.000Z","updated":"2022-04-18T15:00:04.915Z","comments":false,"path":"List/gallery/wallpaper/index.html","permalink":"http://mjean.life/List/gallery/wallpaper/index.html","excerpt":"","text":""}],"posts":[{"title":"Java并发","slug":"juc","date":"2021-07-26T14:30:08.000Z","updated":"2022-04-18T12:48:45.850Z","comments":true,"path":"posts/918971b1.html","link":"","permalink":"http://mjean.life/posts/918971b1.html","excerpt":"","text":"前言本次学习是从【黑马java并发编程教程】视频中进行的。视频地址 基本概念进程与线程进程 程序由指令和数据组成，但这些指令要运行，数据要读写，就必须将指令加载至 CPU，数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程就是用来加载指令、管理内存、管理 IO 的。 当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。 进程可以看做是程序的一个实例。（也可以理解为进程是程序的执行过程，程序是静态的，进程是动态的） 线程 一个进程之内可以分为一到多个线程。 一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给 CPU 执行 。 Java 中，线程作为最小调度单位，进程作为资源分配的最小单位。 在 windows 中进程是不活动的，只是作为线程的容器 二者对比 进程基本上相互独立的，而线程存在于进程内，是进程的一个子集 进程拥有共享的资源，如内存空间等，供其内部的线程共享 进程间通信较为复杂 同一台计算机的进程通信称为 IPC（Inter-process communication） 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP 线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低 进程和线程的切换 上下文切换 内核为每一个进程维持一个上下文。上下文就是内核重新启动一个被抢占的进程所需的状态。包括以下内容： 通用目的寄存器 浮点寄存器 程序计数器 用户栈 状态寄存器 内核栈 各种内核数据结构：比如描绘地址空间的页表，包含有关当前进程信息的进程表，以及包含进程已打开文件的信息的文件表 进程切换和线程切换的主要区别 最主要的一个区别在于进程切换涉及虚拟地址空间的切换而线程不会。因为每个进程都有自己的虚拟地址空间，而线程是共享所在进程的虚拟地址空间的，因此同一个进程中的线程进行线程切换时不涉及虚拟地址空间的转换 页表查找是一个很慢的过程，因此通常使用cache来缓存常用的地址映射，这样可以加速页表查找，这个cache就是快表TLB（translation Lookaside Buffer，用来加速页表查找）。由于每个进程都有自己的虚拟地址空间，那么显然每个进程都有自己的页表，那么当进程切换后页表也要进行切换，页表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的就是程序运行会变慢，而线程切换则不会导致TLB失效，因为线程线程无需切换地址空间，因此我们通常说线程切换要比较进程切换快 而且还可能出现缺页中断，这就需要操作系统将需要的内容调入内存中，若内存已满则还需要将不用的内容调出内存，这也需要花费时间 为什么TLB能加快访问速度 快表可以避免每次都对页号进行地址的有效性判断。快表中保存了对应的物理块号，可以直接计算出物理地址，无需再进行有效性检查 并发与并行并发是一个CPU在同一时间段去不同线程中执行指令。(微观串行，宏观并行) 并行是多个CPU在同一时刻处理不同的线程。 引用 Rob Pike 的一段描述： 并发（concurrent）是同一时间应对（dealing with）多件事情的能力 并行（parallel）是同一时间动手做（doing）多件事情的能力 应用应用之异步调用（案例1）以调用方角度来讲，如果 需要等待结果返回，才能继续运行就是同步 不需要等待结果返回，就能继续运行就是异步 1) 设计多线程可以让方法执行变为异步的（即不要巴巴干等着）比如说读取磁盘文件时，假设读取操作花费了 5 秒钟，如果没有线程调度机制，这 5 秒 cpu 什么都做不了，其它代码都得暂停…2) 结论 比如在项目中，视频文件需要转换格式等操作比较费时，这时开一个新线程处理视频转换，避免阻塞主线程 tomcat 的异步 servlet 也是类似的目的，让用户线程处理耗时较长的操作，避免阻塞 tomcat 的工作线程 ui 程序中，开新线程进行其他操作，避免阻塞 ui 线程 注意：需要在多核cpu下才能提高效率，单核仍然是轮流执行 单核 cpu 下，多线程不能实际提高程序运行效率，只是为了能够在不同的任务之间切换，不同线程轮流使用 cpu ，不至于一个线程总占用 cpu，别的线程没法干活 多核 cpu 可以并行跑多个线程，但能否提高程序运行效率还是要分情况的 有些任务，经过精心设计，将任务拆分，并行执行，当然可以提高程序的运行效率。但不是所有计算任务都能拆分（参考后文的【阿姆达尔定律】） 也不是所有任务都需要拆分，任务的目的如果不同，谈拆分和效率没啥意义 IO 操作不占用 cpu，只是我们一般拷贝文件使用的是【阻塞 IO】，这时相当于线程虽然不用 cpu，但需要一 直等待 IO 结束，没能充分利用线程。所以才有后面的【非阻塞 IO】和【异步 IO】优化 Java线程创建一个线程（非主线程）方法一：直接使用 Thread 通过继承Thread类 public class CreateThread { public static void main(String[] args) { Thread myThread = new MyThread(); // 启动线程 myThread.start(); } } class MyThread extends Thread { @Override public void run() { System.out.println(\"my thread running...\"); } } 使用继承方式的好处是，在run（）方法内获取当前线程直接使用this就可以了，无须使用Thread.currentThread（）方法；不好的地方是Java不支持多继承，如果继承了Thread类，那么就不能再继承其他类。另外任务与代码没有分离，当多个线程执行一样的任务时需要多份任务代码 方法二：使用Runnable配合Thread(推荐) 把【线程】和【任务】（要执行的代码）分开 Thread 代表线程 Runnable 可运行的任务（线程要执行的代码） public class Test2 { public static void main(String[] args) { //创建线程任务 Runnable r = new Runnable() { @Override public void run() { System.out.println(\"Runnable running\"); } }; //将Runnable对象传给Thread Thread t = new Thread(r); //启动线程 t.start(); } } 或者 public class CreateThread2 { private static class MyRunnable implements Runnable { @Override public void run() { System.out.println(\"my runnable running...\"); } } public static void main(String[] args) { MyRunnable myRunnable = new MyRunnable(); Thread thread = new Thread(myRunnable); thread.start(); } } 通过实现Runnable接口，并且实现run()方法。在创建线程时作为参数传入该类的实例即可 方法二的简化：使用lambda表达式简化操作 Java 8 以后可以使用 lambda 精简代码 当一个接口带有@FunctionalInterface注解时，是可以使用lambda来简化操作的 所以方法二中的代码可以被简化为 public class Test2 { public static void main(String[] args) { //创建线程任务 Runnable r = () -&gt; { //直接写方法体即可 System.out.println(\"Runnable running\"); System.out.println(\"Hello Thread\"); }; //将Runnable对象传给Thread Thread t = new Thread(r); //启动线程 t.start(); } } 原理之 Thread 与 Runnable 的关系分析 Thread 的源码，理清它与 Runnable 的关系 小结 方法1 是把线程和任务合并在了一起，方法2 是把线程和任务分开了 用 Runnable 更容易与线程池等高级 API 配合 用 Runnable 让任务类脱离了 Thread 继承体系，更灵活 方法三：使用FutureTask与Thread结合 FutureTask 能够接收 Callable 类型的参数，用来处理有返回结果的情况 使用FutureTask可以用泛型指定线程的返回值类型（Runnable的run方法没有返回值） public class Test3 { public static void main(String[] args) throws ExecutionException, InterruptedException { //需要传入一个Callable对象 FutureTask&lt;Integer&gt; task = new FutureTask&lt;Integer&gt;(new Callable&lt;Integer&gt;() { @Override public Integer call() throws Exception { System.out.println(\"线程执行!\"); Thread.sleep(1000); return 100; } }); Thread r1 = new Thread(task, \"t2\"); r1.start(); //获取线程中方法执行后的返回结果 System.out.println(task.get()); } } 或 public class UseFutureTask { public static void main(String[] args) throws ExecutionException, InterruptedException { FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(new MyCall()); Thread thread = new Thread(futureTask); thread.start(); // 获得线程运行后的返回值 System.out.println(futureTask.get()); } } class MyCall implements Callable&lt;String&gt; { @Override public String call() throws Exception { return \"hello world\"; } } 总结使用继承方式的好处是方便传参，可以在子类里面添加成员变量，通过set方法设置参数或者通过构造函数进行传递，而如果使用Runnable方式，则只能使用主线程里面被声明为final的变量。不好的地方是Java不支持多继承，如果继承了Thread类，那么子类不能再继承其他类，而Runable则没有这个限制。前两种方式都没办法拿到任务的返回结果，但是Futuretask方式可以 原理之线程运行栈与栈帧 Java Virtual Machine Stacks （Java 虚拟机栈） 我们都知道 JVM 中由堆、栈、方法区所组成，其中栈内存是给谁用的呢？ 其实就是线程，每个线程启动后，虚拟机就会为其分配一块栈内存 每个栈由多个栈帧（Frame）组成，对应着每次方法调用时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的那个方法 线程上下文切换（Thread Context Switch）因为以下一些原因导致 cpu 不再执行当前的线程，转而执行另一个线程的代码 线程的 cpu 时间片用完 垃圾回收 有更高优先级的线程需要运行 线程自己调用了 sleep、yield、wait、join、park、synchronized、lock 等方法 当 Context Switch 发生时，需要由操作系统保存当前线程的状态，并恢复另一个线程的状态，Java 中对应的概念就是程序计数器（Program Counter Register），它的作用是记住下一条 jvm 指令的执行地址，是线程私有的 状态包括程序计数器、虚拟机栈中每个栈帧的信息，如局部变量、操作数栈、返回地址等 Context Switch 频繁发生会影响性能 常用方法 方法名 static 功能说明 注意 start() 启动一个新线 程，在新的线程运行 run 方法 中的代码 start 方法只是让线程进入就绪，里面代码不一定立刻运行（CPU 的时间片还没分给它）。每个线程对象的 start方法只能调用一次，如果调用了多次会出现 IllegalThreadStateException run() 新线程启动后会调用的方法 如果在构造 Thread 对象时传递了 Runnable 参数，则 线程启动后会调用 Runnable 中的 run 方法，否则默认不执行任何操作。但可以创建 Thread 的子类对象， 来覆盖默认行为 join() 等待线程运行结束 join(long n) 等待线程运行结束,最多等待 n 毫秒 getId() 获取线程长整型的 id id 唯一 getName() 获取线程名 setName(String) 修改线程名 getPriority() 获取线程优先级 setPriority(int) 修改线程优先级 java中规定线程优先级是1~10 的整数，较大的优先级能提高该线程被 CPU 调度的机率 getState() 获取线程状态 Java 中线程状态是用 6 个 enum 表示，分别为： NEW, RUNNABLE, BLOCKED, WAITING, TIMED_WAITING, TERMINATED isInterrupted() 判断是否被打断， 不会清除 打断标记 isAlive() 线程是否存活 （还没有运行完毕） interrupt() 打断线程 如果被打断线程正在 sleep，wait，join 会导致被打断的线程抛出 InterruptedException，并清除 打断标记 ；如果打断的正在运行的线程，则会设置 打断标记 ；park 的线程被打断，也会设置 打断标记 interrupted() static 判断当前线程是否被打断 会清除 打断标记 currentThread() static 获取当前正在执行的线程 sleep(long n) static 让当前执行的线程休眠n毫秒， 休眠时让出 cpu 的时间片给其它线程 yield() static 提示线程调度器让出当前线程对 CPU的使用 主要是为了测试和调试 start() vs run()被创建的Thread对象直接调用重写的run方法时， run方法是在主线程中被执行的，而不是在我们所创建的线程中执行。所以如果想要在所创建的线程中执行run方法，需要使用Thread对象的start方法。 sleep()与yield()sleep (使线程阻塞) 调用 sleep 会让当前线程从 Running 进入 Timed Waiting 状态（阻塞），可通过state()方法查看 其它线程可以使用 interrupt 方法打断正在睡眠的线程，这时 sleep 方法会抛出 InterruptedException 睡眠结束后的线程未必会立刻得到执行 建议用 TimeUnit 的 sleep 代替 Thread 的 sleep 来获得更好的可读性 。如： //休眠一秒 TimeUnit.SECONDS.sleep(1); //休眠一分钟 TimeUnit.MINUTES.sleep(1); yield （让出当前线程） 调用 yield 会让当前线程从 Running 进入 Runnable 就绪状态（仍然有可能被执行），然后调度执行其它线程 具体的实现依赖于操作系统的任务调度器 线程优先级 线程优先级会提示（hint）调度器优先调度该线程，但它仅仅是一个提示，调度器可以忽略它 如果 cpu 比较忙，那么优先级高的线程会获得更多的时间片，但 cpu 闲时，优先级几乎没作用 设置方法： thread1.setPriority(Thread.MAX_PRIORITY); //设置为优先级最高 join()方法用于等待某个线程结束。哪个线程内调用join()方法，就等待哪个线程结束，然后再去执行其他线程。 如在主线程中调用ti.join()，则是主线程等待t1线程结束 Thread thread = new Thread(); //等待thread线程执行结束 thread.join(); //最多等待1000ms,如果1000ms内线程执行完毕，则会直接执行下面的语句，不会等够1000ms thread.join(1000); interrupt()方法 处于阻塞状态的线程，CPU不会给其分配时间片 如果用于打断阻塞**(sleep wait join…)**的线程。 如果一个线程在运行中被打断，打断标记会被置为true，不会清空打断状态 如果是打断因sleep wait join方法而被阻塞的线程，会清空打断状态，会将打断标记置为false //用于查看打断标记，返回值被boolean类型 t1.isInterrupted(); 正常运行的线程在被打断后，不会停止，会继续执行。如果要让线程在被打断后停下来，需要使用打断标记来判断。 while(true) { if(Thread.currentThread().isInterrupted()) { break; } } 两阶段终止模式 当我们在执行线程一时，想要终止线程二，这时就需要使用interrupt方法来优雅的停止线程二。 代码 public class Test7 { public static void main(String[] args) throws InterruptedException { Monitor monitor = new Monitor(); monitor.start(); Thread.sleep(3500); monitor.stop(); } } class Monitor { Thread monitor; /** * 启动监控器线程 */ public void start() { //设置线控器线程，用于监控线程状态 monitor = new Thread() { @Override public void run() { //开始不停的监控 while (true) { //判断当前线程是否被打断了 if(Thread.currentThread().isInterrupted()) { System.out.println(\"处理后续任务\"); //终止线程执行 break; } System.out.println(\"监控器运行中...\"); try { //线程休眠 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); //如果是在休眠的时候被打断，不会将打断标记设置为true，这时要重新设置打断标记 Thread.currentThread().interrupt(); } } } }; monitor.start(); } /** * 用于停止监控器线程 */ public void stop() { //打断线程 monitor.interrupt(); } } 打断 park 线程 打断 park 线程, 不会清空打断状态，如果打断标记已经是 true, 则 park 会失效 提示：可以使用 Thread.interrupted() 清除打断状态 不推荐使用的打断方法 方法名 static 功能说明 stop() 停止线程运行 suspend() 挂起（暂停）线程运行 resume() 恢复线程运行 这些方法已过时，容易破坏同步代码块，造成线程死锁 stop方法 停止线程运行（可能造成共享资源无法被释放，其他线程无法使用这些共享资源） suspend（暂停线程）/resume（恢复线程）方法 守护线程当JAVA进程中有多个线程在执行时，只有当所有非守护线程都执行完毕后，JAVA进程才会结束。但当非守护线程全部执行完毕后，守护线程无论是否执行完毕，也会一同结束。 //将线程设置为守护线程, 默认为false monitor.setDaemon(true); 注意 垃圾回收器线程就是一种守护线程 Tomcat 中的 Acceptor 和 Poller 线程都是守护线程，所以 Tomcat 接收到 shutdown 命令后，不会等待它们处理完当前请求 线程的状态五种状态这是从 操作系统 层面来描述的 【初始状态】仅是在语言层面创建了线程对象，还未与操作系统线程关联（例如线程调用了start方法） 【可运行状态】（就绪状态）指该线程已经被创建（与操作系统线程关联），可以由 CPU 调度执行 【运行状态】指获取了 CPU 时间片运行中的状态 当 CPU 时间片用完，会从【运行状态】转换至【可运行状态】，会导致线程的上下文切换 【阻塞状态】 如果调用了阻塞 API，如 BIO 读写文件，这时该线程实际不会用到 CPU，会导致线程上下文切换，进入 【阻塞状态】 等 BIO 操作完毕，会由操作系统唤醒阻塞的线程，转换至【可运行状态】 与【可运行状态】的区别是，对【阻塞状态】的线程来说只要它们一直不唤醒，调度器就一直不会考虑调度它们 【终止状态】表示线程已经执行完毕，生命周期已经结束，不会再转换为其它状态 六种状态这是从 Java API 层面来描述的根据 Thread.State 枚举，分为六种状态 NEW 线程刚被创建，但是还没有调用 start() 方法 RUNNABLE 当调用了 start() 方法之后，注意，Java API 层面的 RUNNABLE 状态涵盖了操作系统层面的 【可运行状态】、【运行状态】和【阻塞状态】（由于 BIO 导致的线程阻塞，在 Java 里无法区分，仍然认为 是可运行） BLOCKED ， WAITING ， TIMED_WAITING 都是 Java API 层面对【阻塞状态】的细分，如sleep就为TIMED_WAITING， join为WAITING状态。后面会在状态转换一节详述。 TERMINATED 当线程代码运行结束 共享模型之管程共享带来的问题临界区 Critical Section 一个程序运行多个线程本身是没有问题的 问题出在多个线程访问共享资源 多个线程读共享资源其实也没有问题 在多个线程对共享资源读写操作时发生指令交错，就会出现问题 一段代码块内如果存在对共享资源的多线程读写操作，称这段代码块为临界区 例如，下面代码中的临界区 static int counter = 0; static void increment() // 临界区 { counter++; } static void decrement() // 临界区 { counter--; } 竞态条件 Race Condition多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测，称之为发生了竞态条件 synchronized 解决方案解决手段为了避免临界区的竞态条件发生，有多种手段可以达到目的。 阻塞式的解决方案：synchronized，Lock 非阻塞式的解决方案：原子变量 本次课使用阻塞式的解决方案：synchronized，来解决上述问题，即俗称的【对象锁】，它采用互斥的方式让同一时刻至多只有一个线程能持有【对象锁】，其它线程再想获取这个【对象锁】时就会阻塞住(blocked)。这样就能保证拥有锁的线程可以安全的执行临界区内的代码，不用担心线程上下文切换 注意 虽然 java 中互斥和同步都可以采用 synchronized 关键字来完成，但它们还是有区别的： 互斥是保证临界区的竞态条件发生，同一时刻只能有一个线程执行临界区代码 同步是由于线程执行的先后、顺序不同、需要一个线程等待其它线程运行到某个点 synchronized语法synchronized(对象) { //临界区 } 解决 static int counter = 0; //创建一个公共对象，作为对象锁的对象 static final Object room = new Object(); public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { for (int i = 0; i &lt; 5000; i++) { synchronized (room) { counter++; } } }, \"t1\"); Thread t2 = new Thread(() -&gt; { for (int i = 0; i &lt; 5000; i++) { synchronized (room) { counter--; } } }, \"t2\"); t1.start(); t2.start(); t1.join(); t2.join(); log.debug(\"{}\",counter); } synchronized 实际是用对象锁保证了临界区内代码的原子性，临界区内的代码对外是不可分割的，不会被线程切换所打断 synchronized加在方法上 加在成员方法上 public class Demo { //在方法上加上synchronized关键字 public synchronized void test() { } //等价于 public void test() { synchronized(this) { } } } 加在静态方法上 public class Demo { //在静态方法上加上synchronized关键字 public synchronized static void test() { } //等价于 public void test() { synchronized(Demo.class) { } } } 变量的线程安全分析成员变量和静态变量是否线程安全？ 如果它们没有共享，则线程安全 如果它们被共享了，根据它们的状态是否能够改变，又分两种情况 如果只有读操作，则线程安全 如果有读写操作，则这段代码是临界区，需要考虑线程安全 局部变量是否线程安全？ 局部变量是线程安全的 但局部变量引用的对象则未必 （要看该对象是否被共享且被执行了读写操作） 如果该对象没有逃离方法的作用范围，它是线程安全的 如果该对象逃离方法的作用范围，需要考虑线程安全 局部变量是线程安全的——每个方法都在对应线程的栈中创建栈帧，不会被其他线程共享 如果调用的对象被共享，且执行了读写操作，则线程不安全 如果是局部变量，则会在堆中创建对应的对象，不会存在线程安全问题。 常见线程安全类 String Integer StringBuﬀer Random Vector （List的线程安全实现类） Hashtable （Hash的线程安全实现类） java.util.concurrent 包下的类 这里说它们是线程安全的是指，多个线程调用它们同一个实例的某个方法时，是线程安全的。例如： Hashtable table = new Hashtable(); new Thread(()-&gt;{ table.put(\"key\", \"value1\"); }).start(); new Thread(()-&gt;{ table.put(\"key\", \"value2\"); }).start(); 它们的每个方法是原子的（都被加上了synchronized） 但注意它们多个方法的组合不是原子的，所以可能会出现线程安全问题 线程安全类方法的组合 分析下面代码是否线程安全？ Hashtable table = new Hashtable(); // 线程1，线程2 if( table.get(\"key\") == null) { table.put(\"key\", value); } 不可变类线程安全性String、Integer 等都是不可变类，因为其内部的状态不可以改变，因此它们的方法都是线程安全的 有同学或许有疑问，String 有 replace，substring 等方法【可以】改变值啊，那么这些方法又是如何保证线程安全的呢？ 这是因为这些方法的返回值都创建了一个新的对象，而不是直接改变String、Integer对象本身 Monitor概念Java对象头 [参考链接](jvm - What is in Java object header? - Stack Overflow) 原理之 MonitorMonitor 被翻译为监视器或管程 每个 Java 对象都可以关联一个 Monitor 对象，如果使用 synchronized 给对象上锁（重量级）之后，该对象头的 Mark Word 中就被设置指向 Monitor 对象的指针 Monitor 结构如下 刚开始 Monitor 中 Owner 为 null 当 Thread-2 执行 synchronized(obj) 就会将 Monitor 的所有者 Owner 置为 Thread-2，Monitor中只能有一 个 Owner 在 Thread-2 上锁的过程中，如果 Thread-3，Thread-4，Thread-5 也来执行 synchronized(obj)，就会进入 EntryList BLOCKED Thread-2 执行完同步代码块的内容，然后唤醒 EntryList 中等待的线程来竞争锁，竞争的时是非公平的 图中 WaitSet 中的 Thread-0，Thread-1 是之前获得过锁，但条件不满足进入 WAITING 状态的线程，后面讲 wait-notify 时会分析 当线程执行到临界区代码时，如果使用了synchronized，会先查询synchronized中所指定的对象(obj)是否绑定了Monitor。 如果没有绑定，则会先去与Monitor绑定，并且将Owner设为当前线程。 如果已经绑定，则会去查询该Monitor是否已经有了Owner 如果没有，则Owner与将当前线程绑定 如果有，则放入EntryList，进入阻塞状态(blocked) 当Monitor的Owner将临界区中代码执行完毕后，Owner便会被清空，此时EntryList中处于阻塞状态的线程会被叫醒并竞争，此时的竞争是非公平的 注意： 对象在使用了synchronized后与Monitor绑定时，会将对象头中的Mark Word置为Monitor指针。 每个对象都会绑定一个唯一的Monitor，如果synchronized中所指定的对象(obj)不同，则会绑定不同的Monitor 原理之 Synchronized进阶 64 位虚拟机 Mark Word 轻量级锁（用于优化Monitor这类的重量级锁）轻量级锁使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（也就是没有竞争），那么可以使用轻量级锁来优化。 假设有两个方法同步块，利用同一个对象加锁 static final Object obj = new Object(); public static void method1() { synchronized( obj ) { // 同步块 A method2(); } } public static void method2() { synchronized( obj ) { // 同步块 B } } 创建锁记录（Lock Record）对象，每个线程的栈帧都会包含一个锁记录对象，内部可以存储锁定对象的Mark Word 让锁记录中的Object reference指向锁对象（Object），并尝试用cas去替换Object中的Mark Word，将Mark Word的值存入锁记录 如果cas替换成功，则将Object的对象头替换为锁记录的地址和状态 00（轻量级锁状态），并由该线程给对象加锁 如果 cas 失败，有两种情况 如果是其它线程已经持有了该 Object 的轻量级锁，这时表明有竞争，进入锁膨胀过程 如果是自己执行了 synchronized 锁重入，那么再添加一条 Lock Record 作为重入的计数 当退出 synchronized 代码块（解锁时）如果有取值为 null 的锁记录，表示有重入，这时重置锁记录，表示重入计数减一 当退出 synchronized 代码块（解锁时）锁记录的值不为 null，这时使用 cas 将 Mark Word 的值恢复给对象头 成功，则解锁成功 失败，说明轻量级锁进行了锁膨胀或已经升级为重量级锁，进入重量级锁解锁流程 锁膨胀如果在尝试加轻量级锁的过程中，CAS 操作无法成功，这时一种情况就是有其它线程为此对象加上了轻量级锁（有竞争），这时需要进行锁膨胀，将轻量级锁变为重量级锁 static Object obj = new Object(); public static void method1() { synchronized( obj ) { // 同步块 } } 当 Thread-1 进行轻量级加锁时，Thread-0 已经对该对象加了轻量级锁 这时 Thread-1 加轻量级锁失败，进入锁膨胀流程 即为 Object 对象申请 Monitor 锁，让 Object 指向重量级锁地址 将对象头的Mark Word改为Monitor的地址，并且状态改为01(重量级锁) 并且线程进入Monitor 的 EntryList中，并进入阻塞状态(BLOCKED) 当 Thread-0 退出同步块解锁时，使用 cas 将 Mark Word 的值恢复给对象头，失败。这时会进入重量级解锁流程，即按照 Monitor 地址找到 Monitor 对象，设置 Owner 为 null，唤醒 EntryList 中 BLOCKED 线程 自旋优化重量级锁竞争时，还可以使用自旋来进行优化，如果当前线程自旋成功（即使用锁的线程退出了同步块，释放了锁），这时就可以避免线程进入阻塞状态。 自旋重试成功的情况 线程 1 （core 1 上） 对象 Mark 线程 2 （core 2 上） - 10（重量锁） - 访问同步块，获取 monitor 10（重量锁）重量锁指针 - 成功（加锁） 10（重量锁）重量锁指针 - 执行同步块 10（重量锁）重量锁指针 - 执行同步块 10（重量锁）重量锁指针 访问同步块，获取 monitor 执行同步块 10（重量锁）重量锁指针 自旋重试 执行完毕 10（重量锁）重量锁指针 自旋重试 成功（解锁） 自旋重试 - 10（重量锁）重量锁指针 成功（加锁） - 10（重量锁）重量锁指针 执行同步块 - … … 自旋重试失败的情况 线程 1（core 1 上） 对象 Mark 线程 2（core 2 上） - 10（重量锁） - 访问同步块，获取 monitor 10（重量锁）重量锁指针 - 成功（加锁） 10（重量锁）重量锁指针 - 执行同步块 10（重量锁）重量锁指针 - 执行同步块 10（重量锁）重量锁指针 访问同步块，获取 monitor 执行同步块 10（重量锁）重量锁指针 自旋重试 执行同步块 10（重量锁）重量锁指针 自旋重试 执行同步块 10（重量锁）重量锁指针 自旋重试 执行同步块 10（重量锁）重量锁指针 阻塞 - … … 自旋会占用 CPU 时间，单核 CPU 自旋就是浪费，多核 CPU 自旋才能发挥优势 在 Java 6 之后自旋锁是自适应的，比如对象刚刚的一次自旋操作成功过，那么认为这次自旋成功的可能性会高，就多自旋几次；反之，就少自旋甚至不自旋，总之，比较智能 Java 7 之后不能控制是否开启自旋功能 偏向锁(用于优化轻量级锁重入)轻量级锁在没有竞争时，每次重入（该线程执行的方法中再次锁住该对象）操作仍需要CAS操作，这样会使性能降低的。 Java 6中引入了偏向锁进行进一步的优化：只有第一次CAS时会将线程的ID写入对象的Mark Word中，此后发现这个线程ID就是自己的，就表示没有竞争，就不需要重新CAS，以后只要不发生竞争，这个对象就归该线程所有 偏向状态 Normal：一般状态，没有加任何锁，前面62位保存的是对象的信息，最后2位为状态（01），倒数第三位表示是否使用偏向锁（未使用：0） Biased：偏向状态，使用偏向锁，前面54位保存的当前线程的ID，最后2位为状态（01），倒数第三位表示是否使用偏向锁（使用：1） Lightweight：使用轻量级锁，前62位保存的是锁记录的指针，最后两位为状态（00） Heavyweight：使用重量级锁，前62位保存的是Monitor的地址指针，后两位为状态(10) 一个对象创建时： 如果开启了偏向锁（默认开启），在创建对象时，对象的Mark Word后三位应该是101 但是偏向锁默认是有延迟的，不会在程序一启动时就立即生效，而是会在程序运行一段时间（几秒之后）才会生效，如果想避免延迟，可以加 VM 参数 - XX:BiasedLockingStartupDelay=0 来禁用延迟 如果没有开启偏向锁，对象的Mark Word后三位应该是001 注意 处于偏向锁的对象解锁后，线程 id 仍存储于对象头中 撤销偏向状态以下几种情况会使对象的偏向锁失效 调用对象的hashCode方法，但偏向锁的对象 MarkWord 中存储的是线程 id，如果调用 hashCode 会导致偏向锁被撤销 轻量级锁会在锁记录中记录 hashCode 重量级锁会在 Monitor 中记录 hashCode 多个线程使用该对象，会将偏向锁升级为轻量级锁 调用了wait/notify方法（调用wait方法会导致锁膨胀而使用重量级锁） 批量重偏向 如果对象虽然被多个线程访问，但是线程间不存在竞争，这时偏向了线程T1的对象仍有机会重新偏向T2，重偏向会重置Thread ID 当撤销超过20次后（超过阈值），JVM会觉得是不是偏向错了，这时会在给对象加锁时，重新偏向至加锁线程。 批量撤销当撤销偏向锁的阈值超过40以后，就会将整个类的对象都改为不可偏向的 wait notify 原理 锁对象调用wait方法（obj.wait），就会使当前线程进入WaitSet中，变为WAITING状态。 处于BLOCKED和WAITING状态的线程都为阻塞状态，CPU都不会分给他们时间片。但是有所区别： BLOCKED状态的线程是在竞争对象时，发现Monitor的Owner已经是别的线程了，此时就会进入EntryList中，并处于BLOCKED状态 WAITING状态的线程是获得了对象的锁，但是自身因为某些原因需要进入阻塞状态时，锁对象调用了wait方法而进入了WaitSet中，处于WAITING状态 BLOCKED状态的线程会在锁被释放的时候被唤醒，但是处于WAITING状态的线程只有被锁对象调用了notify方法(obj.notify/obj.notifyAll)，才会被唤醒，但唤醒后并不意味者立刻获得锁，仍需进入 EntryList 重新竞争 注：只有当对象被锁以后，才能调用wait和notify方法 public class Test1 { final static Object LOCK = new Object(); public static void main(String[] args) throws InterruptedException { //只有在对象被锁住后才能调用wait方法 synchronized (LOCK) { LOCK.wait(); } } } Wait与Sleep的区别不同点 Sleep是Thread类的静态方法，Wait是Object的方法，Object又是所有类的父类，所以所有类都有Wait方法。 Sleep在阻塞的时候不会释放锁，而Wait在阻塞的时候会释放锁 Sleep不需要与synchronized一起使用，而Wait需要与synchronized一起使用（对象被锁以后才能使用） 相同点 阻塞状态都为TIMED_WAITING 优雅地使用wait/notify什么时候适合使用wait 当线程不满足某些条件，需要暂停运行时，可以使用wait。这样会将对象的锁释放，让其他线程能够继续运行。如果此时使用sleep，会导致所有线程都进入阻塞，导致所有线程都没法运行，直到当前线程sleep结束后，运行完毕，才能得到执行。 使用wait/notify需要注意什么 当有多个线程在运行时，对象都调用了wait方法，此时这些线程都会进入WaitSet中等待。如果这时使用了notify方法，可能会造成虚假唤醒（唤醒的不是满足条件的等待线程），这时就需要使用notifyAll方法 synchronized (LOCK) { while(//不满足条件，一直等待，避免虚假唤醒) { LOCK.wait(); } //满足条件后再运行 } synchronized (LOCK) { //唤醒所有等待线程 LOCK.notifyAll(); } 同步模式之保护性暂停定义即 Guarded Suspension，用在一个线程等待另一个线程的执行结果 要点 有一个结果需要从一个线程传递到另一个线程，让他们关联同一个 GuardedObject 如果有结果不断从一个线程到另一个线程那么可以使用消息队列（见生产者/消费者） JDK 中，join 的实现、Future 的实现，采用的就是此模式 因为要等待另一方的结果，因此归类到同步模式 举例public class Test2 { public static void main(String[] args) { String hello = \"hello thread!\"; Guarded guarded = new Guarded(); new Thread(()-&gt;{ System.out.println(\"想要得到结果\"); synchronized (guarded) { System.out.println(\"结果是：\"+guarded.getResponse()); } System.out.println(\"得到结果\"); }).start(); new Thread(()-&gt;{ System.out.println(\"设置结果\"); synchronized (guarded) { guarded.setResponse(hello); } }).start(); } } class Guarded { /** * 要返回的结果 */ private Object response; //优雅地使用wait/notify public Object getResponse() { //如果返回结果为空就一直等待，避免虚假唤醒 while(response == null) { synchronized (this) { try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } return response; } public void setResponse(Object response) { this.response = response; synchronized (this) { //唤醒休眠的线程 this.notifyAll(); } } @Override public String toString() { return \"Guarded{\" + \"response=\" + response + '}'; } } 带超时判断的暂停 public Object getResponse(long time) { synchronized (this) { //获取开始时间 long currentTime = System.currentTimeMillis(); //用于保存已经等待了的时间 long passedTime = 0; while(response == null) { //看经过的时间-开始时间是否超过了指定时间 long waitTime = time -passedTime; if(waitTime &lt;= 0) { break; } try { //等待剩余时间 this.wait(waitTime); } catch (InterruptedException e) { e.printStackTrace(); } //获取当前时间 passedTime = System.currentTimeMillis()-currentTime } } return response; } 原理之 join—使用保护性暂停模式public final synchronized void join(long millis) throws InterruptedException { long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) { throw new IllegalArgumentException(\"timeout value is negative\"); } if (millis == 0) { while (isAlive()) { wait(0); } } else { while (isAlive()) { long delay = millis - now; if (delay &lt;= 0) { break; } wait(delay); now = System.currentTimeMillis() - base; } } } park/unpark基本使用park/unpark都是LockSupport类中的的方法 // 暂停当前线程 LockSupport.park(); // 恢复某个线程的运行 LockSupport.unpark(暂停线程对象) 例如： //暂停线程运行 LockSupport.park; //恢复线程运行 LockSupport.unpark(thread); public static void main(String[] args) throws InterruptedException { Thread thread = new Thread(()-&gt; { System.out.println(\"park\"); //暂停线程运行 LockSupport.park(); System.out.println(\"resume\"); }, \"t1\"); thread.start(); Thread.sleep(1000); System.out.println(\"unpark\"); //恢复线程运行 LockSupport.unpark(thread); } 特点与wait/notify的区别 wait，notify 和 notifyAll 必须配合Object Monitor一起使用，而park，unpark不必 park ，unpark 是以线程为单位来阻塞和唤醒线程，而 notify 只能随机唤醒一个等待线程，notifyAll 是唤醒所有等待线程，就不那么精确 park &amp; unpark 可以先 unpark，而 wait &amp; notify 不能先 notify park不会释放锁，而wait会释放锁 原理每个线程都有一个自己的Park对象，并且该对象_counter, _cond,__mutex组成 先调用park再调用unpark时 先调用park 线程运行时，会将Park对象中的_counter的值设为0； 调用park时，会先查看counter的值是否为0，如果为0，则将线程放入阻塞队列cond中 放入阻塞队列中后，会再次将counter设置为0 然后调用unpark 调用unpark方法后，会将counter的值设置为1 去唤醒阻塞队列cond中的线程 线程继续运行并将counter的值设为0 先调用unpark，再调用park 调用unpark 会将counter设置为1（运行时0） 调用park方法 查看counter是否为0 因为unpark已经把counter设置为1，所以此时将counter设置为0，但不放入阻塞队列cond中 线程中的状态转换 情况一：NEW –&gt; RUNNABLE 当调用了t.start()方法时，由 NEW –&gt; RUNNABLE 情况二： RUNNABLE &lt;–&gt; WAITING 当调用了t 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait() 方法时，t 线程从 RUNNABLE –&gt; WAITING 调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时 竞争锁成功，t 线程从 WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 WAITING –&gt; BLOCKED 情况三：RUNNABLE &lt;–&gt; WAITING 当前线程 调用 t.join() 方法时，当前线程从 RUNNABLE –&gt; WAITING 注意是当前线程在t 线程对象的监视器上等待 t 线程运行结束，或调用了当前线程的 interrupt() 时，当前线程从 WAITING –&gt; RUNNABLE 情况四： RUNNABLE &lt;–&gt; WAITING 当前线程调用 LockSupport.park() 方法会让当前线程从 RUNNABLE –&gt; WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，会让目标线程从 WAITING –&gt; RUNNABLE 情况五： RUNNABLE &lt;–&gt; TIMED_WAITINGt 线程用 synchronized(obj) 获取了对象锁后 调用 obj.wait(long n) 方法时，t 线程从 RUNNABLE –&gt; TIMED_WAITING t 线程等待时间超过了 n 毫秒，或调用 obj.notify() ， obj.notifyAll() ， t.interrupt() 时 竞争锁成功，t 线程从 TIMED_WAITING –&gt; RUNNABLE 竞争锁失败，t 线程从 TIMED_WAITING –&gt; BLOCKED 情况六：RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 t.join(long n) 方法时，当前线程从 RUNNABLE –&gt; TIMED_WAITING 注意是当前线程在t 线程对象的监视器上等待 当前线程等待时间超过了 n 毫秒，或t 线程运行结束，或调用了当前线程的 interrupt() 时，当前线程从 TIMED_WAITING –&gt; RUNNABLE 情况七：RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 Thread.sleep(long n) ，当前线程从 RUNNABLE –&gt; TIMED_WAITING 当前线程等待时间超过了 n 毫秒，当前线程从 TIMED_WAITING –&gt; RUNNABLE 情况八：RUNNABLE &lt;–&gt; TIMED_WAITING 当前线程调用 LockSupport.parkNanos(long nanos) 或 LockSupport.parkUntil(long millis) 时，当前线 程从 RUNNABLE –&gt; TIMED_WAITING 调用 LockSupport.unpark(目标线程) 或调用了线程 的 interrupt() ，或是等待超时，会让目标线程从 TIMED_WAITING–&gt; RUNNABLE 情况九：RUNNABLE &lt;–&gt; BLOCKED t 线程用 synchronized(obj) 获取了对象锁时如果竞争失败，从 RUNNABLE –&gt; BLOCKED 持 obj 锁线程的同步代码块执行完毕，会唤醒该对象上所有 BLOCKED 的线程重新竞争，如果其中 t 线程竞争 成功，从 BLOCKED –&gt; RUNNABLE ，其它失败的线程仍然 BLOCKED 情况十： RUNNABLE &lt;–&gt; TERMINATED当前线程所有代码运行完毕，进入 TERMINATED 多把锁将锁的粒度细分 class BigRoom { //额外创建对象来作为锁 private final Object studyRoom = new Object(); private final Object bedRoom = new Object(); } 活跃性定义因为某种原因，使得代码一直无法执行完毕，这样的现象叫做活跃性 死锁有这样的情况：一个线程需要同时获取多把锁，这时就容易发生死锁 如：t1 线程 获得 A对象锁，接下来想获取 B对象 的锁， t2 线程 获得 B对象 锁，接下来想获取 A对象 的锁 public static void main(String[] args) { final Object A = new Object(); final Object B = new Object(); new Thread(()-&gt;{ synchronized (A) { try { Thread.sleep(2000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (B) { } } }).start(); new Thread(()-&gt;{ synchronized (B) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } synchronized (A) { } } }).start(); } 发生死锁的必要条件 互斥条件 在一段时间内，一种资源只能被一个进程所使用 请求和保持条件 进程已经拥有了至少一种资源，同时又去申请其他资源。因为其他资源被别的进程所使用，该进程进入阻塞状态，并且不释放自己已有的资源 不可抢占条件 进程对已获得的资源在未使用完成前不能被强占，只能在进程使用完后自己释放 循环等待条件 发生死锁时，必然存在一个进程——资源的循环链。 定位死锁的方法 jps+jstack ThreadID 在JAVA控制台中的Terminal中输入jps指令可以查看运行中的线程ID，使用jstack ThreadID可以查看线程状态。 E:\\study&gt;jps 20672 RemoteMavenServer36 22880 Jps 4432 Launcher 5321 Test5 20184 KotlinCompileDaemon 11132 F:\\study&gt;jstack 5321 打印的结果 //找到一个java级别的死锁 Found one Java-level deadlock: ============================= \"Thread-1\": waiting to lock monitor 0x0000000017f40de8 (object 0x00000000d6188880, a java.lang.Object), which is held by \"Thread-0\" \"Thread-0\": waiting to lock monitor 0x0000000017f43678 (object 0x00000000d6188890, a java.lang.Object), which is held by \"Thread-1\" jconsole检测死锁，即可看到有没有死锁存在 哲学家就餐问题 有五位哲学家，围坐在圆桌旁 他们只做两件事，思考和吃饭，思考一会吃口饭，吃完饭后接着思考 吃饭时要用两根筷子吃，桌上共有 5 根筷子，每位哲学家左右手边各有一根筷子 如果筷子被身边的人拿着，自己就得等待 避免死锁的方法在线程使用锁对象时，顺序加锁即可避免死锁 活锁活锁出现在两个线程互相改变对方的结束条件，后谁也无法结束。 避免活锁的方法在线程执行时，中途给予不同的间隔时间即可。 死锁与活锁的区别 死锁是因为线程互相持有对象想要的锁，并且都不释放，最后到时线程阻塞，停止运行的现象。 活锁是因为线程间修改了对方的结束条件，而导致代码一直在运行，却一直运行不完的现象。 饥饿某些线程因为优先级太低，导致一直无法获得资源的现象。 在使用顺序加锁时，可能会出现饥饿现象 ReentrantLock 和synchronized相比具有的的特点 可中断 可以设置超时时间 可以设置为公平锁 (先到先得) 支持多个条件变量( 具有多个waitset) 与 synchronized 一样，都支持可重入 基本语法 //获取ReentrantLock对象 private ReentrantLock lock = new ReentrantLock(); //加锁 lock.lock(); try { //需要执行的代码 }finally { //释放锁 lock.unlock(); } 可重入 可重入是指同一个线程如果首次获得了这把锁，那么因为它是这把锁的拥有者，因此有权利再次获取这把锁 如果是不可重入锁，那么第二次获得锁时，自己也会被锁挡住 可打断如果某个线程处于阻塞状态，可以调用其interrupt方法让其停止阻塞，获得锁失败 简而言之就是：处于阻塞状态的线程，被打断了就不用阻塞了，直接停止运行 public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(()-&gt; { try { //加锁，可打断锁 lock.lockInterruptibly(); } catch (InterruptedException e) { e.printStackTrace(); //被打断，返回，不再向下执行 return; }finally { //释放锁 lock.unlock(); } }); lock.lock(); try { t1.start(); Thread.sleep(1000); //打断 t1.interrupt(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } 锁超时使用lock.tryLock方法会返回获取锁是否成功。如果成功则返回true，反之则返回false。 并且tryLock方法可以指定等待时间，参数为：tryLock(long timeout, TimeUnit unit), 其中timeout为最长等待时间，TimeUnit为时间单位 简而言之就是：获取失败了、获取超时了或者被打断了，不再阻塞，直接停止运行 不设置等待时间 public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(()-&gt; { //未设置等待时间，一旦获取失败，直接返回false if(!lock.tryLock()) { System.out.println(\"获取失败\"); //获取失败，不再向下执行，返回 return; } System.out.println(\"得到了锁\"); lock.unlock(); }); lock.lock(); try{ t1.start(); Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } 设置等待时间 public static void main(String[] args) { ReentrantLock lock = new ReentrantLock(); Thread t1 = new Thread(()-&gt; { try { //判断获取锁是否成功，最多等待1秒 if(!lock.tryLock(1, TimeUnit.SECONDS)) { System.out.println(\"获取失败\"); //获取失败，不再向下执行，直接返回 return; } } catch (InterruptedException e) { e.printStackTrace(); //被打断，不再向下执行，直接返回 return; } System.out.println(\"得到了锁\"); //释放锁 lock.unlock(); }); lock.lock(); try{ t1.start(); //打断等待 t1.interrupt(); Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } } 公平锁在线程获取锁失败，进入阻塞队列时，先进入的会在锁被释放后先获得锁。这样的获取方式就是公平的。 //默认是不公平锁，需要在创建时指定为公平锁 ReentrantLock lock = new ReentrantLock(true); 条件变量synchronized 中也有条件变量，就是我们讲原理时那个 waitSet 休息室，当条件不满足时进入waitSet 等待 ReentrantLock 的条件变量比 synchronized 强大之处在于，它是支持多个条件变量的，这就好比 synchronized 是那些不满足条件的线程都在一间休息室等消息 而 ReentrantLock 支持多间休息室，比如有专门等烟的休息室、专门等早餐的休息室、唤醒时也是按休息室来唤醒 使用要点： await 前需要获得锁 await 执行后，会释放锁，进入 conditionObject 等待 await 的线程被唤醒（或打断、或超时）取重新竞争 lock 锁 竞争 lock 锁成功后，从 await 后继续执行 static Boolean judge = false; public static void main(String[] args) throws InterruptedException { ReentrantLock lock = new ReentrantLock(); //获得条件变量 Condition condition = lock.newCondition(); new Thread(()-&gt;{ lock.lock(); try{ while(!judge) { System.out.println(\"不满足条件，等待...\"); //等待 condition.await(); } } catch (InterruptedException e) { e.printStackTrace(); } finally { System.out.println(\"执行完毕！\"); lock.unlock(); } }).start(); new Thread(()-&gt;{ lock.lock(); try { Thread.sleep(1); judge = true; //释放 condition.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock(); } }).start(); } 通过Lock与AQS实现可重入锁public class MyLock implements Lock { private static class Sync extends AbstractQueuedSynchronizer { @Override protected boolean tryAcquire(int arg) { if (getExclusiveOwnerThread() == null) { if (compareAndSetState(0, 1)) { setExclusiveOwnerThread(Thread.currentThread()); return true; } return false; } if (getExclusiveOwnerThread() == Thread.currentThread()) { int state = getState(); compareAndSetState(state, state + 1); return true; } return false; } @Override protected boolean tryRelease(int arg) { if (getState() &lt;= 0) { throw new IllegalMonitorStateException(); } if (getExclusiveOwnerThread() != Thread.currentThread()) { throw new IllegalMonitorStateException(); } int state = getState(); if (state == 1) { setExclusiveOwnerThread(null); compareAndSetState(state, 0); } else { compareAndSetState(state, state - 1); } return true; } @Override protected boolean isHeldExclusively() { return getState() &gt;= 1; } public Condition newCondition() { return new ConditionObject(); } } Sync sync = new Sync(); @Override public void lock() { sync.acquire(1); } @Override public void lockInterruptibly() throws InterruptedException { sync.acquireInterruptibly(1); } @Override public boolean tryLock() { return sync.tryAcquire(1); } @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException { return sync.tryAcquireNanos(1, time); } @Override public void unlock() { sync.release(1); } @Override public Condition newCondition() { return sync.newCondition(); } } class Main { static int num = 0; public static void main(String[] args) throws InterruptedException, IOException { MyLock lock = new MyLock(); Object syncLock = new Object(); Thread t1 = new Thread(() -&gt; { for (int i = 0; i &lt; 10000; i++) { lock.lock(); try { lock.lock(); try { lock.lock(); try { num++; } finally { lock.unlock(); } } finally { lock.unlock(); } } finally { lock.unlock(); } } }); Thread t2 = new Thread(() -&gt; { for (int i = 0; i &lt; 10000; i++) { lock.lock(); try { lock.lock(); try { lock.lock(); try { num--; } finally { lock.unlock(); } } finally { lock.unlock(); } } finally { lock.unlock(); } } }); t1.start(); t2.start(); t1.join(); t2.join(); int x = 0; } } 同步模式之 Balking定义 Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做 了，直接结束返回 实现例如： public class MonitorService { // 用来表示是否已经有线程已经在执行启动了 private volatile boolean starting; public void start() { log.info(\"尝试启动监控线程...\"); synchronized (this) { if (starting) { return; } starting = true; } // 真正启动监控线程... } } 当前端页面多次点击按钮调用 start 时 输出 [http-nio-8080-exec-1] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(false) [http-nio-8080-exec-1] cn.itcast.monitor.service.MonitorService - 监控线程已启动... [http-nio-8080-exec-2] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true) [http-nio-8080-exec-3] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true) [http-nio-8080-exec-4] cn.itcast.monitor.service.MonitorService - 该监控线程已启动?(true) 它还经常用来实现线程安全的单例 public final class Singleton { private Singleton() { } private static Singleton INSTANCE = null; public static synchronized Singleton getInstance() { if (INSTANCE != null) { return INSTANCE; } INSTANCE = new Singleton(); return INSTANCE; } } 对比一下保护性暂停模式：保护性暂停模式用在一个线程等待另一个线程的执行结果，当条件不满足时线程等待。 同步模式之顺序控制固定运行顺序 比如，必须先 2 后 1 打印 wait notify版本// 用来同步的对象 static Object obj = new Object(); // t2 运行标记， 代表 t2 是否执行过 static boolean t2runed = false; public static void main(String[] args) { Thread t1 = new Thread(() -&gt; { synchronized (obj) { // 如果 t2 没有执行过 while (!t2runed) { try { // t1 先等一会 obj.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } } System.out.println(1); }); Thread t2 = new Thread(() -&gt; { System.out.println(2); synchronized (obj) { // 修改运行标记 t2runed = true; // 通知 obj 上等待的线程（可能有多个，因此需要用 notifyAll） obj.notifyAll(); } }); t1.start(); t2.start(); } Park Unpark 版可以看到，实现上很麻烦： 首先，需要保证先 wait 再 notify，否则 wait 线程永远得不到唤醒。因此使用了『运行标记』来判断该不该 wait 第二，如果有些干扰线程错误地 notify 了 wait 线程，条件不满足时还要重新等待，使用了 while 循环来解决 此问题 最后，唤醒对象上的 wait 线程需要使用 notifyAll，因为『同步对象』上的等待线程可能不止一个 可以使用 LockSupport 类的 park 和 unpark 来简化上面的题目： Thread t1 = new Thread(() -&gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { } // 当没有『许可』时，当前线程暂停运行；有『许可』时，用掉这个『许可』，当前线程恢复运行 LockSupport.park(); System.out.println(\"1\"); }); Thread t2 = new Thread(() -&gt; { System.out.println(\"2\"); // 给线程 t1 发放『许可』（多次连续调用 unpark 只会发放一个『许可』） LockSupport.unpark(t1); }); t1.start(); t2.start(); park 和 unpark 方法比较灵活，他俩谁先调用，谁后调用无所谓。并且是以线程为单位进行『暂停』和『恢复』， 不需要『同步对象』和『运行标记』 交替输出 比如：线程 1 输出 a 5 次，线程 2 输出 b 5 次，线程 3 输出 c 5 次。现在要求输出 abcabcabcabcabc 怎么实现 wait/notify版本public class Test4 { static Symbol symbol = new Symbol(); public static void main(String[] args) { new Thread(()-&gt;{ symbol.run(\"a\", 1, 2); }).start(); new Thread(()-&gt;{ symbol.run(\"b\", 2, 3); }).start(); symbol.run(\"c\", 3, 1); new Thread(()-&gt;{ }).start(); } } class Symbol { public synchronized void run(String str, int flag, int nextFlag) { for(int i=0; i&lt;loopNumber; i++) { while(flag != this.flag) { try { this.wait(); } catch (InterruptedException e) { e.printStackTrace(); } } System.out.println(str); //设置下一个运行的线程标记 this.flag = nextFlag; //唤醒所有线程 this.notifyAll(); } } /** * 线程的执行标记， 1-&gt;a 2-&gt;b 3-&gt;c */ private int flag = 1; private int loopNumber = 5; public int getFlag() { return flag; } public void setFlag(int flag) { this.flag = flag; } public int getLoopNumber() { return loopNumber; } public void setLoopNumber(int loopNumber) { this.loopNumber = loopNumber; } } await/signal版本public class Test5 { static AwaitSignal awaitSignal = new AwaitSignal(); static Condition conditionA = awaitSignal.newCondition(); static Condition conditionB = awaitSignal.newCondition(); static Condition conditionC = awaitSignal.newCondition(); public static void main(String[] args) { new Thread(()-&gt;{ awaitSignal.run(\"a\", conditionA, conditionB); }).start(); new Thread(()-&gt;{ awaitSignal.run(\"b\", conditionB, conditionC); }).start(); new Thread(()-&gt;{ awaitSignal.run(\"c\", conditionC, conditionA); }).start(); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } awaitSignal.lock(); try { //唤醒一个等待的线程 conditionA.signal(); }finally { awaitSignal.unlock(); } } } class AwaitSignal extends ReentrantLock{ public void run(String str, Condition thisCondition, Condition nextCondition) { for(int i=0; i&lt;loopNumber; i++) { lock(); try { //全部进入等待状态 thisCondition.await(); System.out.print(str); nextCondition.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { unlock(); } } } private int loopNumber=5; public int getLoopNumber() { return loopNumber; } public void setLoopNumber(int loopNumber) { this.loopNumber = loopNumber; } } ThreadLocal简介ThreadLocal是JDK包提供的，它提供了线程本地变量，也就是如果你创建了一个ThreadLocal变量，那么访问这个变量的每个线程都会有这个变量的一个本地副本。当多个线程操作这个变量时，实际操作的是自己本地内存里面的变量，从而避免了线程安全问题 使用public class ThreadLocalStudy { public static void main(String[] args) { // 创建ThreadLocal变量 ThreadLocal&lt;String&gt; stringThreadLocal = new ThreadLocal&lt;&gt;(); ThreadLocal&lt;User&gt; userThreadLocal = new ThreadLocal&lt;&gt;(); // 创建两个线程，分别使用上面的两个ThreadLocal变量 Thread thread1 = new Thread(()-&gt;{ // stringThreadLocal第一次赋值 stringThreadLocal.set(\"thread1 stringThreadLocal first\"); // stringThreadLocal第二次赋值 stringThreadLocal.set(\"thread1 stringThreadLocal second\"); // userThreadLocal赋值 userThreadLocal.set(new User(\"Nyima\", 20)); // 取值 System.out.println(stringThreadLocal.get()); System.out.println(userThreadLocal.get()); // 移除 userThreadLocal.remove(); System.out.println(userThreadLocal.get()); }); Thread thread2 = new Thread(()-&gt;{ // stringThreadLocal第一次赋值 stringThreadLocal.set(\"thread2 stringThreadLocal first\"); // stringThreadLocal第二次赋值 stringThreadLocal.set(\"thread2 stringThreadLocal second\"); // userThreadLocal赋值 userThreadLocal.set(new User(\"Hulu\", 20)); // 取值 System.out.println(stringThreadLocal.get()); System.out.println(userThreadLocal.get()); }); // 启动线程 thread1.start(); thread2.start(); } } class User { String name; int age; public User(String name, int age) { this.name = name; this.age = age; } @Override public String toString() { return \"User{\" + \"name='\" + name + '\\'' + \", age=\" + age + '}'; } } 运行结果 thread1 stringThreadLocal second thread2 stringThreadLocal second User{name='Nyima', age=20} User{name='Hulu', age=20} null 从运行结果可以看出 每个线程中的ThreadLocal变量是每个线程私有的，而不是共享的 从线程1和线程2的打印结果可以看出 ThreadLocal其实就相当于其泛型类型的一个变量，只不过是每个线程私有的 stringThreadLocal被赋值了两次，保存的是最后一次赋值的结果 ThreadLocal可以进行以下几个操作 set 设置值 get 取出值 remove 移除值 原理Thread中的threadLocalspublic class Thread implements Runnable { ... ThreadLocal.ThreadLocalMap threadLocals = null; // 放在后面说 ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ... } static class ThreadLocalMap { static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; { /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) { super(k); value = v; } } 可以看出Thread类中有一个threadLocals和一个inheritableThreadLocals，它们都是ThreadLocalMap类型的变量，而ThreadLocalMap是一个定制化的Hashmap。在默认情况下，每个线程中的这两个变量都为null。此处先讨论threadLocals，inheritableThreadLocals放在后面讨论 ThreadLocal中的方法set方法 public void set(T value) { // 获取当前线程 Thread t = Thread.currentThread(); // 获得ThreadLocalMap对象 // 这里的get会返回Thread类中的threadLocals ThreadLocalMap map = getMap(t); // 判断map是否已经创建，没创建就创建并放入值，创建了就直接放入 if (map != null) // ThreadLocal自生的引用作为key，传入的值作为value map.set(this, value); else createMap(t, value); } 如果未创建 void createMap(Thread t, T firstValue) { // 创建的同时设置想放入的值 // hreadLocal自生的引用作为key，传入的值作为value t.threadLocals = new ThreadLocalMap(this, firstValue); } get方法 public T get() { // 获取当前线程 Thread t = Thread.currentThread(); // 获取当前线程的threadLocals变量 ThreadLocalMap map = getMap(t); // 判断threadLocals是否被初始化了 if (map != null) { // 已经初始化则直接返回 ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) { @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; } } // 否则就创建threadLocals return setInitialValue(); } private T setInitialValue() { // 这个方法返回是null T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); // 无论map创建与否，最终value的值都为null if (map != null) map.set(this, value); else createMap(t, value); return value; } protected T initialValue() { return null; } remove方法 public void remove() { ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) // 如果threadLocals已经被初始化，则移除 m.remove(this); } 总结在每个线程内部都有一个名为threadLocals的成员变量，该变量的类型为HashMap，其中key为我们定义的ThreadLocal变量的this引用，value则为我们使用set方法设置的值。每个线程的本地变量存放在线程自己的内存变量threadLocals中 只有当前线程第一次调用ThreadLocal的set或者get方法时才会创建threadLocals（inheritableThreadLocals也是一样）。其实每个线程的本地变量不是存放在ThreadLocal实例里面，而是存放在调用线程的threadLocals变量里面 15、InheritableThreadLocal简介从ThreadLocal的源码可以看出，无论是set、get、还是remove，都是相对于当前线程操作的 Thread.currentThread() 所以ThreadLocal无法从父线程传向子线程，所以InheritableThreadLocal出现了，它能够让父线程中ThreadLocal的值传给子线程。 也就是从main所在的线程，传给thread1或thread2 使用public class Demo1 { public static void main(String[] args) { ThreadLocal&lt;String&gt; stringThreadLocal = new ThreadLocal&lt;&gt;(); InheritableThreadLocal&lt;String&gt; stringInheritable = new InheritableThreadLocal&lt;&gt;(); // 主线程赋对上面两个变量进行赋值 stringThreadLocal.set(\"this is threadLocal\"); stringInheritable.set(\"this is inheritableThreadLocal\"); // 创建线程 Thread thread1 = new Thread(()-&gt;{ // 获得ThreadLocal中存放的值 System.out.println(stringThreadLocal.get()); // 获得InheritableThreadLocal存放的值 System.out.println(stringInheritable.get()); }); thread1.start(); } } 运行结果 null this is inheritableThreadLocal 可以看出InheritableThreadLocal的值成功从主线程传入了子线程，而ThreadLocal则没有 原理InheritableThreadLocalpublic class InheritableThreadLocal&lt;T&gt; extends ThreadLocal&lt;T&gt; { // 传入父线程中的一个值，然后直接返回 protected T childValue(T parentValue) { return parentValue; } // 返回传入线程的inheritableThreadLocals // Thread中有一个inheritableThreadLocals变量 // ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; ThreadLocalMap getMap(Thread t) { return t.inheritableThreadLocals; } // 创建一个inheritableThreadLocals void createMap(Thread t, T firstValue) { t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue); } } 由如上代码可知，InheritableThreadLocal继承了ThreadLocal，并重写了三个方法。InheritableThreadLocal重写了createMap方法，那么现在当第一次调用set方法时，创建的是当前线程的inheritableThreadLocals变量的实例而不再是threadLocals。当调用getMap方法获取当前线程内部的map变量时，获取的是inheritableThreadLocals而不再是threadLocals childValue(T parentValue)方法的调用在主函数运行时，会调用Thread的默认构造函数（创建主线程，也就是父线程），所以我们先看看Thread的默认构造函数 public Thread() { init(null, null, \"Thread-\" + nextThreadNum(), 0); } private void init(ThreadGroup g, Runnable target, String name, long stackSize, AccessControlContext acc, boolean inheritThreadLocals) { ... // 获得当前线程的，在这里是主线程 Thread parent = currentThread(); ... // 如果父线程的inheritableThreadLocals存在 // 我们在主线程中调用set和get时，会创建inheritableThreadLocals if (inheritThreadLocals &amp;&amp; parent.inheritableThreadLocals != null) // 设置子线程的inheritableThreadLocals this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals); /* Stash the specified stack size in case the VM cares */ this.stackSize = stackSize; /* Set thread ID */ tid = nextThreadID(); } static ThreadLocalMap createInheritedMap(ThreadLocalMap parentMap) { return new ThreadLocalMap(parentMap); } 在createInheritedMap内部使用父线程的inheritableThreadLocals变量作为构造函数创建了一个新的ThreadLocalMap变量，然后赋值给了子线程的inheritableThreadLocals变量 private ThreadLocalMap(ThreadLocalMap parentMap) { Entry[] parentTable = parentMap.table; int len = parentTable.length; setThreshold(len); table = new Entry[len]; for (int j = 0; j &lt; len; j++) { Entry e = parentTable[j]; if (e != null) { @SuppressWarnings(\"unchecked\") ThreadLocal&lt;Object&gt; key = (ThreadLocal&lt;Object&gt;) e.get(); if (key != null) { // 这里调用了 childValue 方法 // 该方法会返回parent的值 Object value = key.childValue(e.value); Entry c = new Entry(key, value); int h = key.threadLocalHashCode &amp; (len - 1); while (table[h] != null) h = nextIndex(h, len); table[h] = c; size++; } } } } 在该构造函数内部把父线程的inheritableThreadLocals成员变量的值复制到新的ThreadLocalMap对象中 总结InheritableThreadLocal类通过重写getMap和createMap，让本地变量保存到了具体线程的inheritableThreadLocals变量里面，那么线程在通过InheritableThreadLocal类实例的set或者get方法设置变量时，就会创建当前线程的inheritableThreadLocals变量。 当父线程创建子线程时，构造函数会把父线程中inheritableThreadLocals变量里面的本地变量复制一份保存到子线程的inheritableThreadLocals变量里面。 共享模型之内存JAVA内存模型（JMM）JMM 即 Java Memory Model，它定义了主存（共享内存）、工作内存（线程私有）抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。 JMM体现在以下几个方面 原子性 - 保证指令不会受到线程上下文切换的影响 可见性 - 保证指令不会受 cpu 缓存的影响 有序性 - 保证指令不会受 cpu 指令并行优化的影响 可见性引例退不出的循环 static Boolean run = true; public static void main(String[] args) throws InterruptedException { new Thread(()-&gt;{ while (run) { //如果run为真，则一直执行 } }).start(); Thread.sleep(1000); System.out.println(\"改变run的值为false\"); run = false; } 为什么无法退出该循环 初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中， 减少对主存中 run 的访问，提高效率 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量 的值，结果永远是旧值 解决方法 使用volatile易变关键字 它可以用来修饰成员变量和静态成员变量（放在主存中的变量），他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存 //使用易变关键字 volatile static Boolean run = true; public static void main(String[] args) throws InterruptedException { new Thread(()-&gt;{ while (run) { //如果run为真，则一直执行 } }).start(); Thread.sleep(1000); System.out.println(\"改变run的值为false\"); run = false; } 可见性与原子性前面例子体现的实际就是可见性，它保证的是在多个线程之间，一个线程对volatile变量的修改对另一个线程可见， 不能保证原子性，仅用在一个写线程，多个读线程的情况 注意 synchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。 但缺点是 synchronized 是属于重量级操作，性能相对更低。 如果在前面示例的死循环中加入 System.out.println() 会发现即使不加 volatile 修饰符，线程 t 也能正确看到 对 run 变量的修改了，想一想为什么？ 因为使用了synchronized关键字 public void println(String x) { //使用了synchronized关键字 synchronized (this) { print(x); newLine(); } } 两阶终止模式优化public class Test7 { public static void main(String[] args) throws InterruptedException { Monitor monitor = new Monitor(); monitor.start(); Thread.sleep(3500); monitor.stop(); } } class Monitor { Thread monitor; //设置标记，用于判断是否被终止了 private volatile boolean stop = false; /** * 启动监控器线程 */ public void start() { //设置线控器线程，用于监控线程状态 monitor = new Thread() { @Override public void run() { //开始不停的监控 while (true) { if(stop) { System.out.println(\"处理后续任务\"); break; } System.out.println(\"监控器运行中...\"); try { //线程休眠 Thread.sleep(1000); } catch (InterruptedException e) { System.out.println(\"被打断了\"); } } } }; monitor.start(); } /** * 用于停止监控器线程 */ public void stop() { //打断线程 monitor.interrupt(); //修改标记 stop = true; } } 同步模式之犹豫模式定义 Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做 了，**直接结束返回** 用一个标记来判断该任务是否已经被执行过了 需要避免线程安全问题 加锁的代码块要尽量的小，以保证性能 package com.nyima.day1; /** * @author Chen Panwen * @data 2020/3/26 16:11 */ public class Test7 { public static void main(String[] args) throws InterruptedException { Monitor monitor = new Monitor(); monitor.start(); monitor.start(); Thread.sleep(3500); monitor.stop(); } } class Monitor { Thread monitor; //设置标记，用于判断是否被终止了 private volatile boolean stop = false; //设置标记，用于判断是否已经启动过了 private boolean starting = false; /** * 启动监控器线程 */ public void start() { //上锁，避免多线程运行时出现线程安全问题 synchronized (this) { if (starting) { //已被启动，直接返回 return; } //启动监视器，改变标记 starting = true; } //设置线控器线程，用于监控线程状态 monitor = new Thread() { @Override public void run() { //开始不停的监控 while (true) { if(stop) { System.out.println(\"处理后续任务\"); break; } System.out.println(\"监控器运行中...\"); try { //线程休眠 Thread.sleep(1000); } catch (InterruptedException e) { System.out.println(\"被打断了\"); } } } }; monitor.start(); } /** * 用于停止监控器线程 */ public void stop() { //打断线程 monitor.interrupt(); stop = true; } } 有序性指令重排 JVM 会在不影响正确性的前提下，可以调整语句的执行顺序 static int i; static int j; // 在某个线程内执行如下赋值操作 i = ...; j = ...; 可以看到，至于是先执行 i 还是 先执行 j ，对最终的结果不会产生影响。所以，上面代码真正执行时，既可以是 i = ...; j = ...; 也可以是 j = ...; i = ...; 这种特性称之为『指令重排』，多线程下『指令重排』会影响正确性。 指令重排序优化 事实上，现代处理器会设计为一个时钟周期完成一条执行时间长的 CPU 指令。为什么这么做呢？可以想到指令还可以再划分成一个个更小的阶段，例如，每条指令都可以分为： 取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回 这5 个阶段 在不改变程序结果的前提下，这些指令的各个阶段可以通过重排序和组合来实现指令级并行 指令重排的前提是，重排指令不能影响结果，例如 // 可以重排的例子 int a = 10; int b = 20; System.out.println( a + b ); // 不能重排的例子 int a = 10; int b = a - 5; 支持流水线的处理器现代 CPU 支持多级指令流水线，例如支持同时执行 取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回 的处理器，就可以称之为五级指令流水线。这时 CPU 可以在一个时钟周期内，同时运行五条指令的不同阶段（相当于一 条执行时间长的复杂指令），IPC = 1，本质上，流水线技术并不能缩短单条指令的执行时间，但它变相地提高了指令地吞吐率。 在多线程环境下，指令重排序可能导致出现意料之外的结果 解决办法volatile 修饰的变量，可以禁用指令重排 禁止的是加volatile关键字变量之前的代码被重排序 内存屏障 可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中新数据 有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 volatile 原理volatile的底层实现原理是内存屏障，Memory Barrier（Memory Fence） 对 volatile 变量的写指令后会加入写屏障 对 volatile 变量的读指令前会加入读屏障 如何保证可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 public void actor2(I_Result r) { num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 } 而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中新数据 public void actor1(I_Result r) { // 读屏障 // ready 是 volatile 读取值带读屏障 if(ready) { r.r1 = num + num; } else { r.r1 = 1; } } 如何保证有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 public void actor2(I_Result r) { num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 } 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 public void actor1(I_Result r) { // 读屏障 // ready 是 volatile 读取值带读屏障 if(ready) { r.r1 = num + num; } else { r.r1 = 1; } } 但是不能解决指令交错问题 写屏障仅仅是保证之后的读能够读到新的结果，但不能保证读跑到它前面去 而有序性的保证也只是保证了本线程内相关代码不被重排序 实现原理之Lock前缀在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时 instance = new Singleton(); 对应的汇编代码是 ... lock addl ... 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事 Lock前缀指令会引起处理器 缓存回写到内存 Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。但是，在最近的处理器里，LOCK #信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据 一个处理器的缓存回写到内存会 导致其他处理器的缓存无效 在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致 共享模型之无锁无锁解决线程安全问题 使用原子整数 AtomicInteger balance = new AtomicInteger(); 例子： interface Account { Integer getBalance(); void withdraw(Integer amount); /** * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作 * 如果初始余额为 10000 那么正确的结果应当是 0 */ static void demo(Account account) { List&lt;Thread&gt; ts = new ArrayList&lt;&gt;(); long start = System.nanoTime(); for (int i = 0; i &lt; 1000; i++) { ts.add(new Thread(() -&gt; { account.withdraw(10); })); } ts.forEach(Thread::start); ts.forEach(t -&gt; { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); long end = System.nanoTime(); System.out.println(account.getBalance() + \" cost: \" + (end - start) / 1000_000 + \" ms\"); } } //线程不安全的做法 class AccountUnsafe implements Account { private Integer balance; public AccountUnsafe(Integer balance) { this.balance = balance; } @Override public Integer getBalance() { return this.balance; } @Override public synchronized void withdraw(Integer amount) { balance -= amount; } public static void main(String[] args) { Account.demo(new AccountUnsafe(10000)); Account.demo(new AccountCas(10000)); } } //线程安全的做法 class AccountCas implements Account { //使用原子整数 private AtomicInteger balance; public AccountCas(int balance) { this.balance = new AtomicInteger(balance); } @Override public Integer getBalance() { //得到原子整数的值 return balance.get(); } @Override public void withdraw(Integer amount) { while(true) { //获得修改前的值 int prev = balance.get(); //获得修改后的值 int next = prev-amount; //比较并设值 if(balance.compareAndSet(prev, next)) { break; } } } } CAS与volatile前面看到的 AtomicInteger 的解决方法，内部并没有用锁来保护共享变量的线程安全。那么它是如何实现的呢？ 其中的关键是 compareAndSwap（比较并设置值），它的简称就是 CAS （也有 Compare And Swap 的说法），它必须是**原子操作。** 过程分析 当一个线程要去修改Account对象中的值时，先获取值prev（调用get方法），然后再将其设置为新的值next（调用cas方法）。在调用cas方法时，会将prev与Account中的余额进行比较。 如果两者相等，就说明该值还未被其他线程修改，此时便可以进行修改操作。 如果两者不相等，就不设置值，重新获取值prev（调用get方法），然后再将其设置为新的值next（调用cas方法），直到修改成功为止。 注意 其实 CAS 的底层是 lock cmpxchg 指令（X86 架构），在单核 CPU 和多核 CPU 下都能够保证【比较-交换】的原子性。 在多核状态下，某个核执行到带 lock 的指令时，CPU 会让总线锁住，当这个核把此指令执行完毕，再开启总线。这个过程中不会被线程的调度机制所打断，保证了多个线程对内存操作的准确性，是原子的。 volatile获取共享变量时，为了保证该变量的可见性，需要使用 volatile 修饰。它可以用来修饰成员变量和静态成员变量，他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取 它的值，线程操作 volatile 变量都是直接操作主存。即一个线程对 volatile 变量的修改，对另一个线程可见。 注意 volatile 仅仅保证了共享变量的可见性，让其它线程能够看到新值，但不能解决指令交错问题（不能保证原子性） CAS 必须借助 volatile 才能读取到共享变量的新值来实现【比较并交换】的效果 效率问题一般情况下，使用无锁比使用加锁的效率更高。 原因 无锁情况下，即使重试失败，线程始终在高速运行，没有停歇，而 synchronized 会让线程在没有获得锁的时 候，发生上下文切换，进入阻塞。 打个比喻 线程就好像高速跑道上的赛车，高速运行时，速度超快，一旦发生上下文切换，就好比赛车要减速、熄火， 等被唤醒又得重新打火、启动、加速… 恢复到高速运行，代价比较大 但无锁情况下，因为线程要保持运行，需要额外 CPU 的支持，CPU 在这里就好比高速跑道，没有额外的跑 道，线程想高速运行也无从谈起，虽然不会进入阻塞，但由于没有分到时间片，仍然会进入可运行状态，还是会导致上下文切换。 CAS特点结合 CAS 和 volatile 可以实现无锁并发，适用于线程数少、多核 CPU 的场景下。 CAS 是基于乐观锁的思想：乐观的估计，不怕别的线程来修改共享变量，就算改了也没关系，我吃亏点再重试呗。 synchronized 是基于悲观锁的思想：悲观的估计，得防着其它线程来修改共享变量，我上了锁你们都别想改，我改完了解开锁，你们才有机会。 CAS 体现的是无锁并发、无阻塞并发，请仔细体会这两句话的意思 因为没有使用 synchronized，所以线程不会陷入阻塞，这是效率提升的因素之一 但如果竞争激烈，可以想到重试必然频繁发生，反而效率会受影响 原子整数J.U.C 并发包提供了 AtomicBoolean AtomicInteger AtomicLong 以 AtomicInteger 为例 AtomicInteger i = new AtomicInteger(0); // 获取并自增（i = 0, 结果 i = 1, 返回 0），类似于 i++ System.out.println(i.getAndIncrement()); // 自增并获取（i = 1, 结果 i = 2, 返回 2），类似于 ++i System.out.println(i.incrementAndGet()); // 自减并获取（i = 2, 结果 i = 1, 返回 1），类似于 --i System.out.println(i.decrementAndGet()); // 获取并自减（i = 1, 结果 i = 0, 返回 1），类似于 i-- System.out.println(i.getAndDecrement()); // 获取并加值（i = 0, 结果 i = 5, 返回 0） System.out.println(i.getAndAdd(5)); // 加值并获取（i = 5, 结果 i = 0, 返回 0） System.out.println(i.addAndGet(-5)); // 获取并更新（i = 0, p 为 i 的当前值, 结果 i = -2, 返回 0） // 其中函数中的操作能保证原子，但函数需要无副作用 System.out.println(i.getAndUpdate(p -&gt; p - 2)); // 更新并获取（i = -2, p 为 i 的当前值, 结果 i = 0, 返回 0） // 其中函数中的操作能保证原子，但函数需要无副作用 System.out.println(i.updateAndGet(p -&gt; p + 2)); // 获取并计算（i = 0, p 为 i 的当前值, x 为参数1, 结果 i = 10, 返回 0） // 其中函数中的操作能保证原子，但函数需要无副作用 // getAndUpdate 如果在 lambda 中引用了外部的局部变量，要保证该局部变量是 final 的 // getAndAccumulate 可以通过 参数1 来引用外部的局部变量，但因为其不在 lambda 中因此不必是 final System.out.println(i.getAndAccumulate(10, (p, x) -&gt; p + x)); // 计算并获取（i = 10, p 为 i 的当前值, x 为参数1, 结果 i = 0, 返回 0） // 其中函数中的操作能保证原子，但函数需要无副作用 System.out.println(i.accumulateAndGet(-10, (p, x) -&gt; p + x)); 原子引用public interface DecimalAccount { BigDecimal getBalance(); void withdraw(BigDecimal amount); /** * 方法内会启动 1000 个线程，每个线程做 -10 元 的操作 * 如果初始余额为 10000 那么正确的结果应当是 0 */ static void demo(DecimalAccountImpl account) { List&lt;Thread&gt; ts = new ArrayList&lt;&gt;(); long start = System.nanoTime(); for (int i = 0; i &lt; 1000; i++) { ts.add(new Thread(() -&gt; { account.withdraw(BigDecimal.TEN); })); } ts.forEach(Thread::start); ts.forEach(t -&gt; { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); long end = System.nanoTime(); System.out.println(account.getBalance() + \" cost: \" + (end - start) / 1000_000 + \" ms\"); } } class DecimalAccountImpl implements DecimalAccount { //原子引用，泛型类型为小数类型 AtomicReference&lt;BigDecimal&gt; balance; public DecimalAccountImpl(BigDecimal balance) { this.balance = new AtomicReference&lt;BigDecimal&gt;(balance); } @Override public BigDecimal getBalance() { return balance.get(); } @Override public void withdraw(BigDecimal amount) { while(true) { BigDecimal pre = balance.get(); BigDecimal next = pre.subtract(amount); if(balance.compareAndSet(pre, next)) { break; } } } public static void main(String[] args) { DecimalAccount.demo(new DecimalAccountImpl(new BigDecimal(\"10000\"))); } } ABA问题public class Demo3 { static AtomicReference&lt;String&gt; str = new AtomicReference&lt;&gt;(\"A\"); public static void main(String[] args) { new Thread(() -&gt; { String pre = str.get(); System.out.println(\"change\"); try { other(); } catch (InterruptedException e) { e.printStackTrace(); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //把str中的A改为C System.out.println(\"change A-&gt;C \" + str.compareAndSet(pre, \"C\")); }).start(); } static void other() throws InterruptedException { new Thread(()-&gt; { System.out.println(\"change A-&gt;B \" + str.compareAndSet(\"A\", \"B\")); }).start(); Thread.sleep(500); new Thread(()-&gt; { System.out.println(\"change B-&gt;A \" + str.compareAndSet(\"B\", \"A\")); }).start(); } } 运行结果如下： change change A -&gt; B true change B -&gt; A true change A -&gt; C true 主线程仅能判断出共享变量的值与初值 A 是否相同，不能感知到这种从 A 改为 B 又 改回 A 的情况，如果主线程希望：只要有其它线程【动过了】共享变量，那么自己的 cas 就算失败，这时，仅比较值是不够的，需要再加一个版本号 AtomicStampedReferencepublic class Demo3 { //指定版本号 static AtomicStampedReference&lt;String&gt; str = new AtomicStampedReference&lt;&gt;(\"A\", 0); public static void main(String[] args) { new Thread(() -&gt; { String pre = str.getReference(); //获得版本号 int stamp = str.getStamp(); System.out.println(\"change\"); try { other(); } catch (InterruptedException e) { e.printStackTrace(); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //把str中的A改为C,并比对版本号，如果版本号相同，就执行替换，并让版本号+1 System.out.println(\"change A-&gt;C stamp \" + stamp + str.compareAndSet(pre, \"C\", stamp, stamp+1)); }).start(); } static void other() throws InterruptedException { new Thread(()-&gt; { int stamp = str.getStamp(); System.out.println(\"change A-&gt;B stamp \" + stamp + str.compareAndSet(\"A\", \"B\", stamp, stamp+1)); }).start(); Thread.sleep(500); new Thread(()-&gt; { int stamp = str.getStamp(); System.out.println(\"change B-&gt;A stamp \" + stamp + str.compareAndSet(\"B\", \"A\", stamp, stamp+1)); }).start(); } } 运行结果如下： change change A -&gt; B stamp 0 true change B -&gt; A stamp 1 true change A -&gt; C stamp 0 false AtomicMarkableReferenceAtomicStampedReference 可以给原子引用加上版本号，追踪原子引用整个的变化过程，如： A -&gt; B -&gt; A -&gt; C ，通过AtomicStampedReference，我们可以知道，引用变量中途被更改了几次。但是有时候，并不关心引用变量更改了几次，只是单纯的关心是否更改过，所以就有了 AtomicMarkableReference public class Demo4 { //指定版本号 static AtomicMarkableReference&lt;String&gt; str = new AtomicMarkableReference&lt;&gt;(\"A\", true); public static void main(String[] args) { new Thread(() -&gt; { String pre = str.getReference(); System.out.println(\"change\"); try { other(); } catch (InterruptedException e) { e.printStackTrace(); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //把str中的A改为C,并比对版本号，如果版本号相同，就执行替换，并让版本号+1 System.out.println(\"change A-&gt;C mark \" + str.compareAndSet(pre, \"C\", true, false)); }).start(); } static void other() throws InterruptedException { new Thread(() -&gt; { System.out.println(\"change A-&gt;A mark \" + str.compareAndSet(\"A\", \"A\", true, false)); }).start(); } } change change A -&gt; A mark true change A -&gt; C mark false 两者的区别 AtomicStampedReference 需要我们传入整型变量作为版本号，来判定是否被更改过 AtomicMarkableReference需要我们传入布尔变量作为标记，来判断是否被更改过 原子数组 AtomicIntegerArray AtomicLongArray AtomicReferenceArray 有如下方法 /** 参数1，提供数组、可以是线程不安全数组或线程安全数组 参数2，获取数组长度的方法 参数3，自增方法，回传 array, index 参数4，打印数组的方法 */ // supplier 提供者 无中生有 ()-&gt;结果 // function 函数 一个参数一个结果 (参数)-&gt;结果 , BiFunction (参数1,参数2)-&gt;结果 // consumer 消费者 一个参数没结果 (参数)-&gt;void, BiConsumer (参数1,参数2)-&gt; private static &lt;T&gt; void demo( Supplier&lt;T&gt; arraySupplier, Function&lt;T, Integer&gt; lengthFun, BiConsumer&lt;T, Integer&gt; putConsumer, Consumer&lt;T&gt; printConsumer ) { List&lt;Thread&gt; ts = new ArrayList&lt;&gt;(); T array = arraySupplier.get(); int length = lengthFun.apply(array); for (int i = 0; i &lt; length; i++) { // 每个线程对数组作 10000 次操作 ts.add(new Thread(() -&gt; { for (int j = 0; j &lt; 10000; j++) { putConsumer.accept(array, j%length); } })); } ts.forEach(t -&gt; t.start()); // 启动所有线程 ts.forEach(t -&gt; { try { t.join(); } catch (InterruptedException e) { e.printStackTrace(); } }); // 等所有线程结束 printConsumer.accept(array); } lamba表达式的使用 提供者 无参又返回 ()-&gt;返回结果 方法 有参有返回 (参数一…)-&gt;返回结果 消费者 有参无返回 (参数一…)-&gt;void 原子更新器 AtomicReferenceFieldUpdater // 域 字段 AtomicIntegerFieldUpdater AtomicLongFieldUpdate 原子更新器用于帮助我们改变某个对象中的某个属性 public class Demo1 { public static void main(String[] args) { Student student = new Student(); // 获得原子更新器 // 泛型 // 参数1 持有属性的类 参数2 被更新的属性的类 // newUpdater中的参数：第三个为属性的名称 AtomicReferenceFieldUpdater&lt;Student, String&gt; updater = AtomicReferenceFieldUpdater.newUpdater(Student.class, String.class, \"name\"); // 修改 updater.compareAndSet(student, null, \"Nyima\"); System.out.println(student); } } class Student { volatile String name; @Override public String toString() { return \"Student{\" + \"name='\" + name + '\\'' + '}'; } } 原子更新器初始化过程从上面的例子可以看出，原子更新器是通过newUpdater来获取实例的。其中传入了三个参数 拥有属性的类的Class 属性的Class 属性的名称 大概可以猜出来，初始化过程用到了反射，让我们看看源码来验证一下这个猜测。 newUpdater方法public static &lt;U,W&gt; AtomicReferenceFieldUpdater&lt;U,W&gt; newUpdater(Class&lt;U&gt; tclass, Class&lt;W&gt; vclass, String fieldName) { // 返回了一个AtomicReferenceFieldUpdaterImpl实例 return new AtomicReferenceFieldUpdaterImpl&lt;U,W&gt; (tclass, vclass, fieldName, Reflection.getCallerClass()); } 从newUpdater方法还并不能看出来具体的初始化过程 内部实现类 AtomicReferenceFieldUpdater为抽象类，该类内部有一个自己的实现类AtomicReferenceFieldUpdaterImpl private static final class AtomicReferenceFieldUpdaterImpl&lt;T,V&gt; extends AtomicReferenceFieldUpdater&lt;T,V&gt; 构造方法 AtomicReferenceFieldUpdaterImpl(final Class&lt;T&gt; tclass, final Class&lt;V&gt; vclass, final String fieldName, final Class&lt;?&gt; caller) { // 用于保存要被修改的属性 final Field field; // 属性的Class final Class&lt;?&gt; fieldClass; // field的修饰符 final int modifiers; try { // 反射获得属性 field = AccessController.doPrivileged( new PrivilegedExceptionAction&lt;Field&gt;() { public Field run() throws NoSuchFieldException { // tclass为传入的属性的Class，可以通过它来获得属性 return tclass.getDeclaredField(fieldName); } }); // 获得属性的修饰符，主要用于判断 // 1、vclass 与 属性确切的类型是否匹配 // 2、是否为引用类型 // 3、被修改的属性是否加了volatile关键字 modifiers = field.getModifiers(); sun.reflect.misc.ReflectUtil.ensureMemberAccess( caller, tclass, null, modifiers); ClassLoader cl = tclass.getClassLoader(); ClassLoader ccl = caller.getClassLoader(); if ((ccl != null) &amp;&amp; (ccl != cl) &amp;&amp; ((cl == null) || !isAncestor(cl, ccl))) { sun.reflect.misc.ReflectUtil.checkPackageAccess(tclass); } // 获得属性类的Class fieldClass = field.getType(); } catch (PrivilegedActionException pae) { throw new RuntimeException(pae.getException()); } catch (Exception ex) { throw new RuntimeException(ex); } if (vclass != fieldClass) throw new ClassCastException(); if (vclass.isPrimitive()) throw new IllegalArgumentException(\"Must be reference type\"); if (!Modifier.isVolatile(modifiers)) throw new IllegalArgumentException(\"Must be volatile type\"); // Access to protected field members is restricted to receivers only // of the accessing class, or one of its subclasses, and the // accessing class must in turn be a subclass (or package sibling) // of the protected member's defining class. // If the updater refers to a protected field of a declaring class // outside the current package, the receiver argument will be // narrowed to the type of the accessing class. // 对类中的属性进行初始化 this.cclass = (Modifier.isProtected(modifiers) &amp;&amp; tclass.isAssignableFrom(caller) &amp;&amp; !isSamePackage(tclass, caller)) ? caller : tclass; this.tclass = tclass; this.vclass = vclass; // 获得偏移量 this.offset = U.objectFieldOffset(field); } 可以看出，原子引用更新器确实使用了反射 原理之LongAdderLongAdder 是并发大师 @author Doug Lea （大哥李）的作品，设计的非常精巧 LongAdder 类有几个关键域： // 累加单元数组, 懒惰初始化 transient volatile Cell[] cells; // 基础值, 如果没有竞争, 则用 cas 累加这个域 transient volatile long base; // 在 cells 创建或扩容时, 置为 1, 表示加锁 transient volatile int cellsBusy; 原理之伪共享其中 Cell 即为累加单元 // 防止缓存行伪共享 @sun.misc.Contended static final class Cell { volatile long value; Cell(long x) { value = x; } // 最重要的方法, 用来 cas 方式进行累加, prev 表示旧值, next 表示新值 final boolean cas(long prev, long next) { return UNSAFE.compareAndSwapLong(this, valueOffset, prev, next); } // 省略不重要代码 } 得从缓存说起缓存与内存的速度比较 从 cpu 到 大约需要的时钟周期 寄存器 1 cycle (4GHz 的 CPU 约为0.25ns) L1 3~4 cycle L2 10~20 cycle L3 40~45 cycle 内存 120~240 cycle 因为 CPU 与 内存的速度差异很大，需要靠预读数据至缓存来提升效率。而缓存以缓存行为单位，每个缓存行对应着一块内存，一般是 64 byte（8 个 long）缓存的加入会造成数据副本的产生，即同一份数据会缓存在不同核心的缓存行中CPU 要保证数据的一致性，如果某个 CPU 核心更改了数据，其它 CPU 核心对应的整个缓存行必须失效 因为 Cell 是数组形式，在内存中是连续存储的，一个 Cell 为 24 字节（16 字节的对象头和 8 字节的 value），因 此缓存行可以存下 2 个的 Cell 对象。这样问题来了： Core-0 要修改 Cell[0] Core-1 要修改 Cell[1] 无论谁修改成功，都会导致对方 Core 的缓存行失效， 比如 Core-0 中 Cell[0]=6000, Cell[1]=8000 要累加 Cell[0]=6001, Cell[1]=8000 ，这时会让 Core-1 的缓存行失效 @sun.misc.Contended 用来解决这个问题，它的原理是在使用此注解的对象或字段的前后各增加 128 字节大小的 padding（空白），从而让 CPU 将对象预读至缓存时占用不同的缓存行，这样，不会造成对方缓存行的失效 累加主要调用以下方法 public void add(long x) { // as 为累加单元数组 // b 为基础值 // x 为累加值 Cell[] as; long b, v; int m; Cell a; // 进入 if 的两个条件 // 1. as 有值, 表示已经发生过竞争, 进入 if // 2. cas 给 base 累加时失败了, 表示 base 发生了竞争, 进入 if if ((as = cells) != null || !casBase(b = base, b + x)) { // uncontended 表示 cell 没有竞争 boolean uncontended = true; if ( // as 还没有创建 as == null || (m = as.length - 1) &lt; 0 || // 当前线程对应的 cell 还没有 (a = as[getProbe() &amp; m]) == null || // cas 给当前线程的 cell 累加失败 uncontended=false ( a 为当前线程的 cell ) !(uncontended = a.cas(v = a.value, v + x)) ) { // 进入 cell 数组创建、cell 创建的流程 longAccumulate(x, null, uncontended); } } } add/累加流程图 final void longAccumulate(long x, LongBinaryOperator fn, boolean wasUncontended) { int h; // 当前线程还没有对应的 cell, 需要随机生成一个 h 值用来将当前线程绑定到 cell if ((h = getProbe()) == 0) { // 初始化 probe ThreadLocalRandom.current(); // h 对应新的 probe 值, 用来对应 cell h = getProbe(); wasUncontended = true; } // collide 为 true 表示需要扩容 boolean collide = false; for (;;) { Cell[] as; Cell a; int n; long v; // 已经有了 cells if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) { // 还没有 cell if ((a = as[(n - 1) &amp; h]) == null) { // 为 cellsBusy 加锁, 创建 cell, cell 的初始累加值为 x // 成功则 break, 否则继续 continue 循环 } // 有竞争, 改变线程对应的 cell 来重试 cas else if (!wasUncontended) wasUncontended = true; // cas 尝试累加, fn 配合 LongAccumulator 不为 null, 配合 LongAdder 为 null else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; // 如果 cells 长度已经超过了最大长度, 或者已经扩容, 改变线程对应的 cell 来重试 cas else if (n &gt;= NCPU || cells != as) collide = false; // 确保 collide 为 false 进入此分支, 就不会进入下面的 else if 进行扩容了 else if (!collide) collide = true; // 加锁 else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) { // 加锁成功, 扩容 continue; } // 改变线程对应的 cell h = advanceProbe(h); } // 还没有 cells, 尝试给 cellsBusy 加锁 else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) { // 加锁成功, 初始化 cells, 最开始长度为 2, 并填充一个 cell // 成功则 break; } // 上两种情况失败, 尝试给 base 累加 else if (casBase(v = base, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; } } longAccumulate 流程图 每个线程刚进入 longAccumulate 时，会尝试对应一个 cell 对象（找到一个坑位） 获取最终结果通过 sum 方法 public long sum() { Cell[] as = cells; Cell a; long sum = base; if (as != null) { for (int i = 0; i &lt; as.length; ++i) { if ((a = as[i]) != null) sum += a.value; } } return sum; } UnsafeUnsafe 对象提供了非常底层的，操作内存、线程的方法，Unsafe 对象不能直接调用，只能通过反射获得 public class GetUnsafe { public static void main(String[] args) throws NoSuchMethodException, IllegalAccessException, InvocationTargetException, InstantiationException, NoSuchFieldException { // 通过反射获得Unsafe对象 Class unsafeClass = Unsafe.class; // 获得构造函数，Unsafe的构造函数为私有的 Constructor constructor = unsafeClass.getDeclaredConstructor(); // 设置为允许访问私有内容 constructor.setAccessible(true); // 创建Unsafe对象 Unsafe unsafe = (Unsafe) constructor.newInstance(); // 创建Person对象 Person person = new Person(); // 获得其属性 name 的偏移量 Field field = Person.class.getDeclaredField(\"name\"); long offset = unsafe.objectFieldOffset(field); // 通过unsafe的CAS操作改变值 unsafe.compareAndSwapObject(person, offset, null, \"Nyima\"); System.out.println(person); } } class Person { // 配合CAS操作，必须用volatile修饰 volatile String name; @Override public String toString() { return \"Person{\" + \"name='\" + name + '\\'' + '}'; } } 共享模型之不可变不可变如果一个对象在不能够修改其内部状态（属性），那么它就是线程安全的，因为不存在并发修改。 不可变设计String类中不可变的体现public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; /** Cache the hash code for the string */ private int hash; // Default to 0 //.... } } ﬁnal 的使用发现该类、类中所有属性都是 ﬁnal 的 属性用 ﬁnal 修饰保证了该属性是只读的，不能修改 类用 ﬁnal 修饰保证了该类中的方法不能被覆盖，防止子类无意间破坏不可变性 **保护性拷贝 **但有同学会说，使用字符串时，也有一些跟修改相关的方法啊，比如 substring 等，那么下面就看一看这些方法是 如何实现的，就以 substring 为例 public String substring(int beginIndex) { if (beginIndex &lt; 0) { throw new StringIndexOutOfBoundsException(beginIndex); } int subLen = value.length - beginIndex; if (subLen &lt; 0) { throw new StringIndexOutOfBoundsException(subLen); } //返回的是一个新的对象 return (beginIndex == 0) ? this : new String(value, beginIndex, subLen); } 发现其内部是调用 String 的构造方法创建了一个新字符串 public String(char value[], int offset, int count) { if (offset &lt; 0) { throw new StringIndexOutOfBoundsException(offset); } if (count &lt;= 0) { if (count &lt; 0) { throw new StringIndexOutOfBoundsException(count); } if (offset &lt;= value.length) { this.value = \"\".value; return; } } // Note: offset or count might be near -1&gt;&gt;&gt;1. if (offset &gt; value.length - count) { throw new StringIndexOutOfBoundsException(offset + count); } this.value = Arrays.copyOfRange(value, offset, offset+count); } 构造新字符串对象时，会生成新的 char[] value，对内容进行复制 。这种通过创建副本对象来避免共享的手段称之为【保护性拷贝（defensive copy）】 模式之享元简介定义 英文名称：Flyweight pattern. 当需要重用数量有限的同一类对象 体现包装类在JDK中 Boolean，Byte，Short，Integer，Long，Character 等包装类提供了 valueOf 方法，例如 Long 的 valueOf 会缓存 -128~127 之间的 Long 对象，在这个范围之间会重用对象，大于这个范围，才会新建 Long 对 象： public static Long valueOf(long l) { final int offset = 128; if (l &gt;= -128 &amp;&amp; l &lt;= 127) { // will cache return LongCache.cache[(int)l + offset]; } return new Long(l); } 注意： Byte, Short, Long 缓存的范围都是 -128~127 Character 缓存的范围是 0~127 Integer的默认范围是 -128~127 最小值不能变 但最大值可以通过调整虚拟机参数 -Djava.lang.Integer.IntegerCache.high 来改变 Boolean 缓存了 TRUE 和 FALSE String 串池可以参考jvm中的内容 共享模型之工具线程池自定义线程池 阻塞队列中维护了由主线程（或者其他线程）所产生的的任务 主线程类似于生产者，产生任务并放入阻塞队列中 线程池类似于消费者，得到阻塞队列中已有的任务并执行 代码实现public class Demo3 { public static void main(String[] args) { ThreadPool threadPool = new ThreadPool(2, TimeUnit.SECONDS, 1, 4); for (int i = 0; i &lt; 10; i++) { threadPool.execute(()-&gt;{ try { TimeUnit.SECONDS.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(\"任务正在执行!\"); }); } } } /** * 自定义线程池 */ class ThreadPool { /** * 自定义阻塞队列 */ private BlockingQueue&lt;Runnable&gt; blockingQueue; /** * 核心线程数 */ private int coreSize; private HashSet&lt;Worker&gt; workers = new HashSet&lt;&gt;(); /** * 用于指定线程最大存活时间 */ private TimeUnit timeUnit; private long timeout; /** * 工作线程类 * 内部封装了Thread类，并且添加了一些属性 */ private class Worker extends Thread { Runnable task; public Worker(Runnable task) { System.out.println(\"初始化任务\"); this.task = task; } @Override public void run() { // 如果有任务就执行 // 如果阻塞队列中有任务，就继续执行 while (task != null || (task = blockingQueue.take()) != null) { try { System.out.println(\"执行任务\"); task.run(); } catch (Exception e) { e.printStackTrace(); } finally { // 任务执行完毕，设为空 System.out.println(\"任务执行完毕\"); task = null; } } // 移除任务 synchronized (workers) { System.out.println(\"移除任务\"); workers.remove(this); } } } public ThreadPool(int coreSize, TimeUnit timeUnit, long timeout, int capacity) { this.coreSize = coreSize; this.timeUnit = timeUnit; blockingQueue = new BlockingQueue&lt;&gt;(capacity); this.timeout = timeout; } public void execute(Runnable task) { synchronized (workers) { // 创建任务 // 池中还有空余线程时，可以运行任务 // 否则阻塞 if (workers.size() &lt; coreSize) { Worker worker = new Worker(task); workers.add(worker); worker.start(); } else { System.out.println(\"线程池中线程已用完，请稍等\"); blockingQueue.put(task); } } } } /** * 阻塞队列 * 用于存放主线程或其他线程产生的任务 */ class BlockingQueue&lt;T&gt; { /** * 阻塞队列 */ private Deque&lt;T&gt; blockingQueue; /** * 阻塞队列容量 */ private int capacity; /** * 锁 */ private ReentrantLock lock; /** * 条件队列 */ private Condition fullQueue; private Condition emptyQueue; public BlockingQueue(int capacity) { blockingQueue = new ArrayDeque&lt;&gt;(capacity); lock = new ReentrantLock(); fullQueue = lock.newCondition(); emptyQueue = lock.newCondition(); this.capacity = capacity; } /** * 获取任务的方法 */ public T take() { // 加锁 lock.lock(); try { // 如果阻塞队列为空（没有任务），就一直等待 while (blockingQueue.isEmpty()) { try { emptyQueue.await(); } catch (InterruptedException e) { e.printStackTrace(); } } // 获取任务并唤醒生产者线程 T task = blockingQueue.removeFirst(); fullQueue.signalAll(); return task; } finally { lock.unlock(); } } public T takeNanos(long timeout, TimeUnit unit) { // 转换等待时间 lock.lock(); try { long nanos = unit.toNanos(timeout); while (blockingQueue.isEmpty()) { try { // awaitNanos会返回剩下的等待时间 nanos = emptyQueue.awaitNanos(nanos); if (nanos &lt; 0) { return null; } } catch (InterruptedException e) { e.printStackTrace(); } } T task = blockingQueue.removeFirst(); fullQueue.signalAll(); return task; } finally { lock.unlock(); } } /** * 放入任务的方法 * @param task 放入阻塞队列的任务 */ public void put(T task) { lock.lock(); try { while (blockingQueue.size() == capacity) { try { System.out.println(\"阻塞队列已满\"); fullQueue.await(); } catch (InterruptedException e) { e.printStackTrace(); } } blockingQueue.add(task); // 唤醒等待的消费者 emptyQueue.signalAll(); } finally { lock.unlock(); } } public int getSize() { lock.lock(); try { return blockingQueue.size(); } finally { lock.unlock(); } } } 实现了一个简单的线程池 阻塞队列BlockingQueue用于暂存来不及被线程执行的任务 也可以说是平衡生产者和消费者执行速度上的差异 里面的获取任务和放入任务用到了生产者消费者模式 线程池中对线程Thread进行了再次的封装，封装为了Worker 在调用任务的run方法时，线程会去执行该任务，执行完毕后还会到阻塞队列中获取新任务来执行 线程池中执行任务的主要方法为execute方法 执行时要判断正在执行的线程数是否大于了线程池容量 ThreadPoolExecutor继承关系图 线程池状态ThreadPoolExecutor 使用 int 的高 3 位来表示线程池状态，低 29 位表示线程数量 // 线程池状态 // runState is stored in the high-order bits // RUNNING 高3位为111 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; // SHUTDOWN 高3位为000 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; // 高3位 001 private static final int STOP = 1 &lt;&lt; COUNT_BITS; // 高3位 010 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; // 高3位 011 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; 状态名称 高3位的值 描述 RUNNING 111 接收新任务，同时处理任务队列中的任务 SHUTDOWN 000 不接受新任务，但是处理任务队列中的任务 STOP 001 中断正在执行的任务，同时抛弃阻塞队列中的任务 TIDYING 010 任务执行完毕，活动线程为0时，即将进入终结阶段 TERMINATED 011 终结状态 线程池状态和线程池中线程的数量由一个原子整型ctl来共同表示 使用一个数来表示两个值的主要原因是：可以通过一次CAS同时更改两个属性的值 // 原子整数，前3位保存了线程池的状态，剩余位保存的是线程数量 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); // 并不是所有平台的int都是32位。 // 去掉前三位保存线程状态的位数，剩下的用于保存线程数量 // 高3位为0，剩余位数全为1 private static final int COUNT_BITS = Integer.SIZE - 3; // 2^COUNT_BITS次方，表示可以保存的最大线程数 // CAPACITY 的高3位为 0 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; 获取线程池状态、线程数量以及合并两个值的操作 // Packing and unpacking ctl // 获取运行状态 // 该操作会让除高3位以外的数全部变为0 private static int runStateOf(int c) { return c &amp; ~CAPACITY; } // 获取运行线程数 // 该操作会让高3位为0 private static int workerCountOf(int c) { return c &amp; CAPACITY; } // 计算ctl新值 private static int ctlOf(int rs, int wc) { return rs | wc; } 线程池属性// 工作线程，内部封装了Thread private final class Worker extends AbstractQueuedSynchronizer implements Runnable { ... } // 阻塞队列，用于存放来不及被核心线程执行的任务 private final BlockingQueue&lt;Runnable&gt; workQueue; // 锁 private final ReentrantLock mainLock = new ReentrantLock(); // 用于存放核心线程的容器，只有当持有锁时才能够获取其中的元素（核心线程） private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); 构造方法极其参数ThreadPoolExecutor最全面的构造方法 也是构造自定义线程池的方法 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 参数解释 corePoolSize：核心线程数 maximumPoolSize：最大线程数 maximumPoolSize - corePoolSize = 救急线程数 keepAliveTime：救急线程空闲时的最大生存时间 unit：时间单位 workQueue：阻塞队列（存放任务） 有界阻塞队列 ArrayBlockingQueue 无界阻塞队列 LinkedBlockingQueue 最多只有一个同步元素的 SynchronousQueue 优先队列 PriorityBlockingQueue threadFactory：线程工厂（给线程取名字） handler：拒绝策略 工作方式 当一个任务传给线程池以后，可能有以下几种可能 将任务分配给一个核心线程来执行 核心线程都在执行任务，将任务放到阻塞队列workQueue中等待被执行 阻塞队列满了，使用救急线程来执行任务 救急线程用完以后，超过生存时间（keepAliveTime）后会被释放 任务总数大于了 最大线程数（maximumPoolSize）与阻塞队列容量的最大值（workQueue.capacity），使用拒接策略 拒绝策略如果线程到达 maximumPoolSize 仍然有新任务这时会执行拒绝策略。拒绝策略 jdk 提供了 4 种实现 AbortPolicy：让调用者抛出 RejectedExecutionException 异常，这是默认策略 CallerRunsPolicy：让调用者运行任务 DiscardPolicy：放弃本次任务 DiscardOldestPolicy：放弃队列中最早的任务，本任务取而代之 使用public class Demo1 { static AtomicInteger threadId = new AtomicInteger(0); public static void main(String[] args) { // 手动创建线程池 // 创建有界阻塞队列 ArrayBlockingQueue&lt;Runnable&gt; runnable = new ArrayBlockingQueue&lt;Runnable&gt;(10); // 创建线程工厂 ThreadFactory threadFactory = new ThreadFactory() { @Override public Thread newThread(Runnable r) { Thread thread = new Thread(r, \"working_thread_\"+threadId.getAndIncrement()); return thread; } }; // 手动创建线程池 // 拒绝策略采用默认策略 ThreadPoolExecutor executor = new ThreadPoolExecutor(5, 7, 10, TimeUnit.SECONDS, runnable, threadFactory); for (int i = 0; i &lt; 20; i++) { executor.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread()); try { Thread.sleep(100000); } catch (InterruptedException e) { e.printStackTrace(); } } }); } } } newFixedThreadPoolpublic static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); } 固定大小的线程池可以传入两个参数 核心线程数：nThreads 线程工厂：threadFactory 内部调用的构造方法 ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(), threadFactory); 特点 核心线程数 == 最大线程数（没有救急线程被创建），因此也无需超时时间 阻塞队列是无界的，可以放任意数量的任务 评价 适用于任务量已知，相对耗时的任务 newCachedThreadPoolpublic static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); } 内部构造方法 ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); 没有核心线程，最大线程数为Integer.MAX_VALUE，所有创建的线程都是救急线程，空闲时生存时间为60秒 阻塞队列使用的是SynchronousQueue SynchronousQueue 是一种特殊的队列 没有容量，没有线程来取是放不进去的 只有当线程取任务时，才会将任务放入该阻塞队列中 评价 整个线程池表现为线程数会根据任务量不断增长，没有上限，当任务执行完毕，空闲 1分钟后释放线 程。 适合任务数比较密集，但每个任务执行时间较短的情况 newSingleThreadExecutorpublic static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); } 内部构造方法 new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); 内部调用了new ThreadPoolExecutor的构造方法，传入的corePoolSize和maximumPoolSize都为1。然后将该对象传给了FinalizableDelegatedExecutorService。该类修饰了ThreadPoolExecutor，让外部无法调用ThreadPoolExecutor内部的某些方法来修改所创建的线程池的大小 newScheduledThreadPoolnewScheduledThreadPool是一个可以周期性执行任务的线程池 public ScheduledThreadPoolExecutor(int corePoolSize) { super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue()); } schedule：在指定的延迟后启用，任务立即提交给线程池，线程池安排线程在指定时间后正式开始运作，运作以后保持正常节奏 scheduleAtFixedRate：创建并执行一个周期性动作，该动作在给定的初始延迟后首先启用，随后在一个执行的终止与下一个开始的之间具有给定的延迟。如果任务的任何执行遇到异常，则将取消后续执行。 否则，该任务将仅通过取消或终止执行程序而终止 情况一：任务所需执行时间超过时间间隔的时候，实际下一次执行时间=任务实际执行时间。当执行任务的时间大于我们指定的间隔时间时，它并不会在指定间隔时开辟一个新的线程并发执行这个任务。而是等待该线程执行完毕。 情况二：任务所需执行时间为小于设置时间间隔的时候，实际下一次执行时间为设置的时间间隔 scheduleWithFixedDelay：创建并执行一个周期性动作，该动作在给定的初始延迟后首先启用，随后在一个执行的终止与下一个的开始之间具有的延迟。如果任务的任何执行遇到异常，则将取消后续执行。 否则，该任务将仅通过取消或终止执行程序而终止 实际下一次执行时间是任务所需执行时间+时间间隔 几个注意 newSingleThreadExecutor和自己创建一个线程来运行多个任务的区别 当线程正在执行的任务发生错误时，如果是自己创建的线程，该任务和剩余的任务就无法再继续运行下去。而newSingleThreadExecutor会创建一个新线程，继续执行任务队列中剩余的任务。 newSingleThreadExecutor和newFixedThreadPool(1)的区别 newFixedThreadPool(1)传值为1，可以将FixedThreadPool强转为ThreadPoolExecutor，然后通过setCorePoolSize改变核心线程数 // 强转为ThreadPoolExecutor ThreadPoolExecutor threadPool = (ThreadPoolExecutor) Executors.newFixedThreadPool(1); // 改变核心线程数 threadPool.setCorePoolSize(2); 而newSingleThreadExecutor无法修改核心线程数 执行任务execute()方法execute(Runnable command) 传入一个Runnable对象，执行其中的run方法 源码解析 public void execute(Runnable command) { if (command == null) throw new NullPointerException(); // 获取ctl int c = ctl.get(); // 判断当前启用的线程数是否小于核心线程数 if (workerCountOf(c) &lt; corePoolSize) { // 为该任务分配线程 if (addWorker(command, true)) // 分配成功就返回 return; // 分配失败再次获取ctl c = ctl.get(); } // 分配和信息线程失败以后 // 如果池状态为RUNNING并且插入到任务队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { // 双重检测，可能在添加后线程池状态变为了非RUNNING int recheck = ctl.get(); // 如果池状态为非RUNNING，则不会执行新来的任务 // 将该任务从阻塞队列中移除 if (! isRunning(recheck) &amp;&amp; remove(command)) // 调用拒绝策略，拒绝该任务的执行 reject(command); // 如果没有正在运行的线程 else if (workerCountOf(recheck) == 0) // 就创建新线程来执行该任务 addWorker(null, false); } // 如果添加失败了（任务队列已满），就调用拒绝策略 else if (!addWorker(command, false)) reject(command); } 其中调用了**addWoker()**方法，再看看看这个方法 private boolean addWorker(Runnable firstTask, boolean core) { retry: for (;;) { int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. // 如果池状态为非RUNNING状态、线程池为SHUTDOWN且该任务为空 或者阻塞队列中已经有任务 if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) // 创建新线程失败 return false; for (;;) { // 获得当前工作线程数 int wc = workerCountOf(c); // 参数中 core 为true // CAPACITY 为 1 &lt;&lt; COUNT_BITS-1，一般不会超过 // 如果工作线程数大于了核心线程数，则创建失败 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 通过CAS操作改变c的值 if (compareAndIncrementWorkerCount(c)) // 更改成功就跳出多重循环，且不再运行循环 break retry; // 更改失败，重新获取ctl的值 c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) // 跳出多重循环，且重新进入循环 continue retry; // else CAS failed due to workerCount change; retry inner loop } } // 用于标记work中的任务是否成功执行 boolean workerStarted = false; // 用于标记worker是否成功加入了线程池中 boolean workerAdded = false; Worker w = null; try { // 创建新线程来执行任务 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) { final ReentrantLock mainLock = this.mainLock; // 加锁 mainLock.lock(); try { // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. // 加锁的同时再次检测 // 避免在释放锁之前调用了shut down int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) { if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将线程添加到线程池中 workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; // 添加成功标志位变为true workerAdded = true; } } finally { mainLock.unlock(); } // 如果worker成功加入了线程池，就执行其中的任务 if (workerAdded) { t.start(); // 启动成功 workerStarted = true; } } } finally { // 如果执行失败 if (! workerStarted) // 调用添加失败的函数 addWorkerFailed(w); } return workerStarted; } submit()方法Future&lt;T&gt; submit(Callable&lt;T&gt; task) 传入一个Callable对象，用Future来捕获返回值 使用 // 通过submit执行Callable中的call方法 // 通过Future来捕获返回值 Future&lt;String&gt; future = threadPool.submit(new Callable&lt;String&gt;() { @Override public String call() throws Exception { return \"hello submit\"; } }); // 查看捕获的返回值 System.out.println(future.get()); 提交任务// 提交 tasks 中所有任务 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)throws InterruptedException; // 提交 tasks 中所有任务，带超时时间 &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,long timeout, TimeUnit unit) throws InterruptedException; // 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; // 提交 tasks 中所有任务，哪个任务先成功执行完毕，返回此任务执行结果，其它任务取消，带超时时间 &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 关闭线程池shutdown()/* 线程池状态变为 SHUTDOWN - 不会接收新任务 - 但已提交任务会执行完 - 此方法不会阻塞调用线程的执行 */ void shutdown(); /** * 将线程池的状态改为 SHUTDOWN * 不再接受新任务，但是会将阻塞队列中的任务执行完 */ public void shutdown() { final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 修改线程池状态为 SHUTDOWN advanceRunState(SHUTDOWN); // 中断空闲线程（没有执行任务的线程） // Idle：空闲的 interruptIdleWorkers(); onShutdown(); // hook for ScheduledThreadPoolExecutor } finally { mainLock.unlock(); } // 尝试终结，不一定成功 // tryTerminate(); } final void tryTerminate() { for (;;) { int c = ctl.get(); // 终结失败的条件 // 线程池状态为RUNNING // 线程池状态为 RUNNING SHUTDOWN STOP （状态值大于TIDYING） // 线程池状态为SHUTDOWN，但阻塞队列中还有任务等待执行 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) return; // 如果活跃线程数不为0 if (workerCountOf(c) != 0) { // Eligible to terminate // 中断空闲线程 interruptIdleWorkers(ONLY_ONE); return; } final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { // 处于可以终结的状态 // 通过CAS将线程池状态改为TIDYING if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) { try { terminated(); } finally { // 通过CAS将线程池状态改为TERMINATED ctl.set(ctlOf(TERMINATED, 0)); termination.signalAll(); } return; } } finally { mainLock.unlock(); } // else retry on failed CAS } } shutdownNow()/* 线程池状态变为 STOP - 不会接收新任务 - 会将队列中的任务返回 - 并用 interrupt 的方式中断正在执行的任务 */ List&lt;Runnable&gt; shutdownNow(); /** * 将线程池的状态改为 STOP * 不再接受新任务，也不会在执行阻塞队列中的任务 * 会将阻塞队列中未执行的任务返回给调用者 */ public List&lt;Runnable&gt; shutdownNow() { List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try { checkShutdownAccess(); // 修改状态为STOP，不执行任何任务 advanceRunState(STOP); // 中断所有线程 interruptWorkers(); // 将未执行的任务从队列中移除，然后返回给调用者 tasks = drainQueue(); } finally { mainLock.unlock(); } // 尝试终结，一定会成功，因为阻塞队列为空了 tryTerminate(); return tasks; } 其它方法// 不在 RUNNING 状态的线程池，此方法就返回 true boolean isShutdown(); // 线程池状态是否是 TERMINATED boolean isTerminated(); // 调用 shutdown 后，由于调用线程并不会等待所有任务运行结束，因此如果它想在线程池 TERMINATED 后做些事情，可以利用此方法等待 boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; 任务调度线程池在『任务调度线程池』功能加入之前，可以使用 java.util.Timer 来实现定时功能，Timer 的优点在于简单易用，但由于所有任务都是由同一个线程来调度，因此所有任务都是串行执行的，同一时间只能有一个任务在执行，前一个任务的延迟或异常都将会影响到之后的任务。 正确处理执行任务异常方法1：主动捉异常 例如： ExecutorService pool = Executors.newFixedThreadPool(1); pool.submit(() -&gt; { try { log.debug(\"task1\"); int i = 1 / 0; } catch (Exception e) { log.error(\"error:\", e); } }); 方法2：使用 Future ExecutorService pool = Executors.newFixedThreadPool(1); Future&lt;Boolean&gt; f = pool.submit(() -&gt; { log.debug(\"task1\"); int i = 1 / 0; return true; }); log.debug(\"result:{}\", f.get()); Tomcat 线程池Tomcat 在哪里用到了线程池呢 LimitLatch 用来限流，可以控制最大连接个数，类似 J.U.C 中的 Semaphore 后面再讲 Acceptor 只负责【接收新的 socket 连接】 Poller 只负责监听 socket channel 是否有【可读的 I/O 事件】 一旦可读，封装一个任务对象（socketProcessor），提交给 Executor 线程池处理 Executor 线程池中的工作线程最终负责【处理请求】 Tomcat 线程池扩展了 ThreadPoolExecutor，行为稍有不同 如果总线程数达到 maximumPoolSize 这时不会立刻抛 RejectedExecutionException 异常 而是再次尝试将任务放入队列，如果还失败，才抛出 RejectedExecutionException 异常 Connector 配置 配置项 默认值 说明 acceptorThreadCount 1 acceptor 线程数量 pollerThreadCount 1 poller 线程数量 minSpareThreads 10 核心线程数，即 corePoolSize maxThreads 200 最大线程数，即 maximumPoolSize executor - Executor名称，用来引用下面的 Executor Executor 线程配置 配置项 默认值 说明 threadPriority 5 线程优先级 daemon true 是否守护线程 minSpareThreads 25 核心线程数，即 corePoolSize maxThreads 200 最大线程数，即 maximumPoolSize maxIdleTime 60000 线程生存时间，单位是毫秒，默认值即 1 分钟 maxQueueSize Integer.MAX_VALUE 队列长度 prestartminSpareThreads false 核心线程是否在服务器启动时启动 Fork/Join概念Fork/Join 是 JDK 1.7 加入的新的线程池实现，它体现的是一种分治思想，适用于能够进行任务拆分的 cpu 密集型 运算 所谓的任务拆分，是将一个大任务拆分为算法上相同的小任务，直至不能拆分可以直接求解。跟递归相关的一些计算，如归并排序、斐波那契数列、都可以用分治思想进行求解 Fork/Join 在分治的基础上加入了多线程，可以把每个任务的分解和合并交给不同的线程来完成，进一步提升了运算效率 Fork/Join 默认会创建与 cpu 核心数大小相同的线程池 使用提交给 Fork/Join 线程池的任务需要继承 RecursiveTask（有返回值）或 RecursiveAction（没有返回值） 异步模式之工作线程定义让有限的工作线程（Worker Thread）来轮流异步处理无限多的任务。也可以将其归类为分工模式，它的典型实现 就是线程池，也体现了经典设计模式中的享元模式。 注意，不同任务类型应该使用不同的线程池，这样能够避免饥饿，并能提升效率 饥饿 固定大小线程池会有饥饿现象 两个工人是同一个线程池中的两个线程 他们要做的事情是：为客人点餐和到后厨做菜，这是两个阶段的工作 客人点餐：必须先点完餐，等菜做好，上菜，在此期间处理点餐的工人必须等待 后厨做菜：没啥说的，做就是了 比如工人A 处理了点餐任务，接下来它要等着 工人B 把菜做好，然后上菜，他俩也配合的蛮好 但现在同时来了两个客人，这个时候工人A 和工人B 都去处理点餐了，这时没人做饭了，饥饿 解决方法可以增加线程池的大小，不过不是根本解决方案，还是前面提到的，不同的任务类型，采用不同的线程池 创建多少线程池合适 过小会导致程序不能充分地利用系统资源、容易导致饥饿 过大会导致更多的线程上下文切换，占用更多内存 CPU 密集型运算通常采用 cpu 核数 + 1 能够实现最优的 CPU 利用率，+1 是保证当线程由于页缺失故障（操作系统）或其它原因 导致暂停时，额外的这个线程就能顶上去，保证 CPU 时钟周期不被浪费 I/O 密集型运算CPU 不总是处于繁忙状态，例如，当你执行业务计算时，这时候会使用 CPU 资源，但当你执行 I/O 操作时、远程 RPC 调用时，包括进行数据库操作时，这时候 CPU 就闲下来了，你可以利用多线程提高它的利用率。 经验公式如下 线程数 = 核数 * 期望 CPU 利用率 * 总时间(CPU计算时间+等待时间) / CPU 计算时间 例如 4 核 CPU 计算时间是 50% ，其它等待时间是 50%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 50% = 8 例如 4 核 CPU 计算时间是 10% ，其它等待时间是 90%，期望 cpu 被 100% 利用，套用公式 4 * 100% * 100% / 10% = 40 J.U.CAQS 原理概述全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架 特点： 用 state 属性来表示资源的状态（分独占模式和共享模式），子类需要定义如何维护这个状态，控制如何获取锁和释放锁 getState - 获取 state 状态 setState - 设置 state 状态 compareAndSetState - cas 机制设置 state 状态 独占模式是只有一个线程能够访问资源，而共享模式可以允许多个线程访问资源 提供了基于 FIFO 的等待队列，类似于 Monitor 的 EntryList 条件变量来实现等待、唤醒机制，支持多个条件变量，类似于 Monitor 的 WaitSet 子类主要实现这样一些方法（默认抛出 UnsupportedOperationException） tryAcquire tryRelease tryAcquireShared tryReleaseShared isHeldExclusively 获取锁的姿势 // 如果获取锁失败 if (!tryAcquire(arg)) { // 入队, 可以选择阻塞当前线程 park unpark } 释放锁的姿势 // 如果释放锁成功 if (tryRelease(arg)) { // 让阻塞线程恢复运行 } 相关知识起源 早期程序员会自己通过一种同步器去实现另一种相近的同步器，例如用可重入锁去实现信号量，或反之。这显然不 够优雅，于是在 JSR166（java 规范提案）中创建了 AQS，提供了这种通用的同步器机制。 目标 AQS 要实现的功能目标 阻塞版本获取锁 acquire 和非阻塞的版本尝试获取锁 tryAcquire 获取锁超时机制 通过打断取消机制 独占机制及共享机制 条件不满足时的等待机制 设计 AQS 的基本思想其实很简单 获取锁的逻辑 while(state 状态不允许获取) { if(队列中还没有此线程) { 入队并阻塞 } } 当前线程出队 释放锁的逻辑 if(state 状态允许了) { 恢复阻塞的线程(s) } 要点 原子维护 state 状态 阻塞及恢复线程 维护队列 1) state 设计 state 使用 volatile 配合 cas 保证其修改时的原子性 state 使用了 32bit int 来维护同步状态，因为当时使用 long 在很多平台下测试的结果并不理想 2) 阻塞恢复设计 早期的控制线程暂停和恢复的 api 有 suspend 和 resume，但它们是不可用的，因为如果先调用的 resume 那么 suspend 将感知不到 解决方法是使用 park &amp; unpark 来实现线程的暂停和恢复，具体原理在之前讲过了，先 unpark 再 park 也没问题 park &amp; unpark 是针对线程的，而不是针对同步器的，因此控制粒度更为精细 park 线程还可以通过 interrupt 打断 3) 队列设计 使用了 FIFO 先入先出队列，并不支持优先级队列 设计时借鉴了 CLH 队列，它是一种单向无锁队列","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"JUC","slug":"笔记/JUC","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/JUC/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://mjean.life/tags/JUC/"},{"name":"Java并发编程","slug":"Java并发编程","permalink":"http://mjean.life/tags/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"JVM","slug":"jvm","date":"2021-07-03T16:50:26.000Z","updated":"2022-04-18T12:48:45.845Z","comments":true,"path":"posts/66c016fb.html","link":"","permalink":"http://mjean.life/posts/66c016fb.html","excerpt":"","text":"前言本次学习是从【黑马程序员出品】的解密JVM教程视频中进行的。视频地址 什么是JVM定义 Java Virtual Machine(JVM)，JAVA程序的运行环境（JAVA二进制字节码的运行环境）。 好处 一次编写，到处运行 自动内存管理，垃圾回收机制 数组下标越界检查 比较 JVM、JRE、JDK的区别！ 内存结构 整体架构！ 程序计数器 Program Counter Register 程序计数器（寄存器）。 作用用于保存JVM中下一条所要执行的指令的地址。 特点 线程私有 CPU会为每个线程分配时间片，当当前线程的时间片使用完以后，CPU就会去执行另一个线程中的代码 程序计数器是每个线程所私有的，当另一个线程的时间片用完，又返回来执行当前线程的代码时，通过程序计数器可以知道应该执行哪一句指令 不会存在内存溢出 虚拟机栈 Java Virtual Machine Stacks （Java 虚拟机栈） 每个线程运行需要的内存空间，称为虚拟机栈 每个栈由多个栈帧组成，对应着每次调用方法时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的方法 问题辨析 垃圾回收是否涉及栈内存？ 不需要。因为虚拟机栈中是由一个个栈帧组成的，在方法执行完毕后，对应的栈帧就会被弹出栈。所以无需通过垃圾回收机制去回收内存。 栈内存分配越大越好吗？ 不是。因为物理内存是一定的，栈内存越大，可以支持更多的递归调用，但是可执行的线程数就会越少。 方法内的局部变量是否线程安全？ 1、如果方法内局部变量没有逃离方法的作用范围，它是线程安全的 2、如果是局部变量引用了对象，并逃离方法的作用范围，需要考虑线程安全 内存溢出 Java.lang.stackOverflowError（ 栈内存溢出） 发生原因 虚拟机栈中，栈帧过多（无限递归） 每个栈帧所占用过大 线程运行诊断CPU占用过高 Linux环境下运行某些程序的时候，可能导致CPU的占用过高，这时需要定位占用CPU过高的线程 top命令，查看是哪个进程占用CPU过高 ps H -eo pid, tid（线程id）, %cpu | grep 进程id (通过ps命令进一步查看是哪个线程占用CPU过高) jstack 进程id 可以根据线程id找到有问题的线程，进一步定位到问题代码的源码行号（注意jstack查找出的线程id是16进制的，需要转换） 本地方法栈 一些带有native关键字的方法就是需要JAVA去调用本地的C或者C++方法，因为JAVA有时候没法直接和操作系统底层交互，所以需要用到本地方法。 堆 通过new关键字创建的对象都会被放在堆内存。 特点 所有线程共享，堆内存中的对象都需要考虑线程安全问题 有垃圾回收机制 堆内存溢出 java.lang.OutofMemoryError ：java heap space. （堆内存溢出） 堆内存诊断 jps：查看当前系统中有哪些java进程 jmap：查看堆内存占用情况 jmap -heap 进程id jconsole：图形界面的，多功能的监测工具，可以连续监测 JVisulVM：可视化的JVM监控工具 方法区结构 内存溢出 1.8以前会导致永久代内存溢出 1.8以后会导致元空间内存溢出 常量池 二进制字节码的组成：类的基本信息、常量池、类的方法定义（包含了虚拟机指令） 通过反编译来查看类的信息 获得对应类的.class文件 javac .java文件 在控制台输入 javap -v 类的绝对路径 javap -v 类的绝对路径 然后能在控制台看到反编译以后类的信息了 运行时常量池 常量池，就是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等信息 运行时常量池，常量池是 .class 文件中的，当该类被加载，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实地址 常量池与串池的关系StringTable（串池）特性： 常量池中的字符串仅是符号，第一次用到时才变为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是 StringBuilder （1.8） 字符串常量拼接的原理是编译器优化 可以使用 intern 方法，主动将串池中还没有的字符串对象放入串池 1.8 将这个字符串对象尝试放入串池，如果有则并不会放入，如果没有则放入串池， 会把串池中的对象返回 1.6 将这个字符串对象尝试放入串池，如果有则并不会放入，如果没有会把此对象复制一份， 放入串池， 会把串池中的对象返回 例1：用来放字符串对象且里面的元素不重复 &gt;public class StringTableStudy{ &gt;public static void main(String[] args) { String a = \"a\"; String b = \"b\"; String ab = \"ab\"; } &gt;} 常量池中的信息，都会被加载到运行时常量池中，但这是a、 b、 ab 仅是常量池中的符号，还没有成为java字符串 &gt;0: ldc #2 // String a &gt;2: astore_1 &gt;3: ldc #3 // String b &gt;5: astore_2 &gt;6: ldc #4 // String ab &gt;8: astore_3 &gt;9: return 当执行到 ldc #2 时，会把符号 a 变为 “a” 字符串对象，并放入串池中（hashtable结构 不可扩容） 当执行到 ldc #3 时，会把符号 b 变为 “b” 字符串对象，并放入串池中 当执行到 ldc #4 时，会把符号 ab 变为 “ab” 字符串对象，并放入串池 最终StringTable [“a”, “b”, “ab”] 注意：字符串对象的创建都是懒惰的，只有当运行到那一行字符串且在串池中不存在的时候（如 ldc #2）时，该字符串才会被创建并放入串池中。 例2：使用拼接字符串变量对象创建字符串的过程 public class StringTableStudy { public static void main(String[] args) { String a = \"a\"; String b = \"b\"; String ab = \"ab\"; //拼接字符串对象来创建新的字符串 String c = a+b; } } 反编译后如下： Code: stack=2, locals=5, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String ;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String ;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/Str ing; 27: astore 4 29: return 通过拼接的方式来创建字符串的过程是：StringBuilder().append(“a”).append(“b”).toString() 最后的toString方法的返回值是一个新的字符串，但字符串的值和拼接的字符串一致，但是两个不同的字符串，一个存在于串池之中，一个存在于堆内存之中 String ab = \"ab\"; String c = a+b; //结果为false,因为ab是存在于串池之中，c是由StringBuffer的toString方法所返回的一个对象，存在于堆内存之中 System.out.println(ab == ab2); //false 例3：使用拼接字符串常量对象的方法创建字符串 public class StringTableStudy { public static void main(String[] args) { String a = \"a\"; String b = \"b\"; String ab = \"ab\"; String c = a+b; //使用拼接字符串的方法创建字符串 String ab2 = \"a\" + \"b\"; } } 反编译后如下： Code: stack=2, locals=6, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String ;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String ;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/Str ing; 27: astore 4 //ab2初始化时直接从串池中获取字符串 29: ldc #4 // String ab 31: astore 5 33: return 使用拼接字符串常量的方法来创建新的字符串时，因为内容是常量，javac在编译期会进行优化，结果已在编译期确定为ab，而创建ab的时候已经在串池中放入了“ab”，所以ab2直接从串池中获取值，所以进行的操作和 ab = “ab” 一致。 使用拼接字符串变量的方法来创建新的字符串时，因为内容是变量，只能在运行期确定它的值，所以需要使用StringBuilder来创建 intern方法 1.8调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，则放入成功 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 注意：此时如果调用intern方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象 例1： public class StringTableStudy { public static void main(String[] args) { //\"a\" \"b\" 被放入串池中，str则存在于堆内存之中 String str = new String(\"a\") + new String(\"b\"); //调用str的intern方法，这时串池中没有\"ab\"，则会将该字符串对象放入到串池中，此时堆内存与串池中的\"ab\"是同一个对象 String st2 = str.intern(); //给str3赋值，因为此时串池中已有\"ab\"，则直接将串池中的内容返回 String str3 = \"ab\"; //因为堆内存与串池中的\"ab\"是同一个对象，所以以下两条语句打印的都为true System.out.println(str == st2); System.out.println(str == str3); } } 例2： public class StringTableStudy { public static void main(String[] args) { //此处创建字符串对象\"ab\"，因为串池中还没有\"ab\"，所以将其放入串池中 String str3 = \"ab\"; //\"a\" \"b\" 被放入串池中，str则存在于堆内存之中 String str = new String(\"a\") + new String(\"b\"); //此时因为在创建str3时，\"ab\"已存在与串池中，所以放入失败，但是会返回串池中的\"ab\" String str2 = str.intern(); //false System.out.println(str == str2); //false System.out.println(str == str3); //true System.out.println(str2 == str3); } } intern方法 1.6调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，会将该字符串对象复制一份，再放入到串池中 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 注意：此时无论调用intern方法成功与否，串池中的字符串对象和堆内存中的字符串对象都不是同一个对象 StringTable 垃圾回收 StringTable在内存紧张时，会发生垃圾回收 StringTable调优 因为StringTable是由HashTable实现的，所以可以适当增加HashTable桶的个数，来减少字符串放入串池所需要的时间 -XX:StringTableSize=xxxx 考虑是否需要将字符串对象入池 可以通过intern方法减少重复入池 直接内存 Direct Memory 常见于 NIO 操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不受 JVM 内存回收管理 文件读写流程 使用了DirectBuffer 直接内存是操作系统和Java代码都可以访问的一块区域，无需将代码从系统内存复制到Java堆内存，从而提高了效率 释放原理直接内存的回收不是通过JVM的垃圾回收来释放的，而是通过unsafe.freeMemory来手动释放 示例 申请直接内存 //通过ByteBuffer申请1M的直接内存 ByteBuffer byteBuffer = ByteBuffer.allocateDirect(_1M); allocateDirect的实现 public static ByteBuffer allocateDirect(int capacity) { return new DirectByteBuffer(capacity); } DirectByteBuffer类 DirectByteBuffer(int cap) { // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try { base = unsafe.allocateMemory(size); //申请内存 } catch (OutOfMemoryError x) { Bits.unreserveMemory(size, cap); throw x; } unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) { // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); } else { address = base; } cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); //通过虚引用，来实现直接内存的释放，this为虚引用的实际对象 att = null; } 这里调用了一个Cleaner的create方法，且后台线程还会对虚引用的对象监测，如果虚引用的实际对象（这里是DirectByteBuffer）被回收以后，就会调用Cleaner的clean方法，来清除直接内存中占用的内存 public void clean() { if (remove(this)) { try { this.thunk.run(); //调用run方法 } catch (final Throwable var2) { AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() { public Void run() { if (System.err != null) { (new Error(\"Cleaner terminated abnormally\", var2)).printStackTrace(); } System.exit(1); return null; } }); } 对应对象的run方法 public void run() { if (address == 0) { // Paranoia return; } unsafe.freeMemory(address); //释放直接内存中占用的内存 address = 0; Bits.unreserveMemory(size, capacity); } 直接内存的回收机制总结 使用了 Unsafe 对象完成直接内存的分配回收，并且回收需要主动调用 freeMemory 方法 ByteBuffer 的实现类内部，使用了 Cleaner（虚引用)来监测 ByteBuffer 对象，一旦 ByteBuffer 对象被垃圾回收，那么就会由 ReferenceHandler 线程通过 Cleaner 的 clean 方法调用 freeMemory 来释放直接内存 垃圾回收如何判断对象是否可以回收引用计数法弊端：循环引用时，两个对象的计数都为1，导致两个对象都无法被释放 可达性分析算法 Java 虚拟机中的垃圾回收器采用可达性分析来探索所有存活的对象 扫描堆中的对象，看是否能够沿着 GC Root对象 为起点的引用链找到该对象，如果找不到，表示可以回收 哪些对象可以作为 GC Root ? 虚拟机栈（栈帧中的本地变量表）中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 五种引用 强引用(StrongReference) 只有所有 GC Roots 对象都不通过【强引用】引用该对象，该对象才能被垃圾回收 如上图，只有B、C对象都不引用A1对象时，A1对象才会被回收 软引用(SoftReference) 仅有软引用引用该对象时，在垃圾回收后，内存仍不足时会再次触发垃圾回收，回收软引用所引用的对象 如上图，如果B对象不再引用A2对象且内存不足时，软引用所引用的A2对象就会被回收 可以配合引用队列来释放软引用自身 软引用的使用 public class Demo { public static void main(String[] args) { final int _4M = 4*1024*1024; //使用软引用对象 list对SoftReference是强引用，而SoftReference对byte数组则是软引用 List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); SoftReference&lt;byte[]&gt; ref= new SoftReference&lt;&gt;(new byte[_4M]); } } 如果在垃圾回收时发现内存不足，在回收软引用所指向的对象时，软引用本身不会被清理 如果想要清理软引用，需要使用引用队列 public class Demo1 { public static void main(String[] args) { final int _4M = 4*1024*1024; //使用引用队列，用于移除引用为空的软引用对象 ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); //使用软引用对象 list对SoftReference是强引用，而SoftReference对byte数组则是软引用 List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); SoftReference&lt;byte[]&gt; ref= new SoftReference&lt;&gt;(new byte[_4M]); //遍历引用队列，如果有元素，则移除 Reference&lt;? extends byte[]&gt; poll = queue.poll(); while(poll != null) { //引用队列不为空，则从集合中移除该元素 list.remove(poll); //移动到引用队列中的下一个元素 poll = queue.poll(); } } } 思路：查看引用队列中有无软引用，如果有，则将该软引用从存放它的集合中移除（这里为一个list集合） 弱引用 仅有弱引用引用该对象时，在垃圾回收时，无论内存是否充足，都会回收弱引用对象 如上图，如果B对象不再引用A3对象，则A3对象会被回收 可以配合引用队列来释放弱引用自身 虚引用 必须配合引用队列使用，主要配合 ByteBuffer 使用 当虚引用所引用得对象被回收后，虚引用就会被放入引用队列中， 由 Reference Handler 线程调用虚引用相关方法释放直接内存 1）虚引用的一个体现是释放直接内存所分配的内存，当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存 2）如上图，如果B对象不再引用ByteBuffer对象，ByteBuffer就会被回收。但是直接内存中的内存还未被回收。这时需要将虚引用对象Cleaner放入引用队列中，然后调用它的clean方法来释放直接内存 终结器引用 所有的类都继承自Object类，Object类有一个finalize方法 无需手动编码，但其内部配合引用队列使用 当某个对象不再被其他的对象所引用时，在垃圾回收时，会先将终结器引用放入引用队列中，然后根据终结器引用对象找到它所引用的对象，然后调用该对象的finalize方法。调用以后，第二次 GC时，该对象就可以被垃圾回收了 如上图，B对象不再引用A4对象，在垃圾回收时，终结器引用被放入引用队列（被终结器引用所引用的对象暂时没有被回收），再由 Finalizer 线程通过终结器引用找到被引用对象并调用它的 finalize 方法，第二次 GC 时才能回收被引用对象 引用队列 软引用和弱引用可以配合引用队列 在弱引用和虚引用所引用的对象被回收以后，会将这些引用放入引用队列中，方便一起回收这些软/弱引用对象 虚引用和终结器引用必须配合引用队列 虚引用和终结器引用在使用时会关联一个引用队列 垃圾回收算法标记 - 清除 定义： Mark Sweep 速度较快 定义：标记清除算法顾名思义，是指在虚拟机执行垃圾回收的过程中，先采用标记算法确定可回收对象，然后垃圾收集器根据标识清除相应的内容，给堆内存腾出相应的空间 这里的腾出内存空间并不是将内存空间的字节清零，而是记录下这段内存的起始结束地址，下次分配内存的时候，会直接覆盖这段内存 缺点：容易产生大量的内存碎片，可能无法满足大对象的内存分配，一旦导致无法分配对象，那就会导致jvm启动gc，一旦启动gc，我们的应用程序就会暂停，这就导致应用的响应速度变慢 标记 - 整理 定义：Mark Compact 速度慢 标记-整理 会将不被GC Root引用的对象回收，清楚其占用的内存空间。然后整理剩余的对象，可以有效避免因内存碎片而导致的问题，但是因为整体需要消耗一定的时间，所以效率较低 复制 将内存分为等大小的两个区域，FROM和TO（TO中为空）。先将被GC Root引用的对象从FROM放入TO中，再回收不被GC Root引用的对象。然后交换FROM和TO。这样也可以避免内存碎片的问题，但是会占用双倍的内存空间 分代回收 对象首先分配在伊甸园(Eden)区域 新生代空间不足时，触发 minor gc，伊甸园和 from 存活的对象使用 copy 复制到 to 中，存活的对象年龄加 1并且交换 from to minor gc 会引发 stop the world(STW)，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行 当对象寿命超过阈值时，会晋升至老年代，最大寿命是15（4bit） 当老年代空间不足，会先尝试触发 minor gc，如果之后空间仍不足，那么触发 full gc，STW的时间更长 回收流程 新创建的对象都被放在了新生代的伊甸园中 当伊甸园中的内存不足时，就会进行一次垃圾回收，这时的回收叫做 Minor GC Minor GC 会将伊甸园和幸存区FROM存活的对象先复制到 幸存区 TO中， 并让其寿命加1，再交换两个幸存区 再次创建对象，若新生代的伊甸园又满了，则会再次触发 Minor GC（会触发 stop the world， 暂停其他用户线程，只让垃圾回收线程工作），这时不仅会回收伊甸园中的垃圾，还会回收幸存区中的垃圾，再将活跃对象复制到幸存区TO中。回收以后会交换两个幸存区，并让幸存区中的对象寿命加1 如果幸存区中的对象的寿命超过某个阈值（最大为15，4bit），就会被放入老年代中 如果新生代老年代中的内存都满了，就会先触发Minor GC，再触发Full GC，扫描新生代和老年代中所有不再使用的对象并回收 GC 分析大对象处理策略当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代 线程内存溢出某个线程的内存溢出了而抛异常（out of memory），不会让其他的线程结束运行 这是因为当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行，进程依然正常 垃圾回收器 并行收集：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 并发收集：指用户线程与垃圾收集线程同时工作（不一定是并行的可能会交替执行）,用户程序在继续运行 吞吐量：即CPU用于运行用户代码的时间与CPU总消耗时间的比值（吞吐量 = 运行用户代码时间 / ( 运行用户代码时间 + 垃圾收集时间 )），也就是。例如：虚拟机共运行100分钟，垃圾收集器花掉1分钟，那么吞吐量就是99% 串行 单线程 内存较小，适合个人电脑（CPU核数少） 安全点：让其他线程都在这个点停下来，以免垃圾回收时改变的对象的地址被改变导致其他线程找不到被改变的对象。因为是串行的，所以只有一个垃圾回收线程。且在该线程执行回收工作时，其他线程进入阻塞状态 Serial 垃圾收集器Serial收集器是最基本的、发展历史最悠久的收集器；主要用于新生代。 特点：单线程、简单高效（与其他收集器的单线程相比），采用复制算法。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程收集效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程，直到它结束（Stop The World） ParNew 垃圾收集器ParNew收集器（Par就是Parallel的缩写 New 指的是新生代）就是Serial收集器的多线程版本 特点：多线程、ParNew收集器默认开启的收集线程数与CPU的数量相同，在CPU非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。和Serial收集器一样存在Stop The World问题 Serial Old 垃圾收集器Serial Old是Serial收集器的老年代版本 特点：同样是单线程收集器，采用标记-整理算法 吞吐量优先 多线程 堆内存较大，多核CPU 单位时间内，STW（stop the world，停掉其他所有工作线程）时间最短 JDK1.8默认使用的垃圾回收器 Parallel Scavenge 收集器与吞吐量关系密切，故也称为吞吐量优先收集器 特点：属于新生代收集器也是采用复制算法的收集器（用到了新生代的幸存区），又是并行的多线程收集器（与ParNew收集器类似） 该收集器的目标是达到一个可控制的吞吐量。还有一个值得关注的点是：GC自适应调节策略，例如 -XX:+UseAdaptiveSizePolicy 可以动态调整新生代的大小（-XMn）、Eden与Survivor区的比例（—XX:SurvivorRation）等等。（与ParNew收集器最重要的一个区别） 相关参数 -XX:+UseParallelGC ~ -XX:+UseParallelOldGC -XX:+UseParallelGC：告诉JVM使用多线程并行执行年轻代垃圾收集 -XX:+UseParallelOldGC：Old 指的是老年代 ，激活了年老代并行垃圾收集 -XX:+UseAdaptiveSizePolicy 根据GC的情况自动计算 Eden、From 和 To 区的大小；然后动态的进行调整 -XX:GCTimeRatio=ratio 告诉JVM吞吐量要达到的目标值。例如：-XX:GCTimeRatio=N指定目标应用程序线程的执行时间(与总的程序执行时间)达到N/(N+1)的目标比值，-XX:GCTimeRatio的默认值是99，也就是说，应用程序线程应该运行至少99%的总执行时间。 -XX:MaxGCPauseMillis=ms 告诉JVM最大暂停时间的目标值(以毫秒为单位) -XX:ParallelGCThreads=n 指定并行垃圾收集的线程数量 Parallel Old 收集器 是Parallel Scavenge收集器的老年代版本 特点：多线程，采用标记-整理算法（老年代没有幸存区） 响应时间优先 多线程 堆内存较大，多核CPU 尽可能让单次STW时间变短（尽量不影响其他线程运行） CMS 收集器 Concurrent Mark Sweep，一种以获取最短回收停顿时间为目标的针对老年代的收集器 特点 基于标记-清除算法实现，会产生内存碎片 以获取最短回收停顿时间为目标 并发收集、低停顿 需要更多的内存 应用场景：适用于注重服务的响应速度，希望系统停顿时间最短，给用户带来更好的体验等场景下。如web程序、b/s服务 CMS收集器的运行过程分为下列4步： 初始标记：仅标记GC Roots能直接关联到的对象。速度很快，但需要Stop The World 并发标记：进行GC Roots Tracing 的过程，找出存活对象（并不能保证可以标记出所有的存活对象）且用户线程可并发执行 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。仍然需要Stop The World，且停顿时间比初始标记稍长，但远比并发标记短 并发清除：回收所有的垃圾对象 CMS收集器的内存回收过程是与用户线程一起并发执行的 缺点 对CPU资源非常敏感：并发收集虽然不会暂停用户线程，但因为占用一部分CPU资源，还是会影响应用程序的性能。CMS的默认收集线程数量是=（CPU数量 + 3)/4：当CPU数量多于4个，收集线程占用的CPU资源多于25%，对用户程序影响可能较大；不足4个时，影响更大，可能无法接受 无法处理浮动垃圾,可能出现”Concurrent Mode Failure“失败：在并发标记时，用户线程新产生的垃圾 ，称为浮动垃圾； 如果CMS预留内存空间无法满足程序需要，就会出现一次”Concurrent Mode Failure”失败；这时， JVM启用后备预案：临时启用Serail Old收集器，而导致另一次Full GC的产生；这样的代价是很大的，所以CMSInitiatingOccupancyFraction不能设置得太大 产生大量内存碎片：由于 CMS基于”标记-清除”算法，清除后不进行压缩操作 G1 (Garbage First) JDK 9以后默认使用，而且替代了CMS 收集器 适用场景 同时注重吞吐量和低延迟（响应时间） 超大堆内存（内存大的），会将堆内存划分为多个大小相等的区域 整体上是标记-整理算法，两个区域之间是复制算法 相关参数 -XX:+UseG1GC ：启用 Garbage First (G1) 收集器 -XX:G1HeapRegionSize=size ：使用G1时Java堆会被分为大小统一的的区(region)。此参数可以指定每个heap区的大小，默认值将根据 heap size 算出最优解. 最小值为1Mb, 最大值为 32Mb -XX:MaxGCPauseMillis=time：设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到）(默认200ms) Region的介绍 G1收集器，默认将Java堆划分成约2048个大小相同的独立的Region块，每一个Region块大小根据堆空间的实际大小来决定，范围控制在1MB到32MB之内。所有的Region大小相同，且在JVM生命周期内不会改变(除非JVM停止之后，重新设置Region的大小，否则region的大小不会改变) Region使新生代和老年代的物理空间可以是不连续的。 Region的类型 Old region：老年代的Old区 。 Eden region：新生代的eden区。 Survivor region：新生代的survivor区。 Humongous region: 大区，主要用于存储大对象，如果对象大小超过0.5个Region，就放到这个区 设置H区（Humongous region）的原因：对于堆中的大对象，默认会被分配到老年代，但是如果它是一个短期存在的对象，由于老年代垃圾收集的频率较低，这个对象是不能及时被回收掉的，会对垃圾收集造成负面的影响。设置H区，就能够及时回收。如果一个H区装不下一个大对象，则寻找连续的H区来存储，如果找不到连续的H区，就会启动Full GC G1回收阶段 新生代伊甸园垃圾回收—–&gt;内存不足，新生代回收+并发标记—–&gt;回收新生代伊甸园、幸存区、老年代内存——&gt;新生代伊甸园垃圾回收(重新开始) Young CollectionE：伊甸园 S：幸存区 O：老年代 会 STW Young Collection + CMCM：并发标记 在 Young GC 时会对 GC Root 进行初始标记，需要STW 在老年代占用堆内存的比例达到阈值时（默认是45%），会进行并发标记（不会STW），阈值可以-XX:InitiatingHeapOccupancyPercent来设置 Mixed Collection会对E S O 进行全面的回收 最终标记（Remark）会STW 拷贝存活会STW 问：为什么有的老年代被拷贝了，有的没拷贝？ 因为指定了最大停顿时间，如果对所有老年代都进行回收，耗时可能过高。为了保证时间不超过设定的停顿时间，会回收最有价值的老年代（回收后，能够得到更多内存） ​ Full GC SerialGC 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足发生的垃圾收集 - full gc ParallelGC 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足发生的垃圾收集 - full gc CMS 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足如果并发出现失败 -full gc G1 新生代内存不足发生的垃圾收集 - minor gc 老年代内存不足（老年代所占内存超过阈值） 如果垃圾产生速度慢于垃圾回收速度，不会触发Full GC，还是并发地进行清理 如果垃圾产生速度快于垃圾回收速度，便会触发Full GC Young Collection 跨代引用 新生代回收的跨代引用（老年代引用新生代）问题 卡表与Remembered Set Remembered Set 存在于E中，用于保存新生代对象对应的脏卡 脏卡：O被划分为多个区域（一个区域512K），如果该区域引用了新生代对象，则该区域被称为脏卡 在引用变更时通过post-write barried + dirty card queue concurrent refinement threads 更新 Remembered Set Remark pre-write barrier + satb_mark_queue 最终标记阶段 黑色：已被处理，需要保留的 灰色：正在处理中的 白色：还未处理的 但是在并发标记过程中，有可能A被处理了以后未引用C，但该处理过程还未结束，在处理过程结束之前A引用了C，这时就会用到remark 过程如下 之前C未被引用，这时A引用了C，就会给C加一个写屏障，写屏障的指令会被执行，将C放入一个队列当中，并将C变为 处理中 状态 在并发标记阶段结束以后，重新标记阶段会STW，然后将放在该队列中的对象重新处理，发现有强引用引用它，就会处理它 JDK 8u20 字符串去重 优点：节省了大量内存 缺点：新生代回收时间略微增加，导致略微多占用CPU String s1 = new String(\"hello\"); // char[]{'h','e','l','l','o'} String s2 = new String(\"hello\"); // char[]{'h','e','l','l','o'} 相关参数：-XX:+UseStringDeduplication 将所有新分配的字符串（底层是char[]）放入一个队列 当新生代回收时，G1并发检查是否有重复的字符串 如果字符串的值一样，就让他们引用同一个字符串对象 注意，其与String.intern()不一样 String.intern()关注的是字符串对象 字符串去重关注的是char[] 在JVM内部，使用了不同的字符串表 JDK 8u40 并发标记类卸载所有对象在并发标记阶段结束以后，就能知道哪些类不再被使用。如果一个类加载器的所有类都不再使用，则卸载它所加载的所有类 -XX:+ClassUnloadingWithConcurrentMark 默认启用 JDK 8u60 回收巨型对象 一个对象大于region的一半时，就称为巨型对象 G1不会对巨型对象进行拷贝 回收时被优先考虑 G1会跟踪老年代所有incoming引用，如果老年代incoming引用为0的巨型对象就可以在新生代垃圾回收时处理掉 GC调优查看虚拟机参数命令 \"F:\\JAVA\\JDK8.0\\bin\\java\" -XX:+PrintFlagsFinal -version | findstr \"GC\" 可以根据参数去查询具体的信息 调优领域 内存 锁竞争 CPU占用 IO GC 确定目标 低延迟/高吞吐量？ 选择合适的GC CMS G1 ZGC ParallelGC Zing 最快的GC是不发生GC首先排除减少因为自身编写的代码而引发的内存问题 查看Full GC前后的内存占用，考虑以下几个问题 数据是不是太多？ 数据表示是否太臃肿 对象图 对象大小 是否存在内存泄漏 新生代调优 新生代的特点 所有的new操作分配内存都是非常廉价的 TLAB thread-local allocation buffer 死亡对象的回收代价是零 大部分对象用过即死（朝生夕死） Minor GC 所用时间远远小于 Full GC 新生代内存越大越好么？ 不是 新生代内存太小：频繁触发Minor GC，会STW，会使得吞吐量下降 新生代内存太大：老年代内存占比有所降低，会更频繁地触发Full GC。而且触发Minor GC时，清理新生代所花费的时间会更长 *新生代内存设置为能容纳[并发量(请求-响应)]的数据为宜** 幸存区调优 幸存区需要能够保存 【当前活跃对象+需要晋升的对象】 晋升阈值配置得当，让长时间存活的对象尽快晋升 老年代调优 可以先尝试调优新生代 类加载与字节码技术 类文件结构 一个简单的 HelloWorld.java // HelloWorld 示例 public class HelloWorld { public static void main(String[] args) { System.out.println(\"hello world\"); } } 执行 javac -parameters -d . HellowWorld.java 编译为 HelloWorld.class 后是这个样子的： 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 0000020 00 16 00 17 08 00 18 0a 00 19 00 1a 07 00 1b 07 0000040 00 1c 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 29 0000060 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e 0000100 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 63 0000120 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 01 0000140 00 04 74 68 69 73 01 00 1d 4c 63 6e 2f 69 74 63 0000160 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 6f 0000200 57 6f 72 6c 64 3b 01 00 04 6d 61 69 6e 01 00 16 0000220 28 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 0000240 69 6e 67 3b 29 56 01 00 04 61 72 67 73 01 00 13 0000260 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 0000300 6e 67 3b 01 00 10 4d 65 74 68 6f 64 50 61 72 61 0000320 6d 65 74 65 72 73 01 00 0a 53 6f 75 72 63 65 46 0000340 69 6c 65 01 00 0f 48 65 6c 6c 6f 57 6f 72 6c 64 0000360 2e 6a 61 76 61 0c 00 07 00 08 07 00 1d 0c 00 1e 0000400 00 1f 01 00 0b 68 65 6c 6c 6f 20 77 6f 72 6c 64 0000420 07 00 20 0c 00 21 00 22 01 00 1b 63 6e 2f 69 74 0000440 63 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 0000460 6f 57 6f 72 6c 64 01 00 10 6a 61 76 61 2f 6c 61 0000500 6e 67 2f 4f 62 6a 65 63 74 01 00 10 6a 61 76 61 0000520 2f 6c 61 6e 67 2f 53 79 73 74 65 6d 01 00 03 6f 0000540 75 74 01 00 15 4c 6a 61 76 61 2f 69 6f 2f 50 72 0000560 69 6e 74 53 74 72 65 61 6d 3b 01 00 13 6a 61 76 0000600 61 2f 69 6f 2f 50 72 69 6e 74 53 74 72 65 61 6d 0000620 01 00 07 70 72 69 6e 74 6c 6e 01 00 15 28 4c 6a 0000640 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 6e 67 3b 0000660 29 56 00 21 00 05 00 06 00 00 00 00 00 02 00 01 0000700 00 07 00 08 00 01 00 09 00 00 00 2f 00 01 00 01 0000720 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 0a 00 0000740 00 00 06 00 01 00 00 00 04 00 0b 00 00 00 0c 00 0000760 01 00 00 00 05 00 0c 00 0d 00 00 00 09 00 0e 00 0001000 0f 00 02 00 09 00 00 00 37 00 02 00 01 00 00 00 0001020 09 b2 00 02 12 03 b6 00 04 b1 00 00 00 02 00 0a 0001040 00 00 00 0a 00 02 00 00 00 06 00 08 00 07 00 0b 0001060 00 00 00 0c 00 01 00 00 00 09 00 10 00 11 00 00 0001100 00 12 00 00 00 05 01 00 10 00 00 00 01 00 13 00 0001120 00 00 02 00 14 根据 JVM 规范，类文件结构如下 u4 magic u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count]; 魔数对应字节码文件的0~3 字节，表示它是否是【class】类型的文件 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 版本对应字节码文件的4~7 字节，表示类的版本 00 34（52） 表示是 Java 8 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 常量池 常量表类型 标志值(占 1byte) CONSTANT_Class 7 CONSTANT_Fieldref 9 CONSTANT_Methodref 10 CONSTANT_InterfaceMethodref 11 CONSTANT_String 8 CONSTANT_Integer 3 CONSTANT_Float 4 CONSTANT_Long 5 CONSTANT_Double 6 CONSTANT_NameAndType 12 CONSTANT_Utf8 1 CONSTANT_MethodHandle 15 CONSTANT_MethodType 16 CONSTANT_InvokeDynamic 18 具体请参考 Chapter 4. The class File Format (oracle.com) 字节码指令 具体请参考 Chapter 6. The Java Virtual Machine Instruction Set (oracle.com) javap工具自己分析类文件结构太麻烦了，Oracle 提供了 javap 工具来反编译 class 文件 javap -v 文件名.class e:\\study&gt;javap -v e:\\studysrc\\Demo1.class Classfile /e:\\studysrc\\Demo1.class Last modified 2020-6-5; size 434 bytes MD5 checksum df1dce65bf6fb0b4c1de318051f4a67e Compiled from \"Demo1.java\" public class Demo1 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPER Constant pool: #1 = Methodref #6.#15 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Fieldref #16.#17 // java/lang/System.out:Ljava/io/PrintStream; #3 = String #18 // hello world #4 = Methodref #19.#20 // java/io/PrintStream.println:(Ljava/lang/String;)V #5 = Class #21 // com/nyima/JVM/day5/Demo1 #6 = Class #22 // java/lang/Object #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 main #12 = Utf8 ([Ljava/lang/String;)V #13 = Utf8 SourceFile #14 = Utf8 Demo1.java #15 = NameAndType #7:#8 // \"&lt;init&gt;\":()V #16 = Class #23 // java/lang/System #17 = NameAndType #24:#25 // out:Ljava/io/PrintStream; #18 = Utf8 hello world #19 = Class #26 // java/io/PrintStream #20 = NameAndType #27:#28 // println:(Ljava/lang/String;)V #21 = Utf8 com/nyima/JVM/day5/Demo1 #22 = Utf8 java/lang/Object #23 = Utf8 java/lang/System #24 = Utf8 out #25 = Utf8 Ljava/io/PrintStream; #26 = Utf8 java/io/PrintStream #27 = Utf8 println #28 = Utf8 (Ljava/lang/String;)V { public Demo1(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 7: 0 public static void main(java.lang.String[]); descriptor: ([Ljava/lang/String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack=2, locals=1, args_size=1 0: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #3 // String hello world 5: invokevirtual #4 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return LineNumberTable: line 9: 0 line 10: 8 } 图解方法执行流程原始java代码public class Demo3_1 { public static void main(String[] args) { int a = 10; int b = Short.MAX_VALUE + 1; int c = a + b; System.out.println(c); } } 编译成字节码文件 javap -v Demo3_1.class 常量池载入运行时常量池 常量池也属于方法区，只不过这里单独提出来了 方法字节码载入方法区 （stack=2，locals=4） 对应操作数栈有2个空间（每个空间4个字节），局部变量表中有4个槽位 执行引擎开始执行字节码bipush 10 将一个 byte 压入操作数栈（其长度会补齐 4 个字节），类似的指令还有 sipush 将一个 short 压入操作数栈（其长度会补齐 4 个字节） ldc 将一个 int 压入操作数栈 ldc2_w 将一个 long 压入操作数栈（分两次压入，因为 long 是 8 个字节） 这里小的数字都是和字节码指令存在一起，超过 short 范围的数字存入了常量池 istore 1 将操作数栈栈顶元素弹出，放入局部变量表的slot 1中 对应代码中的 a = 10 ldc #3 读取运行时常量池中#3，即32768(超过short最大值范围的数会被放到运行时常量池中)，将其加载到操作数栈中 注意 Short.MAX_VALUE 是 32767，所以 32768 = Short.MAX_VALUE + 1 实际是在编译期间计算好的 istore 2 将操作数栈中的元素弹出，放到局部变量表的2号位置 iload1 iload2 将局部变量表中1号位置和2号位置的元素放入操作数栈中 因为只能在操作数栈中执行运算操作 iadd 将操作数栈中的两个元素弹出栈并相加，结果在压入操作数栈中 istore 3 将操作数栈中的元素弹出，放入局部变量表的3号位置 getstatic #4 在运行时常量池中找到#4，发现是一个对象 在堆内存中找到该对象，并将其引用放入操作数栈中 iload 3 将局部变量表中3号位置的元素压入操作数栈中 invokevirtual 5 找到常量池 #5 项 定位到方法区 java/io/PrintStream.println:(I)V 方法 生成新的栈帧（分配 locals、stack等） 传递参数，执行新栈帧中的字节码 执行完毕，弹出栈帧 清除 main 操作数栈内容 return 完成 main 方法调用，弹出 main 栈帧 程序结束 通过字节码指令来分析问题原始的java代码public class Demo2 { public static void main(String[] args) { int i=0; int x=0; while(i&lt;10) { x = x++; i++; } System.out.println(x); //接过为0 } } 为什么最终的x结果为0呢？ 通过分析字节码指令即可知晓 Code: stack=2, locals=3, args_size=1 //操作数栈分配2个空间，局部变量表分配3个空间 0: iconst_0 //准备一个常数0 1: istore_1 //将常数0放入局部变量表的1号槽位 i=0 2: iconst_0 //准备一个常数0 3: istore_2 //将常数0放入局部变量的2号槽位 x=0 4: iload_1 //将局部变量表1号槽位的数放入操作数栈中 5: bipush 10 //将数字10放入操作数栈中，此时操作数栈中有2个数 7: if_icmpge 21 //比较操作数栈中的两个数，如果下面的数大于上面的数，就跳转到21。这里的比较是将两个数做减法。因为涉及运算操作，所以会将两个数弹出操作数栈来进行运算。运算结束后操作数栈为空 10: iload_2 //将局部变量2号槽位的数放入操作数栈中，放入的值是0 11: iinc 2, 1 //将局部变量2号槽位的数加1，自增后，槽位中的值为1 14: istore_2 //将操作数栈中的数放入到局部变量表的2号槽位，2号槽位的值又变为了0 15: iinc 1, 1 //1号槽位的值自增1 18: goto 4 //跳转到第4条指令 21: getstatic #2 // Field java/lang/System.out:Ljava/io/PrintStream; 24: iload_2 25: invokevirtual #3 // Method java/io/PrintStream.println:(I)V 28: return 构造方法cinit()Vpublic class Demo3 { static int i = 10; static { i = 20; } static { i = 30; } public static void main(String[] args) { System.out.println(i); //结果为30 } } 编译器会按从上至下的顺序，收集所有 static 静态代码块和静态成员赋值的代码，合并为一个特殊的方法 cinit()V ： stack=1, locals=0, args_size=0 0: bipush 10 2: putstatic #3 // Field i:I 5: bipush 20 7: putstatic #3 // Field i:I 10: bipush 30 12: putstatic #3 // Field i:I 15: return init()Vpublic class Demo4 { private String a = \"s1\"; { b = 20; } private int b = 10; { a = \"s2\"; } public Demo4(String a, int b) { this.a = a; this.b = b; } public static void main(String[] args) { Demo4 d = new Demo4(\"s3\", 30); System.out.println(d.a); System.out.println(d.b); } } 编译器会按从上至下的顺序，收集所有 {} 代码块和成员变量赋值的代码，形成新的构造方法，但原始构造方法内的代码总是在最后 Code: stack=2, locals=3, args_size=3 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: aload_0 5: ldc #2 // String s1 7: putfield #3 // Field a:Ljava/lang/String; 10: aload_0 11: bipush 20 13: putfield #4 // Field b:I 16: aload_0 17: bipush 10 19: putfield #4 // Field b:I 22: aload_0 23: ldc #5 // String s2 25: putfield #3 // Field a:Ljava/lang/String; //原始构造方法在最后执行 28: aload_0 29: aload_1 30: putfield #3 // Field a:Ljava/lang/String; 33: aload_0 34: iload_2 35: putfield #4 // Field b:I 38: return 方法调用public class Demo5 { public Demo5() { } private void test1() { } private final void test2() { } public void test3() { } public static void test4() { } public static void main(String[] args) { Demo5 demo5 = new Demo5(); demo5.test1(); demo5.test2(); demo5.test3(); Demo5.test4(); } } 不同方法在调用时，对应的虚拟机指令有所区别 私有、构造、被final修饰的方法，在调用时都使用invokespecial指令 普通成员方法在调用时，使用invokevirtua指令。因为编译期间无法确定该方法的内容，只有在运行期间才能确定 静态方法在调用时使用invokestatic指令 Code: stack=2, locals=2, args_size=1 0: new #2 // class com/nyima/JVM/day5/Demo5 3: dup 4: invokespecial #3 // Method \"&lt;init&gt;\":()V 7: astore_1 8: aload_1 9: invokespecial #4 // Method test1:()V 12: aload_1 13: invokespecial #5 // Method test2:()V 16: aload_1 17: invokevirtual #6 // Method test3:()V 20: invokestatic #7 // Method test4:()V 23: return new 是创建【对象】，给对象分配堆内存，执行成功会将【对象引用】压入操作数栈 dup 是赋值操作数栈栈顶的内容，本例即为【对象引用】，为什么需要两份引用呢，一个是要配合 invokespecial 调用该对象的构造方法 “init”:()V （会消耗掉栈顶一个引用），另一个要 配合 astore_1 赋值给局部变量 最终方法（ﬁnal），私有方法（private），构造方法都是由 invokespecial 指令来调用，属于静态绑定 普通成员方法是由 invokevirtual 调用，属于动态绑定，即支持多态 成员方法与静态方法调用的另一个区别是，执行方法前是否需要【对象引用】 多态的原理因为普通成员方法需要在运行时才能确定具体的内容，所以虚拟机需要调用invokevirtual指令 在执行invokevirtual指令时，经历了以下几个步骤 先通过栈帧中对象的引用找到对象 分析对象头，找到对象实际的Class Class结构中有vtable，它在类加载的链接阶段就已经根据方法的重写规则生成好了 查询vtable找到方法的具体地址 执行方法的字节码 异常处理try-catchpublic class Demo1 { public static void main(String[] args) { int i = 0; try { i = 10; }catch (Exception e) { i = 20; } } } 对应的字节码指令: Code: stack=1, locals=3, args_size=1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 12 8: astore_2 9: bipush 20 11: istore_1 12: return //多出来一个异常表 Exception table: from to target type 2 5 8 Class java/lang/Exception 可以看到多出来一个 Exception table 的结构，[from, to) 是前闭后开（也就是检测2~4行）的检测范围，一旦这个范围内的字节码执行出现异常，则通过 type 匹配异常类型，如果一致，进入 target 所指示行号 8行的字节码指令 astore_2 是将异常对象引用存入局部变量表的2号位置 多个single-catchpublic class Demo1 { public static void main(String[] args) { int i = 0; try { i = 10; }catch (ArithmeticException e) { i = 20; }catch (Exception e) { i = 30; } } } 对应的字节码指令: Code: stack=1, locals=3, args_size=1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 19 8: astore_2 9: bipush 20 11: istore_1 12: goto 19 15: astore_2 16: bipush 30 18: istore_1 19: return Exception table: from to target type 2 5 8 Class java/lang/ArithmeticException 2 5 15 Class java/lang/Exception 因为异常出现时，只能进入 Exception table 中一个分支，所以局部变量表 slot 2 位置被共用 finallypublic class Demo2 { public static void main(String[] args) { int i = 0; try { i = 10; } catch (Exception e) { i = 20; } finally { i = 30; } } } 对应的字节码指令: Code: stack=1, locals=4, args_size=1 0: iconst_0 1: istore_1 //try块 2: bipush 10 4: istore_1 //try块执行完后，会执行finally 5: bipush 30 7: istore_1 8: goto 27 //catch块 11: astore_2 //异常信息放入局部变量表的2号槽位 12: bipush 20 14: istore_1 //catch块执行完后，会执行finally 15: bipush 30 17: istore_1 18: goto 27 //出现异常，但未被Exception捕获，会抛出其他异常，这时也需要执行finally块中的代码 21: astore_3 22: bipush 30 24: istore_1 25: aload_3 26: athrow //抛出异常 27: return Exception table: from to target type 2 5 11 Class java/lang/Exception 2 5 21 any 11 15 21 any 可以看到 finally 中的代码被复制了 3 份，分别放入 try 流程，catch 流程以及 catch 剩余的异常类型流程 注意：虽然从字节码指令看来，每个块中都有finally块，但是finally块中的代码只会被执行一次 finally中的returnpublic class Demo3 { public static void main(String[] args) { int i = Demo3.test(); //结果为20 System.out.println(i); } public static int test() { int i; try { i = 10; return i; } finally { i = 20; return i; } } } 对应的字节码指令: Code: stack=1, locals=3, args_size=0 0: bipush 10 2: istore_0 3: iload_0 4: istore_1 //暂存返回值 5: bipush 20 7: istore_0 8: iload_0 9: ireturn //ireturn会返回操作数栈顶的整型值20 //如果出现异常，还是会执行finally块中的内容，没有抛出异常 10: astore_2 11: bipush 20 13: istore_0 14: iload_0 15: ireturn //这里没有athrow了，也就是如果在finally块中如果有返回操作的话，且try块中出现异常，会吞掉异常！ Exception table: from to target type 0 5 10 any 由于 ﬁnally 中的 ireturn 被插入了所有可能的流程，因此返回结果肯定以ﬁnally的为准 至于字节码中第 2 行，似乎没啥用，且留个伏笔，看下个例子 跟上例中的 ﬁnally 相比，发现没有 athrow 了，这告诉我们：如果在 ﬁnally 中出现了 return，会吞掉异常 所以尽量不要在finally中进行返回操作 被吞掉的异常public class Demo3 { public static void main(String[] args) { int i = Demo3.test(); //最终结果为20 System.out.println(i); } public static int test() { int i; try { i = 10; //这里应该会抛出异常 i = i/0; return i; } finally { i = 20; return i; } } } 会发现打印结果为20，并未抛出异常 finally不带returnpublic class Demo4 { public static void main(String[] args) { int i = Demo4.test(); System.out.println(i); } public static int test() { int i = 10; try { return i; } finally { i = 20; } } } 对应的字节码指令: Code: stack=1, locals=3, args_size=0 0: bipush 10 2: istore_0 //赋值给i 10 3: iload_0 //加载到操作数栈顶 4: istore_1 //加载到局部变量表的1号位置 5: bipush 20 7: istore_0 //赋值给i 20 8: iload_1 //加载局部变量表1号位置的数10到操作数栈 9: ireturn //返回操作数栈顶元素 10 10: astore_2 11: bipush 20 13: istore_0 14: aload_2 //加载异常 15: athrow //抛出异常 Exception table: from to target type 3 5 10 any 返回的值是10 Synchronizedpublic class Demo5 { public static void main(String[] args) { int i = 10; Lock lock = new Lock(); synchronized (lock) { System.out.println(i); } } } class Lock{} 对应的字节码指令: Code: stack=2, locals=5, args_size=1 0: bipush 10 2: istore_1 3: new #2 // class com/nyima/JVM/day06/Lock 6: dup //复制一份，放到操作数栈顶，用于构造函数消耗 7: invokespecial #3 // Method com/nyima/JVM/day06/Lock.\"&lt;init&gt;\":()V 10: astore_2 //剩下的一份放到局部变量表的2号位置 11: aload_2 //加载到操作数栈 12: dup //复制一份，放到操作数栈，用于加锁时消耗 13: astore_3 //将操作数栈顶元素弹出，暂存到局部变量表的三号槽位。这时操作数栈中有一份对象的引用 14: monitorenter //加锁 //锁住后代码块中的操作 15: getstatic #4 // Field java/lang/System.out:Ljava/io/PrintStream; 18: iload_1 19: invokevirtual #5 // Method java/io/PrintStream.println:(I)V //加载局部变量表中三号槽位对象的引用，用于解锁 22: aload_3 23: monitorexit //解锁 24: goto 34 //异常操作 27: astore 4 29: aload_3 30: monitorexit //解锁 31: aload 4 33: athrow 34: return //可以看出，无论何时出现异常，都会跳转到27行，将异常放入局部变量中，并进行解锁操作，然后加载异常并抛出异常。 Exception table: from to target type 15 24 27 any 27 31 27 any 注意 方法级别的 synchronized 不会在字节码指令中有所体现 编译期处理所谓的 语法糖 ，其实就是指 java 编译器把 *.java 源码编译为 *.class 字节码的过程中，自动生成和转换的一些代码，主要是为了减轻程序员的负担，算是 java 编译器给我们的一个额外福利 注意，以下代码的分析，借助了 javap 工具，idea 的反编译功能，idea 插件 jclasslib 等工具。另外， 编译器转换的结果直接就是 class 字节码，只是为了便于阅读，给出了 几乎等价 的 java 源码方式，并不是编译器还会转换出中间的 java 源码，切记。 默认构造函数public class Candy1 { } 经过编译期优化后 public class Candy1 { //这个无参构造器是java编译器帮我们加上的 public Candy1() { //即调用父类 Object 的无参构造方法，即调用 java/lang/Object.\" &lt;init&gt;\":()V super(); } } 自动拆装箱 基本类型和其包装类型的相互转换过程，称为拆装箱 在JDK 5以后，它们的转换可以在编译期自动完成 public class Demo2 { public static void main(String[] args) { Integer x = 1; int y = x; } } 转换过程如下 public class Demo2 { public static void main(String[] args) { //基本类型赋值给包装类型，称为装箱 Integer x = Integer.valueOf(1); //包装类型赋值给基本类型，称谓拆箱 int y = x.intValue(); } } 泛型集合取值泛型也是在 JDK 5 开始加入的特性，但 java 在编译泛型代码后会执行 泛型擦除 的动作，即泛型信息在编译为字节码之后就丢失了，实际的类型都当做了 Object 类型来处理 public class Demo3 { public static void main(String[] args) { List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); list.add(10); Integer x = list.get(0); } } 对应的字节码指令: Code: stack=2, locals=3, args_size=1 0: new #2 // class java/util/ArrayList 3: dup 4: invokespecial #3 // Method java/util/ArrayList.\"&lt;init&gt;\":()V 7: astore_1 8: aload_1 9: bipush 10 11: invokestatic #4 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; //这里进行了泛型擦除，实际调用的是add(Objcet o) 14: invokeinterface #5, 2 // InterfaceMethod java/util/List.add:(Ljava/lang/Object;)Z 19: pop 20: aload_1 21: iconst_0 //这里也进行了泛型擦除，实际调用的是get(Object o) 22: invokeinterface #6, 2 // InterfaceMethod java/util/List.get:(I)Ljava/lang/Object; //这里进行了类型转换，将Object转换成了Integer 27: checkcast #7 // class java/lang/Integer 30: astore_2 31: return 所以调用get函数取值时，有一个类型转换的操作 Integer x = (Integer) list.get(0); 如果要将返回结果赋值给一个int类型的变量，则还有自动拆箱的操作 int x = (Integer) list.get(0).intValue(); 可变参数public class Demo4 { public static void foo(String... args) { //将args赋值给arr，可以看出String...实际就是String[] String[] arr = args; System.out.println(arr.length); } public static void main(String[] args) { foo(\"hello\", \"world\"); } } 可变参数 String… args 其实是一个 String[] args ，从代码中的赋值语句中就可以看出来。 同 样 java 编译器会在编译期间将上述代码变换为 public class Demo4 { public Demo4 {} public static void foo(String[] args) { String[] arr = args; System.out.println(arr.length); } public static void main(String[] args) { foo(new String[]{\"hello\", \"world\"}); } } 注意，如果调用的是foo()，即未传递参数时，等价代码为foo(new String[]{})，创建了一个空数组，而不是直接传递的null foreachpublic class Demo5 { public static void main(String[] args) { //数组赋初值的简化写法也是一种语法糖。 int[] arr = {1, 2, 3, 4, 5}; for(int x : arr) { System.out.println(x); } } } 编译器会帮我们转换为 public class Demo5 { public Demo5 {} public static void main(String[] args) { int[] arr = new int[]{1, 2, 3, 4, 5}; for(int i=0; i&lt;arr.length; ++i) { int x = arr[i]; System.out.println(x); } } } 如果是集合使用foreach public class Demo5 { public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5); for (Integer x : list) { System.out.println(x); } } } 集合要使用foreach，需要该集合类实现了Iterable接口，因为集合的遍历需要用到迭代器Iterator public class Demo5 { public Demo5 {} public static void main(String[] args) { List&lt;Integer&gt; list = Arrays.asList(1, 2, 3, 4, 5); //获得该集合的迭代器 Iterator&lt;Integer&gt; iterator = list.iterator(); while(iterator.hasNext()) { Integer x = iterator.next(); System.out.println(x); } } } switch字符串public class Demo6 { public static void main(String[] args) { String str = \"hello\"; switch (str) { case \"hello\" : System.out.println(\"h\"); break; case \"world\" : System.out.println(\"w\"); break; default: break; } } } 在编译器中执行的操作 public class Demo6 { public Demo6() { } public static void main(String[] args) { String str = \"hello\"; int x = -1; //通过字符串的hashCode+value来判断是否匹配 switch (str.hashCode()) { //hello的hashCode case 99162322 : //再次比较，因为字符串的hashCode有可能相等 if(str.equals(\"hello\")) { x = 0; } break; //world的hashCode case 11331880 : if(str.equals(\"world\")) { x = 1; } break; default: break; } //用第二个switch在进行输出判断 switch (x) { case 0: System.out.println(\"h\"); break; case 1: System.out.println(\"w\"); break; default: break; } } } 过程说明： 在编译期间，单个的switch被分为了两个 第一个用来匹配字符串，并给x赋值 字符串的匹配用到了字符串的hashCode，还用到了equals方法 使用hashCode是为了提高比较效率，使用equals是防止有hashCode冲突（如BM和C.） 第二个用来根据x的值来决定输出语句 switch枚举public class Demo7 { public static void main(String[] args) { SEX sex = SEX.MALE; switch (sex) { case MALE: System.out.println(\"man\"); break; case FEMALE: System.out.println(\"woman\"); break; default: break; } } } enum SEX { MALE, FEMALE; } 编译器中执行的代码如下 public class Demo7 { /** * 定义一个合成类（仅 jvm 使用，对我们不可见） * 用来映射枚举的 ordinal 与数组元素的关系 * 枚举的 ordinal 表示枚举对象的序号，从 0 开始 * 即 MALE 的 ordinal()=0，FEMALE 的 ordinal()=1 */ static class $MAP { //数组大小即为枚举元素个数，里面存放了case用于比较的数字 static int[] map = new int[2]; static { //ordinal即枚举元素对应所在的位置，MALE为0，FEMALE为1 map[SEX.MALE.ordinal()] = 1; map[SEX.FEMALE.ordinal()] = 2; } } public static void main(String[] args) { SEX sex = SEX.MALE; //将对应位置枚举元素的值赋给x，用于case操作 int x = $MAP.map[sex.ordinal()]; switch (x) { case 1: System.out.println(\"man\"); break; case 2: System.out.println(\"woman\"); break; default: break; } } } enum SEX { MALE, FEMALE; } 枚举类enum SEX { MALE, FEMALE; } 转换后的代码 public final class Sex extends Enum&lt;Sex&gt; { //对应枚举类中的元素 public static final Sex MALE; public static final Sex FEMALE; private static final Sex[] $VALUES; static { //调用构造函数，传入枚举元素的值及ordinal MALE = new Sex(\"MALE\", 0); FEMALE = new Sex(\"FEMALE\", 1); $VALUES = new Sex[]{MALE, FEMALE}; } //调用父类中的方法 private Sex(String name, int ordinal) { super(name, ordinal); } public static Sex[] values() { return $VALUES.clone(); } public static Sex valueOf(String name) { return Enum.valueOf(Sex.class, name); } } 匿名内部类public class Demo8 { public static void main(String[] args) { Runnable runnable = new Runnable() { @Override public void run() { System.out.println(\"running...\"); } }; } } 转换后的代码 public class Demo8 { public static void main(String[] args) { //用额外创建的类来创建匿名内部类对象 Runnable runnable = new Demo8$1(); } } //创建了一个额外的类，实现了Runnable接口 final class Demo8$1 implements Runnable { public Demo8$1() {} @Override public void run() { System.out.println(\"running...\"); } } 如果匿名内部类中引用了局部变量 public class Demo8 { public static void main(String[] args) { int x = 1; Runnable runnable = new Runnable() { @Override public void run() { System.out.println(x); } }; } } 转化后的代码 public class Demo8 { public static void main(String[] args) { int x = 1; Runnable runnable = new Runnable() { @Override public void run() { System.out.println(x); } }; } } final class Demo8$1 implements Runnable { //多创建了一个变量 int val$x; //变为了有参构造器 public Demo8$1(int x) { this.val$x = x; } @Override public void run() { System.out.println(val$x); } } 类加载阶段加载 将类的字节码载入方法区（1.8后为元空间，在本地内存中）中，内部采用 C++ 的 instanceKlass 描述 java 类，它的重要 ﬁeld 有： _java_mirror 即 java 的类镜像，例如对 String 来说，它的镜像类就是 String.class，作用是把 klass 暴露给 java 使用 _super 即父类 _ﬁelds 即成员变量 _methods 即方法 _constants 即常量池 _class_loader 即类加载器 _vtable 虚方法表 _itable 接口方法 如果这个类还有父类没有加载，先加载父类 加载和链接可能是交替运行的 注意 instanceKlass保存在方法区。JDK 8以后，方法区位于元空间中，而元空间又位于本地内存中 _java_mirror则是保存在堆内存中 *InstanceKlass和.class(JAVA镜像类)互相保存了对方的地址** 类的对象在对象头中保存了*.class的地址。让对象可以通过其找到方法区中的instanceKlass，从而获取类的各种信息 链接验证 验证类是否符合 JVM规范，安全性检查 准备为 static 变量分配空间，设置默认值 static变量在JDK 7以前是存储与instanceKlass末尾。但在JDK 7以后就存储在_java_mirror末尾了 static变量在分配空间和赋值是在两个阶段完成的。分配空间在准备阶段完成，赋值在初始化阶段完成 如果 static 变量是 ﬁnal 的基本类型，以及字符串常量，那么编译阶段值就确定了，赋值在准备阶段完成 如果 static 变量是 ﬁnal 的，但属于引用类型，那么赋值也会在初始化阶段完成 解析HSDB的使用 先获得要查看的进程ID jps 打开HSDB java -cp D:\\JAVA\\JDK8.0\\lib\\sa-jdi.jar sun.jvm.hotspot.HSDB 运行时可能会报错，是因为缺少一个.dll的文件，我们在JDK的安装目录中找到该文件，复制到缺失的文件下即可 定位到需要的进程 解析的含义 将常量池中的符号引用解析为直接引用 未解析时，常量池中的看到的对象仅是符号，未真正的存在于内存中 public class Demo1 { public static void main(String[] args) throws IOException, ClassNotFoundException { ClassLoader loader = Demo1.class.getClassLoader(); //只加载不解析 Class&lt;?&gt; c = loader.loadClass(\"com.nyima.JVM.day8.C\"); //用于阻塞主线程 System.in.read(); } } class C { D d = new D(); } class D { } 打开HSDB 可以看到此时只加载了类C 查看类C的常量池，可以看到类D未被解析，只是存在于常量池中的符号 解析以后，会将常量池中的符号引用解析为直接引用 可以看到，此时已加载并解析了类C和类D 初始化初始化阶段就是执行类构造器cinit()V方法的过程，虚拟机会保证这个类的『构造方法』的线程安全 cinit()V方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的 发生时机类的初始化的懒惰的，以下情况会初始化 main 方法所在的类，总会被首先初始化 首次访问这个类的静态变量或静态方法时 子类初始化，如果父类还没初始化，会引发 子类访问父类的静态变量，只会触发父类的初始化 Class.forName new 会导致初始化 以下情况不会初始化 访问类的 static ﬁnal 静态常量（基本类型和字符串） 类对象.class 不会触发初始化 创建该类对象的数组 类加载器的.loadClass方法 Class.forNamed的参数2为false时 验证类是否被初始化，可以看该类的静态代码块是否被执行 类加载器 Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（ClassLoader） 类与类加载器类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远超类加载阶段 对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等 以JDK 8为例 名称 加载的类 说明 Bootstrap ClassLoader（启动类加载器） JAVA_HOME/jre/lib 无法直接访问 Extension ClassLoader(拓展类加载器) JAVA_HOME/jre/lib/ext 上级为Bootstrap，显示为null Application ClassLoader(应用程序类加载器) classpath 上级为Extension 自定义类加载器 自定义 上级为Application 启动类加载器可通过在控制台输入指令，使得类被启动类加器加载 拓展类加载器如果classpath和JAVA_HOME/jre/lib/ext 下有同名类，加载时会使用拓展类加载器加载。当应用程序类加载器发现拓展类加载器已将该同名类加载过了，则不会再次加载 双亲委派模式双亲委派模式，即调用类加载器ClassLoader 的 loadClass 方法时，查找类的规则 loadClass源码 protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException { synchronized (getClassLoadingLock(name)) { // 首先查找该类是否已经被该类加载器加载过了 Class&lt;?&gt; c = findLoadedClass(name); //如果没有被加载过 if (c == null) { long t0 = System.nanoTime(); try { //看是否被它的上级加载器加载过了 Extension的上级是Bootstarp，但它显示为null if (parent != null) { c = parent.loadClass(name, false); } else { //看是否被启动类加载器加载过 c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader //捕获异常，但不做任何处理 } if (c == null) { //如果还是没有找到，先让拓展类加载器调用findClass方法去找到该类，如果还是没找到，就抛出异常 //然后让应用类加载器去找classpath下找该类 long t1 = System.nanoTime(); c = findClass(name); // 记录时间 sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } 过程如图： 自定义类加载器使用场景 想加载非 classpath 随意路径中的类文件 通过接口来使用实现，希望解耦时，常用在框架设计 这些类希望予以隔离，不同应用的同名类都可以加载，不冲突，常见于 tomcat 容器 步骤 继承ClassLoader父类 要遵从双亲委派机制，重写 ﬁndClass 方法 不是重写loadClass方法，否则不会走双亲委派机制 读取类文件的字节码 调用父类的 deﬁneClass 方法来加载类 使用者调用该类加载器的 loadClass 方法 破坏双亲委派模式 双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即JDK1.2面世以前的“远古”时代 建议用户重写findClass()方法，在类加载器中的loadClass()方法中也会调用该方法 双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的 如果有基础类型又要调用回用户的代码，此时也会破坏双亲委派模式 双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的 这里所说的“动态性”指的是一些非常“热”门的名词：代码热替换（Hot Swap）、模块热部署（Hot Deployment）等 运行期优化分层编译JVM 将执行状态分成了 5 个层次： 0层：解释执行，用解释器将字节码翻译为机器码 1层：使用 C1 即时编译器编译执行（不带 proﬁling） 2层：使用 C1 即时编译器编译执行（带基本的profiling） 3层：使用 C1 即时编译器编译执行（带完全的profiling） 4层：使用 C2 即时编译器编译执行 proﬁling 是指在运行过程中收集一些程序执行状态的数据，例如【方法的调用次数】，【循环的 回边次数】等 即时编译器（JIT）与解释器的区别 解释器 将字节码解释为机器码，下次即使遇到相同的字节码，仍会执行重复的解释 是将字节码解释为针对所有平台都通用的机器码 即时编译器 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行，无需再编译 根据平台类型，生成平台特定的机器码 对于大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。 执行效率上简单比较一下 Interpreter &lt; C1 &lt; C2，总的目标是发现热点代码（hotspot名称的由 来），并优化这些热点代码 逃逸分析逃逸分析（Escape Analysis）简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术 逃逸分析的 JVM 参数如下： 开启逃逸分析：-XX:+DoEscapeAnalysis 关闭逃逸分析：-XX:-DoEscapeAnalysis 显示分析结果：-XX:+PrintEscapeAnalysis 逃逸分析技术在 Java SE 6u23+ 开始支持，并默认设置为启用状态，可以不用额外加这个参数 对象逃逸状态 全局逃逸（GlobalEscape） 即一个对象的作用范围逃出了当前方法或者当前线程，有以下几种场景： 对象是一个静态变量 对象是一个已经发生逃逸的对象 对象作为当前方法的返回值 参数逃逸（ArgEscape） 即一个对象被作为方法参数传递或者被参数引用，但在调用过程中不会发生全局逃逸，这个状态是通过被调方法的字节码确定的 没有逃逸 即方法中的对象没有发生逃逸 逃逸分析优化 针对上面第三点，当一个对象没有逃逸时，可以得到以下几个虚拟机的优化 锁消除 我们知道线程同步锁是非常牺牲性能的，当编译器确定当前对象只有当前线程使用，那么就会移除该对象的同步锁 例如，StringBuffer 和 Vector 都是用 synchronized 修饰线程安全的，但大部分情况下，它们都只是在当前线程中用到，这样编译器就会优化移除掉这些锁操作 锁消除的 JVM 参数如下： 开启锁消除：-XX:+EliminateLocks 关闭锁消除：-XX:-EliminateLocks 锁消除在 JDK8 中都是默认开启的，并且锁消除都要建立在逃逸分析的基础上 标量替换 首先要明白标量和聚合量，基础类型和对象的引用可以理解为标量，它们不能被进一步分解。而能被进一步分解的量就是聚合量，比如：对象 对象是聚合量，它又可以被进一步分解成标量，将其成员变量分解为分散的变量，这就叫做标量替换。 这样，如果一个对象没有发生逃逸，那压根就不用创建它，只会在栈或者寄存器上创建它用到的成员标量，节省了内存空间，也提升了应用程序性能 标量替换的 JVM 参数如下： 开启标量替换：-XX:+EliminateAllocations 关闭标量替换：-XX:-EliminateAllocations 显示标量替换详情：-XX:+PrintEliminateAllocations 标量替换同样在 JDK8 中都是默认开启的，并且都要建立在逃逸分析的基础上 栈上分配 当对象没有发生逃逸时，该对象就可以通过标量替换分解成成员标量分配在栈内存中，和方法的生命周期一致，随着栈帧出栈时销毁，减少了 GC 压力，提高了应用程序性能 方法内联内联函数 内联函数就是在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来直接进行替换 JVM内联函数C++是否为内联函数由自己决定，Java由编译器决定。Java不支持直接声明为内联函数的，如果想让他内联，你只能够向编译器提出请求: 关键字final修饰 用来指明那个函数是希望被JVM内联的， public final void doSomething() { // to do something } 总的来说，一般的函数都不会被当做内联函数，只有声明了final后，编译器才会考虑是不是要把你的函数变成内联函数 JVM内建有许多运行时优化。首先短方法更利于JVM推断。流程更明显，作用域更短，副作用也更明显。如果是长方法JVM可能直接就跪了。 第二个原因则更重要：方法内联 如果JVM监测到一些小方法被频繁的执行，它会把方法的调用替换成方法体本身，如： private int add4(int x1, int x2, int x3, int x4) { //这里调用了add2方法 return add2(x1, x2) + add2(x3, x4); } private int add2(int x1, int x2) { return x1 + x2; } 方法调用被替换后 private int add4(int x1, int x2, int x3, int x4) { //被替换为了方法本身 return x1 + x2 + x3 + x4; } 反射优化public class Reflect1 { public static void foo() { System.out.println(\"foo...\"); } public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException { Method foo = Demo3.class.getMethod(\"foo\"); for(int i = 0; i&lt;=16; i++) { foo.invoke(null); } } } foo.invoke 前面 0 ~ 15 次调用使用的是 MethodAccessor 的 NativeMethodAccessorImpl 实现 invoke方法源码 @CallerSensitive public Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException { if (!override) { if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) { Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); } } //MethodAccessor是一个接口，有3个实现类，其中有一个是抽象类 MethodAccessor ma = methodAccessor; // read volatile if (ma == null) { ma = acquireMethodAccessor(); } return ma.invoke(obj, args); } 会由DelegatingMehodAccessorImpl去调用NativeMethodAccessorImpl NativeMethodAccessorImpl源码 class NativeMethodAccessorImpl extends MethodAccessorImpl { private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method var1) { this.method = var1; } //每次进行反射调用，会让numInvocation与ReflectionFactory.inflationThreshold的值（15）进行比较，并使得numInvocation的值加一 //如果numInvocation&gt;ReflectionFactory.inflationThreshold，则会调用本地方法invoke0方法 public Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException { if (++this.numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(this.method.getDeclaringClass())) { MethodAccessorImpl var3 = (MethodAccessorImpl)(new MethodAccessorGenerator()).generateMethod(this.method.getDeclaringClass(), this.method.getName(), this.method.getParameterTypes(), this.method.getReturnType(), this.method.getExceptionTypes(), this.method.getModifiers()); this.parent.setDelegate(var3); } return invoke0(this.method, var1, var2); } void setParent(DelegatingMethodAccessorImpl var1) { this.parent = var1; } private static native Object invoke0(Method var0, Object var1, Object[] var2); } //ReflectionFactory.inflationThreshold()方法的返回值 private static int inflationThreshold = 15; 一开始if条件不满足，就会调用本地方法invoke0 随着numInvocation的增大，当它大于ReflectionFactory.inflationThreshold的值16时，就会将本地方法访问器替换为一个运行时动态生成的访问器，来提高效率 这时会从反射调用变为正常调用，即直接调用 Reflect1.foo() 内存模型JAVA内存模型（JMM）JMM 即 Java Memory Model，它定义了主存（共享内存）、工作内存（线程私有）抽象概念，底层对应着 CPU 寄存器、缓存、硬件内存、 CPU 指令优化等。 JMM体现在以下几个方面 原子性 - 保证指令不会受到线程上下文切换的影响 可见性 - 保证指令不会受 cpu 缓存的影响 有序性 - 保证指令不会受 cpu 指令并行优化的影响 可见性引例退不出的循环 static Boolean run = true; public static void main(String[] args) throws InterruptedException { new Thread(()-&gt;{ while (run) { //如果run为真，则一直执行 } }).start(); Thread.sleep(1000); System.out.println(\"改变run的值为false\"); run = false; } 为什么无法退出该循环 初始状态， t 线程刚开始从主内存读取了 run 的值到工作内存。 因为 t 线程要频繁从主内存中读取 run 的值，JIT 编译器会将 run 的值缓存至自己工作内存中的高速缓存中， 减少对主存中 run 的访问，提高效率 1 秒之后，main 线程修改了 run 的值，并同步至主存，而 t 是从自己工作内存中的高速缓存中读取这个变量 的值，结果永远是旧值 解决方法 使用volatile易变关键字 它可以用来修饰成员变量和静态成员变量（放在主存中的变量），他可以避免线程从自己的工作缓存中查找变量的值，必须到主存中获取它的值，线程操作 volatile 变量都是直接操作主存 //使用易变关键字 volatile static Boolean run = true; public static void main(String[] args) throws InterruptedException { new Thread(()-&gt;{ while (run) { //如果run为真，则一直执行 } }).start(); Thread.sleep(1000); System.out.println(\"改变run的值为false\"); run = false; } 可见性与原子性前面例子体现的实际就是可见性，它保证的是在多个线程之间，一个线程对volatile变量的修改对另一个线程可见， 不能保证原子性，仅用在一个写线程，多个读线程的情况 注意 synchronized 语句块既可以保证代码块的原子性，也同时保证代码块内变量的可见性。 但缺点是 synchronized 是属于重量级操作，性能相对更低。 如果在前面示例的死循环中加入 System.out.println() 会发现即使不加 volatile 修饰符，线程 t 也能正确看到 对 run 变量的修改了，想一想为什么？ 因为使用了synchronized关键字 public void println(String x) { //使用了synchronized关键字 synchronized (this) { print(x); newLine(); } } 两阶终止模式优化public class Test7 { public static void main(String[] args) throws InterruptedException { Monitor monitor = new Monitor(); monitor.start(); Thread.sleep(3500); monitor.stop(); } } class Monitor { Thread monitor; //设置标记，用于判断是否被终止了 private volatile boolean stop = false; /** * 启动监控器线程 */ public void start() { //设置线控器线程，用于监控线程状态 monitor = new Thread() { @Override public void run() { //开始不停的监控 while (true) { if(stop) { System.out.println(\"处理后续任务\"); break; } System.out.println(\"监控器运行中...\"); try { //线程休眠 Thread.sleep(1000); } catch (InterruptedException e) { System.out.println(\"被打断了\"); } } } }; monitor.start(); } /** * 用于停止监控器线程 */ public void stop() { //打断线程 monitor.interrupt(); //修改标记 stop = true; } } 同步模式之犹豫模式定义 Balking （犹豫）模式用在一个线程发现另一个线程或本线程已经做了某一件相同的事，那么本线程就无需再做 了，**直接结束返回** 用一个标记来判断该任务是否已经被执行过了 需要避免线程安全问题 加锁的代码块要尽量的小，以保证性能 package com.nyima.day1; /** * @author Chen Panwen * @data 2020/3/26 16:11 */ public class Test7 { public static void main(String[] args) throws InterruptedException { Monitor monitor = new Monitor(); monitor.start(); monitor.start(); Thread.sleep(3500); monitor.stop(); } } class Monitor { Thread monitor; //设置标记，用于判断是否被终止了 private volatile boolean stop = false; //设置标记，用于判断是否已经启动过了 private boolean starting = false; /** * 启动监控器线程 */ public void start() { //上锁，避免多线程运行时出现线程安全问题 synchronized (this) { if (starting) { //已被启动，直接返回 return; } //启动监视器，改变标记 starting = true; } //设置线控器线程，用于监控线程状态 monitor = new Thread() { @Override public void run() { //开始不停的监控 while (true) { if(stop) { System.out.println(\"处理后续任务\"); break; } System.out.println(\"监控器运行中...\"); try { //线程休眠 Thread.sleep(1000); } catch (InterruptedException e) { System.out.println(\"被打断了\"); } } } }; monitor.start(); } /** * 用于停止监控器线程 */ public void stop() { //打断线程 monitor.interrupt(); stop = true; } } 有序性指令重排 JVM 会在不影响正确性的前提下，可以调整语句的执行顺序 static int i; static int j; // 在某个线程内执行如下赋值操作 i = ...; j = ...; 可以看到，至于是先执行 i 还是 先执行 j ，对最终的结果不会产生影响。所以，上面代码真正执行时，既可以是 i = ...; j = ...; 也可以是 j = ...; i = ...; 这种特性称之为『指令重排』，多线程下『指令重排』会影响正确性。 指令重排序优化 事实上，现代处理器会设计为一个时钟周期完成一条执行时间长的 CPU 指令。为什么这么做呢？可以想到指令还可以再划分成一个个更小的阶段，例如，每条指令都可以分为： 取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回 这5 个阶段 在不改变程序结果的前提下，这些指令的各个阶段可以通过重排序和组合来实现指令级并行 指令重排的前提是，重排指令不能影响结果，例如 // 可以重排的例子 int a = 10; int b = 20; System.out.println( a + b ); // 不能重排的例子 int a = 10; int b = a - 5; 支持流水线的处理器现代 CPU 支持多级指令流水线，例如支持同时执行 取指令 - 指令译码 - 执行指令 - 内存访问 - 数据写回 的处理器，就可以称之为五级指令流水线。这时 CPU 可以在一个时钟周期内，同时运行五条指令的不同阶段（相当于一 条执行时间长的复杂指令），IPC = 1，本质上，流水线技术并不能缩短单条指令的执行时间，但它变相地提高了指令地吞吐率。 在多线程环境下，指令重排序可能导致出现意料之外的结果 解决办法volatile 修饰的变量，可以禁用指令重排 禁止的是加volatile关键字变量之前的代码被重排序 内存屏障 可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中新数据 有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 volatile 原理volatile的底层实现原理是内存屏障，Memory Barrier（Memory Fence） 对 volatile 变量的写指令后会加入写屏障 对 volatile 变量的读指令前会加入读屏障 如何保证可见性 写屏障（sfence）保证在该屏障之前的，对共享变量的改动，都同步到主存当中 public void actor2(I_Result r) { num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 } 而读屏障（lfence）保证在该屏障之后，对共享变量的读取，加载的是主存中新数据 public void actor1(I_Result r) { // 读屏障 // ready 是 volatile 读取值带读屏障 if(ready) { r.r1 = num + num; } else { r.r1 = 1; } } 如何保证有序性 写屏障会确保指令重排序时，不会将写屏障之前的代码排在写屏障之后 public void actor2(I_Result r) { num = 2; ready = true; // ready 是 volatile 赋值带写屏障 // 写屏障 } 读屏障会确保指令重排序时，不会将读屏障之后的代码排在读屏障之前 public void actor1(I_Result r) { // 读屏障 // ready 是 volatile 读取值带读屏障 if(ready) { r.r1 = num + num; } else { r.r1 = 1; } } 但是不能解决指令交错问题 写屏障仅仅是保证之后的读能够读到新的结果，但不能保证读跑到它前面去 而有序性的保证也只是保证了本线程内相关代码不被重排序 实现原理之Lock前缀在X86处理器下通过工具获取JIT编译器生成的汇编指令来查看对volatile进行写操作时 instance = new Singleton(); 对应的汇编代码是 ... lock addl ... 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事 Lock前缀指令会引起处理器 缓存回写到内存 Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。但是，在最近的处理器里，LOCK #信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据 一个处理器的缓存回写到内存会 导致其他处理器的缓存无效 在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致 部分笔记内容参考-&gt;JVM - Nyima’s Blog (gitee.io)，感谢博主的分享。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"jvm","slug":"笔记/jvm","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://mjean.life/tags/jvm/"},{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://mjean.life/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"}]},{"title":"常见的排序算法","slug":"datastructure4","date":"2021-06-26T16:32:58.000Z","updated":"2022-04-18T12:48:45.805Z","comments":true,"path":"posts/e714468f.html","link":"","permalink":"http://mjean.life/posts/e714468f.html","excerpt":"","text":"排序算法的介绍排序也称排序算法(Sort Algorithm)，排序是将一组数据，依指定的顺序进行排列的过程。 排序的分类 内部排序: 指将需要处理的所有数据都加载到内部存储器(内存)中进行排序。 外部排序法： 数据量过大，无法全部加载到内存中，需要借助外部存储(文件等)进行排序。 常见的排序算法分类(见下图) 算法的时间复杂度 度量一个算法执行时间的两种方法：事后统计的方法 和 事前估算的方法 事后统计的方法 这种方法可行,，但是有两个问题：一是要想对设计的算法的运行性能进行评测，需要实际运行该程序；二是所 得时间的统计量依赖于计算机的硬件、软件等环境因素， 这种方式，要在同一台计算机的相同状态下运行，才能比较那个算法速度更快。 事前估算的方法 通过分析某个算法的时间复杂度来判断哪个算法更优. 时间频度：一个算法中的语句执行次数称为语句频度或时间频度。 时间复杂度(O(n))：时间频度忽略常数项 、低次项 、系数，即算法中的基本操作语句的重复执行次数是问题规模 n 的某个函数。 常见的时间复杂度(见下图) 如图的时间复杂度是逐渐增加的，我们应该避免时间复杂度为指数阶的算法。 平均时间复杂度和最坏时间复杂度 平均时间复杂度是指所有可能的输入实例均以等概率出现的情况下，该算法的运行时间。 最坏情况下的时间复杂度称最坏时间复杂度。一般讨论的时间复杂度均是最坏情况下的时间复杂度。这样做的 原因是：最坏情况下的时间复杂度是算法在任何输入实例上运行时间的界限，这就保证了算法的运行时间不会 比最坏情况更长。 平均时间复杂度和最坏时间复杂度是否一致，和算法有关(如下表) 排序法 平均时间 最差情形 稳定度 额外空间 备注 冒泡排序 O(n^2) O(n^2) 稳定 O(1) n小时较好 交换排序 O(n^2) O(n^2) 不稳定 O(1) n小时较好 选择排序 O(n^2) O(n^2) 不稳定 O(1) n小时较好 插入排序 O(n^2) O(n^2) 稳定 O(1) 大部分以排序时较好 基数排序 O(n^2) O(logRB) 稳定 O(n) B是真数（0-9）R是基数 希尔排序 O(nlogn) O(n^s) 1&lt;s&lt;2 不稳定 O(1) s是所选分组 快速排序 O(nlogn) O(n^2) 不稳定 O(nlogn) n大时较好 归并排序 O(nlogn) O(nlogn) 稳定 O(1) n大时较好 堆排序 O(nlogn) O(nlogn) 不稳定 O(1) n大时较好 算法的空间复杂度 类似于时间复杂度的讨论， 一个算法的空间复杂度(Space Complexity)定义为该算法所耗费的存储空间， 它也是问题规模 n 的函数。 空间复杂度(Space Complexity)是对一个算法在运行过程中临时占用存储空间大小的量度。 有的算法需要占用的临时工作单元数与解决问题的规模 n 有关， 它随着 n 的增大而增大， 当 n 较大时， 将占用较多的存储单元， 例如快速排序和归并排序算法, 基数排序就属于这种情况 在做算法分析时， 主要讨论的是时间复杂度。 因为从用户使用体验上看， 更看重的程序执行的速度。 一些缓存产品 (redis, memcache) 和算法(基数排序)本质就是用空间换时间。 冒泡排序 冒泡排序（Bubble Sorting）的基本思想是：通过对待排序序列从前向后（从下标较小的元素开始），依次比较相邻元素的值，若发现逆序则交换，使值较大的元素逐渐从前移向后部，就象水底下的气泡一样逐渐向上冒。 思路分析依次比较相邻的两个数，将比较小的数放在前面，比较大的数放在后面。 第一次比较：首先比较第一和第二个数，将小数放在前面，将大数放在后面。 比较第2和第3个数，将小数 放在前面，大数放在后面。 …… 如此继续，直到比较到最后的两个数，将小数放在前面，大数放在后面，重复步骤，直至全部排序完成 在上面一趟比较完成后，最后一个数一定是数组中最大的一个数，所以在比较第二趟的时候，最后一个数是不参加比较的。 在第二趟比较完成后，倒数第二个数也一定是数组中倒数第二大数，所以在第三趟的比较中，最后两个数是不参与比较的。 依次类推，每一趟比较次数减少依次 注意：因为排序的过程中，各元素不断接近自己的位置，如果一趟比较下来没有进行过交换，就说明序列有序，因此要在排序过程中设置一个标志 flag 判断元素是否进行过交换。从而减少不必要的比较。 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * 冒泡排序 * @author xhc * @date 2021/6/4 13:08 */ public class BubbleSort { public static void main(String[] args) { // int[] arr = {3,9,-1,10,-2}; //测试一下冒泡排序的速度，给八万个数据，测试 //创建一个80000个的随机的数组 int[] arr = new int[80000]; for (int i = 0; i &lt; 80000; i++) { arr[i] = (int) (Math.random()*800000); //生成【0,8000000】的数 } Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \"+ date1Str); //测试冒泡排序 bubbleSort(arr); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \"+ date2Str); // System.out.println(\"排序后\"); //System.out.println(Arrays.toString(arr)); } //将前面的冒泡排序算法，封装成一个方法 public static void bubbleSort(int[] arr){ //冒泡排序，时间复杂度O(n^2) boolean flag = false; //标识变量，表示是否进行过交换 int temp = 0; //临时变量 for (int i = 0; i &lt; arr.length - 1; i++) { for (int j = 0; j &lt; arr.length - 1 - i; j++) { //如果前面的数比后面的数大，则交换 if (arr[j] &gt; arr[j+1]){ flag = true; temp = arr[j]; arr[j] = arr[j+1]; arr[j+1] = temp; } } if (!flag){ //在一趟排序中，一次交换都没有发生过 break; }else { flag = false; //重置flag，进行下次判断 } } } } 小结： N个数字要排序完成，总共进行N-1趟排序，每 i 趟的排序次数为(N-i)次 每一趟排序的次数在逐渐的减少 如果我们发现在某趟排序中，没有发生一次交换， 可以提前结束冒泡排序 冒泡排序总的平均时间复杂度为：O(n^2) 选择排序 选择排序也属于内部排序法，是从欲排序的数据中，按指定的规则选出某一元素，再依规定交换位置后达到排序的目的。 思路分析 在一个长度为 N 的无序数组中，第一次遍历 n-1 个数找到最小的和第一个数交换。 第二次从下一个数开始遍历 n-2 个数，找到最小的数和第二个数交换。 重复以上操作直到第 n-1 次遍历，找到最小的数和第 n-1 个数交换，排序完成。 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * 选择排序 * @author xhc * @date 2021/6/4 14:35 */ public class SelectSort { public static void main(String[] args) { // int[] arr = {101,34,119,1}; int[] arr = new int[80000]; for (int i = 0; i &lt; 80000; i++) { arr[i] = (int) (Math.random()*800000); //生成【0,8000000】的数 } Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \"+ date1Str); selectSort(arr); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \"+ date2Str); // System.out.println(\"排序后~\"); // System.out.println(Arrays.toString(arr)); } public static void selectSort(int[] arr){ //选择排序的时间复杂度是O(n^2) for (int i = 0; i &lt; arr.length - 1; i++) { int minIndex = i; int min = arr[i]; for (int j = i + 1; j &lt; arr.length; j++) { if (min &gt; arr[j]){ //说明假定的最小值并不是最小值 min = arr[j]; // 重置min minIndex = j; // 重置minIndex } } //将最小值，放在arr[i],即交换 if (minIndex != i){ arr[minIndex] = arr[i]; arr[i] = min; } } } } 小结： N个数字要排序完成，总共进行N-1轮排序，每轮排序只进行 元素数 - 轮数 次比较 每一轮排序的元素数在逐渐的减少 选择排序总的平均时间复杂度为：O(n^2) 插入排序 插入式排序属于内部排序法，是对于欲排序的元素以插入的方式找寻该元素的适当位置，以达到排序的目的。 思路分析 把n个待排序的元素看成为一个有序表和一个无序表 开始时有序表中只包含一个元素，无序表中包含有n-1个元素 排序过程中每次从无序表中取出第一个元素，把它的排序码依次与有序表元素的排序码进行比较，将它插入到有序表中的适当位置，使之成为新的有序表。 1）定义一个变量insertVal，用来保存待插入的值，定义一个指针，一开始指向有序表的最后一个元素，用来查找合适的位置。 2）从数组的第二个元素开始往前比较，此时有序表中只有数组的第一个元素。即一开始用第二个数和他前面的一个比较，如果符合条件（比前面的大或者小，自定义），则将前面的第一个元素往后移一位，待排序的这个元素插入到合适的位置上。 3）然后再用第三个数和第二个比较，符合则将前面的第一个元素往后移一位，指针继续往前移动，继续往前比较，比如有 5个数 8，15，20，45, 17,17比45小，则将17位置上的值改为45，指针继续向前移动，17也比20小，则将原来45位置上的值改为20，当指针移动到15的位置上时，说明已经找到了位置，此时将17插入到15后面的位置，即原来20的位置上即可。 4）重复步骤 3），一直到数据全都排完。 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * 插入排序 * @author xhc * @date 2021/6/4 15:04 */ public class InsertSort { public static void main(String[] args) { // int[] arr = {101,34,119,1}; // insertSort(arr); // System.out.println(Arrays.toString(arr)); int[] arr = new int[80000]; for (int i = 0; i &lt; 80000; i++) { arr[i] = (int) (Math.random()*800000); //生成【0,8000000】的数 } Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \"+ date1Str); insertSort(arr); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \"+ date2Str); } public static void insertSort(int[] arr){ int insertVal = 0; int insertIndex = 0; for (int i = 1; i &lt; arr.length; i++) { //定义待插入的数 insertVal = arr[i]; insertIndex = i - 1; // 即arr[i]的前面这个数的下标 // 给insertVal 找到插入的位置 //说明 //1.insertIndex &gt;= 0 保证在给 insertVal 找插入位置，不越界 //2.insertVal &lt; arr[insertIndex] 待插入的数，还没有找到插入位置 //3。就需要将arr[insertIndex]后移 while (insertIndex &gt;= 0 &amp;&amp; insertVal &lt; arr[insertIndex]){ arr[insertIndex + 1] = arr[insertIndex]; insertIndex--; } //当退出while循环时，说明插入的位置找到，insertIndex + 1; if (insertIndex + 1 != i){ arr[insertIndex + 1] = insertVal; } } } } 小结： 每一次插入，待排序的元素都减一，有序序列的元素加一 插入排序总的平均时间复杂度为：O(n^2) 希尔排序 简单插入排序存在的问题 数组 arr = {2,3,4,5,6,1} ，这时需要插入的数 1(最小), 这样的过程是 {2,3,4,5,6,6} {2,3,4,5,5,6} {2,3,4,4,5,6} {2,3,3,4,5,6} {2,2,3,4,5,6} {1,2,3,4,5,6} 结论: 当需要插入的数是较小的数时，后移的次数明显增多，对效率有影响 希尔排序是希尔（Donald Shell）于 1959 年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入，排序经过改进之后的一个更高效的版本，也称为缩小增量排序。 思路分析 希尔排序是将待排序的数组元素按下标的一定增量（步长）分组 ，分成多个子序列，然后对各个子序列进行直接插入排序算法排序；然后依次缩减增量再进行排序，直到增量为1时，进行最后一次直接插入排序，排序结束。 增量的首次取值为 gap=length/2，缩小增量以 gap = gap/2 的方式。 举例说明：假设有这样一组数 {7,6,9,3,1,5,2,4} 1）以增量为 gap = length/2 = 4 开始进行分组： 7 1 6 5 9 2 3 4 2）然后我们对每一个分组进行插入排序： 1 7 5 6 2 9 3 4 此时数组中的数为{1,5,2,3,7,6,9,4} 3）缩小增量 gap = gap/2 = 2，进行分组： 1 2 7 9 5 3 6 4 4）然后我们对每一个分组进行插入排序： 1 2 7 9 3 4 5 6 此时数组中的数为{1,3,2,4,7,5,9,6} 5）缩小增量 gap = gap/2 = 1，进行分组并排序： 分组后：1 3 2 4 7 5 9 6 排序后：1 2 3 4 5 6 7 9 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * 希尔排序 * @author xhc * @date 2021/6/5 10:56 */ public class ShellSort { public static void main(String[] args) { // int[] arr = {7,5,1,2,6,4,9,3,8,0}; // shellSort2(arr); // System.out.println(Arrays.toString(arr)); int[] arr = new int[80000]; for (int i = 0; i &lt; 80000; i++) { arr[i] = (int) (Math.random()*800000); //生成【0,8000000】的数 } Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \"+ date1Str); //测试希尔排序 shellSort2(arr); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \"+ date2Str); } //交换式希尔排序 public static void shellSort(int[] arr){ int temp = 0; for (int gap = arr.length / 2;gap &gt; 0;gap /= 2){ for (int i = gap; i &lt; arr.length; i++) { //遍历各组中所有的元素（共gap组）步长 gap for (int j = i - gap; j &gt;= 0 ; j -= gap) { // 如果当前元素大于加上步长后的那个元素，就进行交换 if (arr[j] &gt; arr[j + gap]){ temp = arr[j]; arr[j] = arr[j + gap]; arr[j + gap] = temp; } } } } } //对交换式的希尔排序进行优化 -&gt; 移位法 public static void shellSort2(int[] arr){ //增量 gap，并逐步的缩小增量 for (int gap = arr.length / 2;gap &gt; 0;gap /= 2){ //从第 gap 个元素，逐个对其所在的组进行直接插入排序 for (int i = gap;i &lt; arr.length;i++){ int j = i; int temp = arr[j]; if (arr[j] &lt; arr[j - gap]){ while (j - gap &gt;=0 &amp;&amp; temp &lt; arr[j - gap]){ //移动 arr[j] = arr[j - gap]; j -= gap; } //当退出while后，就给temp找到插入的位置 arr[j] = temp; } } } } } 小结： 希尔排序时简单插入排序的一种改进 一开始增量是最大的，每一次排序之后，增量以原来的增量的一半进行缩小 最后一次增量肯定缩小为1 希尔排序总的平均时间复杂度为：O(nlogn) 快速排序 快速排序（Quicksort）是对冒泡排序的一种改进 思路分析 选择一个基数pivot，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。 再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 基数的选择可以选取任意数，这里选择最左边的数为基数pivot 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * 快速排序 * * @author xhc * @date 2021/6/5 14:05 */ public class QuickSort { public static void main(String[] args) { // int[] arr = {-9, 78, 0, 23, -567, 70, 0, 1, 555}; // quickSort(arr,0,arr.length - 1); // System.out.println(Arrays.toString(arr)); int[] arr = new int[30000000]; for (int i = 0; i &lt; 30000000; i++) { arr[i] = (int) (Math.random()*30000000); //生成【0,8000000】的数 } Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \" + date1Str); //测试快速排序 quickSort2(arr, 0, arr.length - 1); // System.out.println(Arrays.toString(arr)); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \" + date2Str); } public static void quickSort2(int[] arr, int start, int end) { if (start &lt; end) { //将数组中的第0个数字 设置为基准数 int pivot = arr[start]; //记录需要排序的下标 int low = start; int high = end; while (low &lt; high) { //右边的数比基准数大 则向左移动high指针 while (low &lt; high &amp;&amp; arr[high] &gt; pivot) { high--; }//退出此while循环说明当前a[high]&lt;stard arr[low] = arr[high];//用high位的数覆盖low位的数 //左边的数比基准数小 则向右移动low指针 while (low &lt; high &amp;&amp; arr[low] &lt;= pivot) { low++; }//退出此while循环说明当前a[low]&gt;stard arr[high] = arr[low]; } //low和high指针相遇时 将基准数赋给此下标处 arr[low] = pivot; //递归 //处理所有比基准数小的数字 quickSort(arr, start, low - 1); //处理所有比基准数大的数字 quickSort(arr, low + 1, end); } } } 小结： 快速排序算法当序列中元素的排列比较随机时效率最高，但是当序列中的元素接近有序时，会达到最坏时间复杂度O(n^2) 快速排序总的平均时间复杂度为：O(nlogn) 快速排序的基数可以是数列中的任何数，不过为了方便，一般取数列的最左边的数为基数 归并排序 归并排序（MERGE-SORT）是利用归并的思想实现的排序方法，该算法采用经典的分治（divide-and-conquer）策略（分治法将问题分(divide)成一些小的问题然后递归求解，而治(conquer)的阶段则将分的阶段得到的各答案”修补”在一起，即分而治之)。 分而治之 思路分析 将待排序的数列分解成若干个长度为1的子数列，这些子数列都是各自有序的，然后将这些数列两两合并；得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将他们两两合并；直到合并成一个数列为止； 分解时，先将数列按1/2的方式进行分解，然后用同样的方式进行向左和向右递归分解数列； 合并时，如何把分裂的元素归并成一个有序的序列呢？ 1）这里需要定义一个临时的数组temp[],用来存放排好序的序列。2）放置原则是：由于两个序列都已经有序，我们只需要从这两个序列的低位轮番比较，将比较结果小的值放置到temp[]临时数组中，然后继续拿出该值所在序列中的下一个元素比较，直到某个序列中没有元素后，将有剩余元素的序列中剩余的元素依次放置在temp[]临时数组后面即可。此时临时数组里面存放的序列是两个序列的有序合并，最后将临时数组拷贝给原数组即可。 代码实现import java.text.SimpleDateFormat; import java.util.Arrays; import java.util.Date; /** * @author xhc * @date 2021/6/6 13:12 */ public class MergeSort { public static void main(String[] args) { // int[] arr = {8,4,5,7,1,3,6,2}; // //归并排序需要一个额外空间 // mergeSort(arr,0,arr.length - 1,temp); int[] arr = new int[8]; for (int i = 0; i &lt; 8; i++) { arr[i] = (int) (Math.random()*30); //生成【0,8000000】的数 } System.out.println(Arrays.toString(arr)); int[] temp = new int[arr.length]; Date date1 = new Date(); SimpleDateFormat simpleDateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String date1Str = simpleDateFormat.format(date1); System.out.println(\"排序前的时间是 \"+ date1Str); //测试归并排序 mergeSort(arr,0,arr.length - 1,temp); Date date2 = new Date(); String date2Str = simpleDateFormat.format(date2); System.out.println(\"排序后的时间是 \"+ date2Str); System.out.println(Arrays.toString(arr)); } //分合并方法 public static void mergeSort(int[] arr,int left,int right,int[] temp){ if (left &lt; right){ int mid = (left + right) / 2; //中间索引 //向左递归进行分解 mergeSort(arr,left,mid,temp); //向右递归分解 mergeSort(arr,mid + 1,right,temp); //合并 merge(arr,left,mid,right,temp); } } /** * * 合并的方法 * @param arr 排序的原始数组 * @param left 左边有序序列的初始索引 * @param mid 中间索引 * @param right 右边索引 * @param temp 做中转的数组 */ public static void merge(int[] arr,int left,int mid,int right,int[] temp){ int i = left; //初始化 i 左边有序序列的初始索引 int j = mid + 1; //初始化 j，右边有序序列的初始索引 int t = left; //指向temp数组的当前索引 //（一） //先把左右两边（有序）的数据按照规则填充到temp数组 //直到左右两边的有序序列，有一边处理完毕为止 while (i &lt;= mid &amp;&amp; j &lt;= right){ //继续 //如果左边的有序序列的当前元素，小于等于右边有序序列的当前元素 //即将左边的当前元素，拷贝到temp数组 //然后 t++ i++ if (arr[i] &lt;= arr[j]){ temp[t] = arr[i]; t += 1; i += 1; }else { //反之，将右边有序序列的当前元素 拷贝到temp数组 temp[t] = arr[j]; t += 1; j += 1; } } //（二） //把有剩余数据的一边的数据依次全部填充到temp while (i &lt;= mid){ //左边的有序序列还有剩余的元素，就全部填充到temp temp[t] = arr[i]; t += 1; i += 1; } while (j &lt;= right){ temp[t] = arr[j]; t += 1; j += 1; } //（三） //将temp数组的元素拷贝到 arr //注意，并不是每次都拷贝所有 // t = 0; int tempLeft = left; while (tempLeft &lt;= right){ arr[tempLeft] = temp[tempLeft]; // t += 1; tempLeft += 1; } } } 小结： 当待排序列中有8个元素时，只需要归并7次，n个元素也就需要归并n-1次 可以看到，归并次数呈线性增长。相比冒泡、插入排序的呈指数增长，归并排序的效率还是挺快的 归并排序总的平均时间复杂度为：O(nlogn) 基数排序 基数排序（radix sort）属于“分配式排序”（distribution sort），又称“桶子法”（bucket sort）或 bin sort，顾 名思义，它是通过键值的各个位的值，将要排序的元素分配至某些“桶”中，达到排序的作用。 基数排序法是属于稳定性的排序基数排序法的是效率高的稳定性排序法。 基数排序(Radix Sort)是桶排序的扩展 基数排序是 1887 年赫尔曼·何乐礼发明的。它是这样实现的：将整数按位数切割成不同的数字，然后按每个 位数分别比较。 思路分析 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。 这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 举例说明 将数组 {53, 3, 542, 748, 14, 214} 使用基数排序, 进行升序排序 第一轮排序 {53, 3, 542, 748, 14, 214} 1)将每个元素的个位数取出，然后看这个数应该放在哪个对应的桶（一个一维数组） 2)按照这个桶的顺序（一维数组的下标依次取出数据，放入原来的数组） 个位 0 1 2 542 3 53、3 4 14、214 5 6 7 8 748 9 第二轮排序 {542,53,3,14,214,748} 1)将每个元素的十位数取出，然后看这个数应该放在哪个对应的桶（一个一维数组） 2)按照这个桶的顺序（一维数组的下标依次取出数据，放入原来的数组） 十位 0 3 1 14、214 2 3 4 542、748 5 53 6 7 8 9 第三轮排序 {3,14,214,542,748,53} 1)将每个元素的百位数取出，然后看这个数应该放在哪个对应的桶（一个一维数组） 2)按照这个桶的顺序（一维数组的下标依次取出数据，放入原来的数组） 百位 0 3、14、53 1 2 214 3 4 5 542 6 7 748 8 9 排序完毕! 代码实现package com.xhc.sort; import java.util.Arrays; /** * @author xhc * @date 2021/6/6 16:20 */ public class RadixSort { public static void main(String[] args) { int[] arr = {53,3,542,748,14,214}; radixSort(arr); } //基数排序方法 public static void radixSort(int[] arr){ //1.得到数组中最大数的位数 int max = arr[0]; //假设第一个数就是最大数 for (int i = 1;i &lt; arr.length;i++){ if (arr[i] &gt; max){ max = arr[i]; } } //得到最大数是几位数 int maxLength = (max + \"\").length(); //定义一个二维数组，表示10个桶，每个桶就是一个一维数组 //说明 //1.二维数组包含10个一维数组 //2.为了防止在放入数的时候，数据溢出，则每个一维数组，大小定为arr.length int[][] bucket = new int[10][arr.length]; //为了记录每个桶中，实际存放了多少个数据，我们定义一个一维数组来记录每个桶的每次放入的数据个数 //可以这里理解 //比如： bucketElementCount[0],记录的就是 bucket[0] 桶的放入数据个数 int[] bucketElementCount = new int[10]; //这里使用循环将代码处理 for (int i = 0; i &lt; maxLength; i++) { //第一轮（针对每个元素的个位进行排序处理）(每一轮都是重复这个过程，对应的位不一样) for (int j = 0;j &lt; arr.length;j++){ //取出每个元素的对应位的值 Math.pow(10,i) 10的i次方 int digitOfElement = arr[j] / (int) Math.pow(10,i) % 10; //放到对应的桶中 bucket[digitOfElement][bucketElementCount[digitOfElement]] = arr[j]; bucketElementCount[digitOfElement]++; } //按照这个桶的顺序（一位数组的下标依次取出数据，放入到原来的数组） int index = 0; //遍历每个桶，并将桶中的数据，放入到原数组 for (int k = 0;k &lt; bucketElementCount.length;k++){ //如果桶中有数据，才放入到原数组 if (bucketElementCount[k] != 0){ //循环该桶即第k个桶（即第k个一维数组）放入 for (int l = 0;l &lt; bucketElementCount[k];l++){ //取出元素放入到arr arr[index] = bucket[k][l]; index++; } } //第一轮处理后，需要将每个bucketElementCount[k] = 0 bucketElementCount[k] = 0; } System.out.println(\"第\"+(i+1)+\"轮\"+Arrays.toString(arr)); } } } 小结： 基数排序是对传统桶排序的扩展，速度很快. 基数排序是经典的空间换时间的方式，占用内存很大, 当对海量数据排序时，容易造成 OutOfMemoryError 。 基数排序是稳定的。 基数排序总的平均时间复杂度为：O(n^2) 堆排序 堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序，它的最坏，最好，平均时间复 杂度均为 O(nlogn)，它也是不稳定排序。 堆是具有以下性质的完全二叉树：每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆, 注意 : 没有 要求结点的左孩子的值和右孩子的值的大小关系。 每个结点的值都小于或等于其左右孩子结点的值，称为小顶堆。 一般升序采用大顶堆，降序采用小顶堆。 思路分析 将待排序序列构造成一个大顶堆 ； 此时，整个序列的最大值就是堆顶的根节点； 将根节点的值（最大值）与末尾元素进行交换，此时末尾就为最大值； 然后将剩余 n-1 个元素重新构造成一个堆，这样会得到 n 个元素的次小值。如此反复执行，便能得到一个有序序列。 代码实现import java.util.Arrays; /** * @author xhc * @date 2021/6/18 15:15 */ public class HeapSort { public static void main(String[] args) { int[] arr = {4, 6, 8, 5, 9, -1, 90, 89, 56, -99}; heapSort(arr); } //编写一个堆排序的方法 public static void heapSort(int[] arr) { int temp = 0; System.out.println(\"堆排序\"); //分步完成 // adjustHeap(arr,1,arr.length); // System.out.println(\"第一次\"+ Arrays.toString(arr)); // adjustHeap(arr,0,arr.length); // System.out.println(\"第二次\"+ Arrays.toString(arr)); //将无序序列构建成一个堆，根据升序降序需求选择大顶堆和小顶堆 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { adjustHeap(arr, i, arr.length); } /* * 2.将堆顶元素与末尾元素交换，将最大元素“沉”到数组末端 * 3.重新调整结构，使其满足定义，然后继续交换堆顶元素与当前末尾元素，反复执行调整 + 交换步骤，直到整个序列有序 * */ for (int j = arr.length - 1; j &gt; 0; j--) { //交换 temp = arr[j]; arr[j] = arr[0]; arr[0] = temp; adjustHeap(arr, 0, j); } System.out.println(Arrays.toString(arr)); } /** * * 将一个数组（二叉树），调整成一个大顶堆 * 功能 完成将以 i 对应的非叶子节点的树调整成大顶堆 * * @param arr 待调整的数组 * @param i 表示非叶子节点在数组中索引 * @param length 表示对多少个元素进行调整 */ public static void adjustHeap(int[] arr, int i, int length) { int temp = arr[i]; //先取出当前元素的值，保存临时变量 //开始调整 //说明 从左至右 从下至上调整 //1. k = i * 2 + 1 k是i节点的左子节点 for (int k = i * 2 + 1; k &lt; length; k = k * 2 + 1) { if (k + 1 &lt; length &amp;&amp; arr[k] &lt; arr[k + 1]) { //说明左子节点的值小于右子节点的值 k++; } if (arr[k] &gt; temp) { // 如果子节点大于父节点 arr[i] = arr[k]; //把较大的值赋给当前节点 i = k; //!!! i 指向 k，继续循环比较 } else { break; } } //当 for 循环结束后，我们已经将以 i 为父节点的树的最大值，放在了最顶（局部） arr[i] = temp; // 将temp值放到调整后的位置 } } 小结： 堆排序是一种选择排序 整体主要由构建初始堆+交换堆顶元素和末尾元素并重建堆两部分组成 最坏，最好，平均时间复 杂度均为 O(nlogn)","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"数据结构和算法","slug":"笔记/数据结构和算法","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://mjean.life/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"http://mjean.life/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"递归","slug":"datastructure3","date":"2021-06-21T16:06:29.000Z","updated":"2022-04-18T12:48:45.668Z","comments":true,"path":"posts/c6654282.html","link":"","permalink":"http://mjean.life/posts/c6654282.html","excerpt":"","text":"递归的概念递归就是方法自己调用自己，每次调用时传入不同的变量。递归有助于编程者解决复杂的问题，同时可以让代码变得简洁。 递归需要遵守的重要规则： 执行一个方法时，会在栈中开辟一个独立的空间。 每个空间的数据（方法的局部变量）是独立的，不会相互影响； 如果方法中使用的是引用类型变量(比如数组)，就会共享该引用类型的数据. 递归必须向退出递归的条件逼近，否则就是无限递归，出现StackOverflowError 当一个方法执行完毕，或者遇到return，就会返回，遵守谁调用，就将结果返回给谁，同时当方法执行完毕或者返回时，该方法也就执行完毕。 递归的应用递归用于解决什么样的问题： 各种数学问题如: 8 皇后问题 , 汉诺塔, 阶乘问题, 迷宫问题, 球和篮子的问题（google 编程大赛） 各种算法中也会使用到递归， 比如快排， 归并排序， 二分查找， 分治算法等 将用栈解决的问题 –&gt; 递归代码比较简洁 递归 - 迷宫问题 有一个迷宫地图，有一些可达的位置，也有一些不可达的位置（障碍、墙壁、边界）。从一个位置到下一个位置只能通过向上（或者向右、或者向下、或者向左）走一步来实现，有一个小球从起点出发，如何找到一条到达终点的通路。 思路分析 使用递归回溯来给小球找路 map 表示地图 i,j 表示从地图的哪个位置开始出发(1,1) 如果小球能到 map[6][5]位置，则说明通路找到 约定：当map[i][j]为 0 表示该点没有走过，当为 1 表示墙；2 表示通路可以走；3 表示点已经走过，但是走不通 在走迷宫时，需要确定一个策略（方法） 下-&gt;右-&gt;上-&gt;左(策略可以改，策略不同，走的路径不一定相同)，如果该点走不通，再回溯 代码实现/** * @author xhc * @date 2021/6/2 10:23 */ public class MiGong { public static void main(String[] args) { //先创建一个二维数组，模拟迷宫 //地图 int[][] map = new int[8][7]; //使用 1 表示墙 //上下全部置为 1 for (int i = 0; i &lt; 7; i++) { map[0][i] = 1; map[7][i] = 1; } //左右全部置为 1 for (int i = 0; i &lt; 8; i++) { map[i][0] = 1; map[i][6] = 1; } //设置挡板，1 表示 map[3][1] = 1; map[3][2] = 1; //输出地图 System.out.println(\"地图的情况\"); for (int i = 0; i &lt; 8; i++) { for (int j = 0; j &lt; 7; j++) { System.out.print(map[i][j]+ \" \"); } System.out.println(); } //setWay(map,1,1); setWay2(map,1,1); //输出新的地图，小球走过并标识过的递归 System.out.println(\"球走过并标识过的地图的情况\"); for (int i = 0; i &lt; 8; i++) { for (int j = 0; j &lt; 7; j++) { System.out.print(map[i][j]+ \" \"); } System.out.println(); } } //使用递归回溯来给小球找路 //说明 //1. map 表示地图 //2. i,j 表示从地图的哪个位置开始出发(1,1) //3. 如果小球能到 map[6][5]位置，则说明通路找到 //4. 约定：当map[i][j] 为 0 表示该点没有走过，当为 1 表示墙；2 表示通路可以走；3 表示点已经走过，但是走不通 //5. 在走迷宫时，需要确定一个策略（方法） 下-&gt;右-&gt;上-&gt;左，如果该点走不通，再回溯 /** * * @param map 表示地图 * @param i 从哪个位置开始找 * @param j * @return 如果找到通路，就返回true，否则返回false */ public static boolean setWay(int[][] map,int i,int j){ if (map[6][5] == 2){//通路已经找到 ok return true; }else { if (map[i][j] == 0){ //如果当前这个点还没有走过 //按照策略 下-&gt;右-&gt;上-&gt;左 走 map[i][j] = 2; //假定该点是可以走通的 if (setWay(map,i+1,j)){ //向下走 return true; }else if (setWay(map,i,j+1)){ //向右走 return true; }else if (setWay(map,i-1,j)){ //向上走 return true; }else if (setWay(map,i,j-1)){ //向左走 return true; }else { //说明该点是走不通的，是死路 map[i][j] = 3; return false; } }else { //如果map[i][j] != 0 ,可能是1,2，3 return false; } } } //修改找路的策略，改成 上右下左 public static boolean setWay2(int[][] map,int i,int j){ if (map[6][5] == 2){//通路已经找到 ok return true; }else { if (map[i][j] == 0){ //如果当前这个点还没有走过 //按照策略 下-&gt;右-&gt;上-&gt;左 走 map[i][j] = 2; //假定该点是可以走通的 if (setWay2(map,i-1,j)){ //向上走 return true; }else if (setWay2(map,i,j+1)){ //向右走 return true; }else if (setWay2(map,i+1,j)){ //向下走 return true; }else if (setWay2(map,i,j-1)){ //向左走 return true; }else { //说明该点是走不通的，是死路 map[i][j] = 3; return false; } }else { //如果map[i][j] != 0 ,可能是1,2，3 return false; } } } } 递归 - 八皇后问题 八皇后问题，是一个古老而著名的问题，是回溯算法的典型案例。该问题是国际西洋棋棋手马克斯·贝瑟尔于 1848 年提出：在 8×8 格的国际象棋上摆放八个皇后，使其不能互相攻击，即：任意两个皇后都不能处于同一行、 同一列或同一斜线上，问有多少种摆法 思路分析 第一个皇后先放第一行第一列 第二个皇后放在第二行第一列，然后判断是否 OK， 如果不 OK，继续放在第二列、第三列、依次把所有列都放完，找到一个合适的位置 继续第三个皇后，还是第一列、第二列……直到第 8 个皇后也能放在一个不冲突的位置，算是找到了一个正确解 当得到一个正确解时，在栈回退到上一个栈时，就会开始回溯，即将得到第一个皇后，放到第一列的所有正确解， 全部得到 然后回头继续第一个皇后放第二列，后面继续循环执行 1,2,3,4 的步骤 说明： 可以使用一个一维数组来表示皇后在棋盘的位置，就是一维数组的下标 + 1 的值， 就是第某个皇后。然后该下标所对应的值 + 1 就是这个皇后所在的列。 例如：一维数组 arr[8]，arr[i]=val =&gt; 表示 第 i+1 个皇后，放在第 i+1 行的 第 val+1 列 代码实现/** * @author xhc * @date 2021/6/2 13:39 */ public class Queen8 { //定义一个max表示共有多少个皇后 int max = 8; //定义数组array，保存皇后放置位置的结果，比如 arr = {0,4,7,5,2,6,1,3} int[] array = new int[max]; static int count = 0; static int judgeCount = 0; public static void main(String[] args) { //测试 8皇后是否正确 Queen8 queen8 = new Queen8(); queen8.check(0); System.out.println(\"一共有\"+count+\"解法\"); System.out.println(\"一共判断冲突的次数是\"+judgeCount); } //编写一个方法，放置第n个皇后 //特别注意：check 是每一次递归时，进入到check中 都有一次for循环 private void check(int n){ if (n == max){ // n=8,其实8个皇后已然放好 print(); return; } //依次放入皇后，并判断是否冲突 for (int i = 0; i &lt; max; i++) { //先把当前的这个皇后 n，放入到该行的第1列 array[n] = i; //判断当放置第n个皇后到i列时，是否冲突 if (judge(n)){ //不冲突 //接着放n+1个皇后，即开始递归 check(n+1); } //如果冲突，就继续执行 array[n] = i;即将第n个皇后，放置在本行的后移的一个位置 } } //查看当我们放置第 n 个皇后，就去检测该皇后是否和前面已经摆放的皇后冲突 /** * * @param n 表示第n个皇后 * @return */ private boolean judge(int n){ judgeCount++; for (int i = 0; i &lt; n; i++) { //说明 //1. array[i] == array[n] 表示判断 第 n个 皇后是否和前面的n-1个皇后在同一列 //2. Math.abs(n - i) == Math.abs(array[n] - array[i]) 表示判断 第 n个 皇后是否和前面的n-1个皇后在同一斜线 if (array[i] == array[n] || Math.abs(n - i) == Math.abs(array[n] - array[i])){ return false; } } return true; } //写一个方法，可以将皇后摆放的位置输出 private void print(){ for (int i = 0; i &lt; array.length; i++) { System.out.print(array[i] + \" \"); } count++; System.out.println(); } } 对check()递归回溯的理解：在找到第一组正确的结果后，会返回到上一个栈，会继续执行上一个栈还未执行完的代码，即执行完check()所在的for循环，而for循环的作用就是将皇后依次摆放在各个列，所以在找到第一组结果后，程序会继续将剩余未摆放的列继续尝试摆放，直到所有的列全部走完，当走完后就回到上一个栈，如果进入if语句，就进入递归。重复这个过程。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"数据结构和算法","slug":"笔记/数据结构和算法","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://mjean.life/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"http://mjean.life/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"数据结构：栈","slug":"datastructure2","date":"2021-06-20T13:47:02.000Z","updated":"2022-04-18T12:48:45.807Z","comments":true,"path":"posts/42fe3134.html","link":"","permalink":"http://mjean.life/posts/42fe3134.html","excerpt":"","text":"栈基本介绍 栈的英文为(stack) 栈是一个先入后出(FILO-First In Last Out)的有序列表。 栈(stack)是限制线性表中元素的插入和删除只能在线性表的同一端进行的一种特殊线性表。 允许插入和删除的 一端，为变化的一端，称为栈顶(Top)，另一端为固定的一端，称为栈底(Bottom)。 根据栈的定义可知，最先放入栈中元素在栈底，最后放入的元素在栈顶，而删除元素刚好相反，最后放入的元素最先删除，最先放入的元素最后删除。 入栈 出栈 应用场景 子程序的调用：在跳往子程序前，会先将下个指令的地址存到堆栈中，直到子程序执行完后再将地址取出，以回到原来的程序中。 处理递归调用：和子程序的调用类似，只是除了储存下一个指令的地址外，也将参数、区域变量等数据存入堆栈中。 表达式的转换[中缀表达式转后缀表达式]与求值(实际解决)。 二叉树的遍历。 图形的深度优先(depth 一 first)搜索法。 快速入门 用数组模拟栈的使用，由于栈是一种有序列表，当然可以使用数组的结构来储存栈的数据内容， 下面我们就用数组模拟栈的出栈，入栈等操作。 数组模拟栈思路分析： 使用数组来模拟栈 定义一个 top 来表示栈顶，初始化为 -1 入栈的操作，当有数据加入到栈时， top++; stack[top] = data; 出栈的操作， int value = stack[top]; top--, return value 代码实现： import java.util.Scanner; /** * @author xhc * @date 2021/5/25 11:24 */ public class ArrayStackDemo { public static void main(String[] args) { //测试 ArrayStack 是否正确 //先创建一个 ArrayStack 对象表示栈 ArrayStack stack = new ArrayStack(4); String key= \"\"; boolean loop = true; //判断是否退出菜单 Scanner scanner = new Scanner(System.in); while (loop){ System.out.println(\"show: 表示显示栈\"); System.out.println(\"exit: 退出程序\"); System.out.println(\"push: 表示添加数据栈（入栈）\"); System.out.println(\"pop: 表示从栈取出数据（出栈）\"); System.out.println(\"请输入你的选择\"); key = scanner.next(); switch (key){ case \"show\": stack.list(); break; case \"push\": System.out.println(\"请输入一个数\"); int value = scanner.nextInt(); stack.push(value); break; case \"pop\": try{ int res = stack.pop(); System.out.printf(\"出栈的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case \"exit\": scanner.close(); loop = false; break; default: break; } } System.out.println(\"程序退出了\"); } } //定义一个 ArrayStack 类 表示栈 class ArrayStack{ private int maxSize; //栈的大小 private int[] stack; //数组，数组模拟栈，数据就放在该数组 private int top = -1; //top表示栈顶，初始化为-1 //构造器 public ArrayStack(int maxSize){ this.maxSize = maxSize; stack = new int[this.maxSize]; } //栈满 public boolean isFull(){ return top == maxSize - 1; } //栈空 public boolean isEmpty(){ return top == -1; } //入栈 push public void push(int value){ //先判断栈是否满 if (isFull()){ System.out.println(\"栈满\"); return; } top++; stack[top] = value; } //出栈 pop public int pop(){ //先判断栈是否空 if (isEmpty()){ //抛出异常 throw new RuntimeException(\"栈空，没有数据\"); } int value = stack[top]; top--; return value; } //遍历栈，遍历时需要从栈顶开始显示数据 public void list(){ if (isEmpty()){ System.out.println(\"栈空，没有数据\"); return; } //需要从栈顶开始显示数据 for (int i = top; i &gt;= 0; i--) { System.out.printf(\"stack[%d]=%d\\n\",i,stack[i]); } } } 用数组模拟栈，创建栈的时候就要声明大小，不是很方便，下面用单链表来模拟栈 单链表模拟栈思路分析： 定义一个 top 节点作为辅助指针，用来表示链表最后入栈的元素 入栈时： 1）如果链表为空，就直接将入栈的节点作为第一个节点，并且将top指向该节点； ​ top = node; 2）如果链表不为空，就将入栈的节点的next域指向链表的top指针指向的节点，然后再将top指针指向该节点； ​ node.setNext(top); ​ top = node; 出栈时：top指针指向的节点就是最后入栈的节点，也是最先出栈的节点，所以直接取出，然后将top指针后移到下一个节点即可 top.getData() top = top.getNext() 遍历时：定义一个 temp 节点作为辅助指针 ，从 top 开始遍历即可。 代码实现： import java.util.Scanner; /** * @author xhc * @date 2021/5/26 10:26 */ public class LinkedListStackDemo { public static void main(String[] args) { LinkedListStack linkedListStack = new LinkedListStack(); String key= \"\"; boolean loop = true; //判断是否退出菜单 Scanner scanner = new Scanner(System.in); while (loop){ System.out.println(\"show: 表示显示栈\"); System.out.println(\"exit: 退出程序\"); System.out.println(\"push: 表示添加数据栈（入栈）\"); System.out.println(\"pop: 表示从栈取出数据（出栈）\"); System.out.println(\"请输入你的选择\"); key = scanner.next(); switch (key){ case \"show\": linkedListStack.list(); break; case \"push\": System.out.println(\"请输入一个数\"); int value = scanner.nextInt(); linkedListStack.push(value); break; case \"pop\": try{ int res = linkedListStack.pop(); System.out.printf(\"出栈的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case \"exit\": scanner.close(); loop = false; break; default: break; } } System.out.println(\"程序退出了\"); } } class LinkedListStack{ Node top = null; //栈空 public boolean isEmpty(){ return top == null; } //入栈 push public void push(int value){ Node node = new Node(value); if (top == null){ top = node; }else { node.setNext(top); top = node; } } //出栈 pop public int pop(){ //先判断栈是否空 if (isEmpty()){ //抛出异常 throw new RuntimeException(\"栈空，没有数据\"); } int value = top.getData(); top = top.getNext(); return value; } //遍历栈，遍历时需要从栈顶开始显示数据 public void list(){ if (isEmpty()){ System.out.println(\"栈空，没有数据\"); return; } Node temp = top; //需要从栈顶开始显示数据 while (temp != null){ System.out.println(temp.getData()); temp = temp.getNext(); } } } class Node{ private int data; private Node next; public Node(int data){ this.data = data; } public int getData() { return data; } public void setData(int data) { this.data = data; } public Node getNext() { return next; } public void setNext(Node next) { this.next = next; } } 栈实现综合计算器（中缀表达式） 使用栈来实现综合计算器 思路分析 创建两个栈，一个为数栈，用来存放数字；另外一个为符号栈，用来存放符号 通过一个 index 值（索引），来遍历我们的表达式 如果我们发现是一个数字，就直接入数栈 如果发现扫描到是一个符号, 就分如下情况 3.1 如果发现当前的符号栈为空，就直接入栈 3.2 如果符号栈有操作符，就进行比较，如果当前的操作符的优先级小于或者等于栈中的操作符， 就需要从数栈中pop出两个数，在从符号栈中pop出一个符号，进行运算，将得到结果，入数栈，然后将当前的操作符入符号栈， 如果当前的操作符的优先级大于栈中的操作符， 就直接入符号栈 当表达式扫描完毕，就顺序的从数栈和符号栈中pop出相应的数和符号，并运行 最后在数栈只有一个数字，就是表达式的结果 代码实现/** * @author xhc * @date 2021/5/27 10:38 */ public class Calculator { public static void main(String[] args) { String expression = \"7*2*2-5+1-5+3-4\"; //创建两个栈，一个数栈，一个符号栈 ArrayStack2 numStack = new ArrayStack2(10); ArrayStack2 operStack = new ArrayStack2(10); //定义相关的变量 int index = 0; //用于扫描 int num1 = 0; int num2 = 0; int oper =0; int res = 0; char ch =' '; //将每次扫描得到char保存到 ch String keepNum=\"\"; //用于拼接多位数 //用 while 循环 扫描 expression while (true){ //依次得到 expression 的每一个字符 ch = expression.substring(index,index+1).charAt(0); //判断ch是什么，然后做相应的处理 if (operStack.isOper(ch)) {//如果是运算符 //判断当前的符号栈是否为空 if (!operStack.isEmpty()){ //如果符号栈有操作符，就进行比较，如果当前的操作符的优先级小于或者等于栈中的操作符，就需要从数栈中pop出两个数 //在符号栈中pop出一个符号，进行运算，将得到结果，入数栈，然后当前的操作符入符号栈 if (operStack.priority(ch) &lt;= operStack.priority(operStack.peek())){ num1 = numStack.pop(); num2 = numStack.pop(); oper = operStack.pop(); res = numStack.cal(num1,num2,oper); //把运算结果入数栈 numStack.push(res); //然后吧当前的操作符入符号栈 operStack.push(ch); }else { //如果当前的操作符的优先级大于栈中的操作符 operStack.push(ch); } }else { //如果为空直接入符号栈 operStack.push(ch); } }else { //如果是数，则直接入数栈 //numStack.push(ch - 48); //分析思路 //1.当处理多位数时，不能发现是一个数就立即入栈，因为他可能是多位数 //2.在处理数时，需要向expression的表达式的index后看一位，如果是数就继续扫描，如果是符号就入栈 //3.我们需要定义一个字符变量，用于拼接 //处理多位数 keepNum += ch; //如果ch已经是expression的最后一位，就直接入栈 if (index == expression.length()-1){ numStack.push(Integer.parseInt(keepNum)); }else { //判断下一个字符是不是数字，如果是数字，就继续扫描，如果是运算符，则入栈 if (operStack.isOper(expression.substring(index + 1, index + 2).charAt(0))) { //如果后一位是运算符 则入栈 numStack.push(Integer.parseInt(keepNum)); //重要：keepNum清空 keepNum = \"\"; } } } //index + 1 ，并判断是否扫描到expression最后 index++; if (index &gt;= expression.length()){ break; } } //当表达式扫描完毕，就顺序的从 数栈和符号栈 中pop出相应的数和符号，并运行 while (true){ //如果符号栈为空，则计算到最后的结果，数栈中只有一个数字 if (operStack.isEmpty()){ break; } num1 = numStack.pop(); num2 = numStack.pop(); oper = operStack.pop(); res = numStack.cal(num1,num2,oper); numStack.push(res); } //将数栈最后的数，pop出就是结果 int res2 = numStack.pop(); System.out.println(\"表达式\" + expression + \"=\" + res2); } } //先创建一个栈 class ArrayStack2{ private int maxSize; //栈的大小 private int[] stack; //数组，数组模拟栈，数据就放在该数组 private int top = -1; //top表示栈顶，初始化为-1 //构造器 public ArrayStack2(int maxSize){ this.maxSize = maxSize; stack = new int[this.maxSize]; } //栈满 public boolean isFull(){ return top == maxSize - 1; } //栈空 public boolean isEmpty(){ return top == -1; } //入栈 push public void push(int value){ //先判断栈是否满 if (isFull()){ System.out.println(\"栈满\"); return; } top++; stack[top] = value; } //出栈 pop public int pop(){ //先判断栈是否空 if (isEmpty()){ //抛出异常 throw new RuntimeException(\"栈空，没有数据\"); } int value = stack[top]; top--; return value; } //增加一个方法，得到栈顶的值，不出栈 public int peek(){ return stack[top]; } //遍历栈，遍历时需要从栈顶开始显示数据 public void list(){ if (isEmpty()){ System.out.println(\"栈空，没有数据\"); return; } //需要从栈顶开始显示数据 for (int i = top; i &gt;= 0; i--) { System.out.printf(\"stack[%d]=%d\\n\",i,stack[i]); } } //返回运算符的优先级，优先级是程序员来确定，优先级使用数字表示 //数字越大，则优先级越高 public int priority(int oper){ if (oper == '*' || oper == '/'){ return 1; }else if (oper == '+' || oper == '-'){ return 0; }else { return -1; //假定目前的表达式只有 + ，-， *， / } } //判断是不是一个运算符 public boolean isOper(char val){ return val == '+' || val == '-' || val == '*' || val == '/'; } //计算方法 public int cal(int num1,int num2,int oper){ int res = 0;//res用于存放计算的结果 switch (oper){ case '+': res = num1 + num2; break; case '-': res = num2 - num1; break; case '*': res = num1 * num2; break; case '/': res = num2 / num1; break; default: break; } return res; } } 多位数的处理思路是： 当处理多位数时，不能发现是一个数就立即入栈，因为他可能是多位数 在处理数时，需要向expression的表达式的index后看一位，如果是数就继续扫描，如果是符号就入栈 我们需要定义一个字符变量，用于拼接 逆波兰计算器 输入一个逆波兰表达式(后缀表达式)，使用栈(Stack), 计算其结果 支持小括号和多位数整数，因为这里我们主要讲的是数据结构，因此计算器进行简化，只支持对整数的计算 思路分析 例如: (3+4)×5-6 对应的后缀表达式就是 3 4 + 5 × 6 - , 针对后缀表达式求值步骤如下: 先将”3 4 + 5 * 6 - “ =&gt; 放到 ArrayList中 对ArrayList 从左至右扫描，将 3 和 4 压入堆栈； 遇到+运算符，因此弹出 4 和 3（4 为栈顶元素，3 为次顶元素），计算出 3+4 的值，得 7，再将 7 入栈； 将 5 入栈； 接下来是×运算符，因此弹出 5 和 7，计算出 7×5=35，将 35 入栈； 将 6 入栈； 最后是-运算符，计算出 35-6 的值，即 29，由此得出最终结果 代码实现import java.util.ArrayList; import java.util.List; import java.util.Stack; /** * @author xhc * @date 2021/5/28 10:09 */ public class PolandNotation { public static void main(String[] args) { /** //先定义一个逆波兰表达式 //1.为了方便，逆波兰表达式的数字和符号使用空格隔开 // String suffixExpression = \"30 4 + 5 * 6 -\"; String suffixExpression = \"4 5 * 8 - 60 + 8 2 / +\"; //思路 //1.先将\"3 4 + 5 * 6 - \" =&gt; 放到 ArrayList中 //2.将ArrayList 传递给一个方法，遍历ArrayList 配合栈 完成计算 List&lt;String&gt; rpnList = getListString(suffixExpression); System.out.println(\"rpnList=\"+rpnList); int res = calculate(rpnList); System.out.println(\"计算的结果是=\" + res); */ } //完成对逆波兰表达式的运算 /** * 1)从左至右扫描，将3和4压入堆栈 * 2）遇到+运算符，因此弹出4和3（4为栈顶元素，3为次顶元素），计算出3+4的值，得7，再将7入栈， * 3）将5入栈 * 4）接下来是x运算符，因此弹出5和7，计算出7*5=35，将35入栈 * 5）将6入栈 * 6）最后是 - 运算符，计算出35-6的值，即29，由此得出最终结果 */ public static int calculate(List&lt;String&gt; ls){ //创建一个栈 Stack&lt;String&gt; stack = new Stack&lt;&gt;(); //遍历 ls for (String item: ls){ //这里是用正则表达式来取数 if (item.matches(\"\\\\d+\")){//匹配的是多位数 //入栈 stack.push(item); }else { //pop出两个数，并运算，再入栈 int num2 = Integer.parseInt(stack.pop()); int num1 = Integer.parseInt(stack.pop()); int res = 0; if (item.equals(\"+\")){ res = num1 + num2; }else if (item.equals(\"-\")){ res = num1 - num2; }else if (item.equals(\"*\")){ res = num1 * num2; }else if (item.equals(\"/\")){ res = num1 / num2; }else { throw new RuntimeException(\"运算符有误\"); } //把res 入栈 stack.push(\"\"+res); } } //最后留在stack中的数据是运算结果 return Integer.parseInt(stack.pop()); } } //编写一个类 可以返回一个运算符 对应的优先级 class Operation{ private static int ADD = 1; private static int SUB = 1; private static int MUL = 2; private static int DIV = 2; //写一个方法，返回对应的优先级数字 public static int getValue(String operation){ int result = 0; switch (operation){ case \"+\": result = ADD; break; case \"-\": result = SUB; break; case \"*\": result = MUL; break; case \"/\": result = DIV; break; default: System.out.println(\"不存在该运算符\"); break; } return result; } } 中缀表达式转换为后缀表达式 大家看到，后缀表达式适合计算式进行运算，但是人却不太容易写出来，尤其是表达式很长的情况下，因此在开发中，我们需要将 中缀表达式转成后缀表达式。 思路分析 初始化两个栈：运算符栈 s1 和储存中间结果的栈 s2； 从左至右扫描中缀表达式； 遇到操作数时，将其压 s2； 遇到运算符时，比较其与 s1 栈顶运算符的优先级： 1）如果 s1 为空，或栈顶运算符为左括号“(”，则直接将此运算符入栈； 2）否则，若优先级比栈顶运算符的高，也将运算符压入 s1； 3）否则，将 s1 栈顶的运算符弹出并压入到 s2 中，再次转到(4-1)与 s1 中新的栈顶运算符相比较； 遇到括号时： 1）如果是左括号“(”，则直接压入 s1 2）如果是右括号“)”，则依次弹出 s1 栈顶的运算符，并压入 s2，直到遇到左括号为止，此时将这一对括号丢弃 重复步骤 2 至 5，直到表达式的最右边 将 s1 中剩余的运算符依次弹出并压入 s2 依次弹出 s2 中的元素并输出，结果的逆序即为中缀表达式对应的后缀表达式 举例说明将中缀表达式“1+((2+3)×4)-5”转换为后缀表达式的过程如下 扫描到的元素 s2（栈底 -&gt; 栈顶） s1（栈底 -&gt; 栈顶） 说明 1 1 空 数字，直接入栈 + 1 + s1为空，运算符直接入栈 ( 1 + ( 左括号，直接入栈 ( 1 + ( ( 同上 2 1 2 + ( ( 数字 + 1 2 + ( ( + s1栈顶为左括号，运算符直接入栈 3 1 2 3 + ( ( + 数字 ) 1 2 3 + + ( 右括号，弹出运算符直至遇到左括号 X 1 2 3 + + ( X s1栈顶为左括号，运算符直接入栈 4 1 2 3 + 4 + ( X 数字 ) 1 2 3 + 4 X + 右括号，弹出运算符直至遇到左括号 - 1 2 3 + 4 X + - - 与 + 优先级相同，因此弹出 +，再压入 - 5 1 2 3 + 4 X + 5 - 数字 到达最右端 1 2 3 + 4 X + 5 - 空 s1中剩余的运算符 因此结果为：”1 2 3 + 4 X + 5 -“ 代码实现import java.util.ArrayList; import java.util.List; import java.util.Stack; /** * @author xhc * @date 2021/5/28 10:09 */ public class PolandNotation { public static void main(String[] args) { //完成将一个中缀表达式转后缀表达式的功能 //说明 //1.1+((2+3)*4)-5 =&gt; 1 2 3 + 4 * + 5 - //2.因为直接对str 进行操作，不方便，因此先将“1+((2+3)*4)-5” =》 中缀的表达式对应的List // 即 “1+((2+3)*4)-5” =》ArrayList [1,+,(,(,2,+,3,),*,4,),-,5] //3.将得到的中缀表达式对应的List =》 后缀表达式对应的list // 即ArrayList [1,+,(,(,2,+,3,),*,4,),-,5] =》 即ArrayList [1,2,3,+,4,*,+,5,-] String expression = \"1+((2+3)*4)-5\"; List&lt;String&gt; infixExpressionList = toInfixExpressionList(expression); System.out.println(\"中缀表达式对应的List\"+infixExpressionList); List&lt;String&gt; parseSuffixExpressionList = parseSuffixExpressionList(infixExpressionList); System.out.println(\"后缀表达式对应的List\"+parseSuffixExpressionList); System.out.println(\"expression=\"+calculate(parseSuffixExpressionList)); /** //先定义一个逆波兰表达式 //1.为了方便，逆波兰表达式的数字和符号使用空格隔开 // String suffixExpression = \"30 4 + 5 * 6 -\"; String suffixExpression = \"4 5 * 8 - 60 + 8 2 / +\"; //思路 //1.先将\"3 4 + 5 * 6 - \" =&gt; 放到 ArrayList中 //2.将ArrayList 传递给一个方法，遍历ArrayList 配合栈 完成计算 List&lt;String&gt; rpnList = getListString(suffixExpression); System.out.println(\"rpnList=\"+rpnList); int res = calculate(rpnList); System.out.println(\"计算的结果是=\" + res); */ } // 将得到的中缀表达式对应的List =》 后缀表达式对应的list // 即ArrayList [1,+,(,(,2,+,3,),*,4,),-,5] =》 即ArrayList [1,2,3,+,4,*,+,5,-] public static List&lt;String&gt; parseSuffixExpressionList(List&lt;String&gt; ls){ //定义两个栈 Stack&lt;String&gt; s1 = new Stack&lt;String&gt;(); //符号栈 //说明：因为s2这个栈，在整个转换过程中，没有pop操作，而且后面我们还需要逆序输出 //因此比较麻烦，这里我们就不用Stack&lt;String&gt; 直接使用List&lt;String&gt; ArrayList&lt;String&gt; s2 = new ArrayList&lt;&gt;(); //遍历 ls for (String item : ls){ //如果是一个数，就加入s2 if(item.matches(\"\\\\d+\")){ s2.add(item); }else if (item.equals(\"(\")){ s1.push(item); }else if (item.equals(\")\")){ //如果是右括号“）”，则依次弹出s1栈顶的运算符，并压入s2，直到遇到左括号为止，此时将这一对括号丢弃 while (!s1.peek().equals(\"(\")){ s2.add(s1.pop()); } s1.pop();//!!!将（ 弹出s1栈，消除小括号 }else { //当item的优先级小于等于 s1 栈顶运算符，将 s1 栈顶的运算弹出并加入到s2中，再次转到（4.1）与s1中新的栈顶运算符相比较 //问题：我们缺少一个比较优先级高低的方法 while (s1.size() != 0 &amp;&amp; Operation.getValue(s1.peek()) &gt;= Operation.getValue(item)){ s2.add(s1.pop()); } //还需要将item压入栈 s1.push(item); } } //将 s1 中剩余的运算符依次弹出并加入 s2 while (s1.size() != 0){ s2.add(s1.pop()); } return s2; } //将中缀表达式转成对应的List public static List&lt;String&gt; toInfixExpressionList(String s){ //定义一个List，存放中缀表达式 对应的内容 ArrayList&lt;String&gt; ls = new ArrayList&lt;&gt;(); int i = 0;//这是一个指针，用于遍历 中缀表达式字符串 String str; //对多位数的拼接 char c;//每遍历到一个字符，就放入到c do { //如果c是一个非数字，就加入到 ls if ((c=s.charAt(i))&lt;48 || (c=s.charAt(i)) &gt; 57){ ls.add(\"\"+c); i++; }else {//如果是一个数，需要考虑多位数 str = \"\"; //先将str 置成 \"\" while (i &lt; s.length() &amp;&amp; (c=s.charAt(i)) &gt;=48 &amp;&amp; (c=s.charAt(i)) &lt;= 57){ str += c; //拼接 i++; } ls.add(str); } }while (i &lt; s.length()); return ls;//返回 } //将一个逆波兰表达式，依次将数据和运算符放入到 ArrayList 中 public static List&lt;String&gt; getListString(String suffixExpression){ //将 suffixExpression 分割 String[] split = suffixExpression.split(\" \"); ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(); for (String ele : split){ list.add(ele); } return list; } //完成对逆波兰表达式的运算 /** * 1)从左至右扫描，将3和4压入堆栈 * 2）遇到+运算符，因此弹出4和3（4为栈顶元素，3为次顶元素），计算出3+4的值，得7，再将7入栈， * 3）将5入栈 * 4）接下来是x运算符，因此弹出5和7，计算出7*5=35，将35入栈 * 5）将6入栈 * 6）最后是 - 运算符，计算出35-6的值，即29，由此得出最终结果 */ public static int calculate(List&lt;String&gt; ls){ //创建一个栈 Stack&lt;String&gt; stack = new Stack&lt;&gt;(); //遍历 ls for (String item: ls){ //这里是用正则表达式来取数 if (item.matches(\"\\\\d+\")){//匹配的是多位数 //入栈 stack.push(item); }else { //pop出两个数，并运算，再入栈 int num2 = Integer.parseInt(stack.pop()); int num1 = Integer.parseInt(stack.pop()); int res = 0; if (item.equals(\"+\")){ res = num1 + num2; }else if (item.equals(\"-\")){ res = num1 - num2; }else if (item.equals(\"*\")){ res = num1 * num2; }else if (item.equals(\"/\")){ res = num1 / num2; }else { throw new RuntimeException(\"运算符有误\"); } //把res 入栈 stack.push(\"\"+res); } } //最后留在stack中的数据是运算结果 return Integer.parseInt(stack.pop()); } } //编写一个类 可以返回一个运算符 对应的优先级 class Operation{ private static int ADD = 1; private static int SUB = 1; private static int MUL = 2; private static int DIV = 2; //写一个方法，返回对应的优先级数字 public static int getValue(String operation){ int result = 0; switch (operation){ case \"+\": result = ADD; break; case \"-\": result = SUB; break; case \"*\": result = MUL; break; case \"/\": result = DIV; break; default: System.out.println(\"不存在该运算符\"); break; } return result; } } 注意：这里的实现中，将存放中间的s2定义成一个list，因为如果是栈的话，根据后进先出的特点，输出来的结果还得经过逆序转换才能得到正确的结果，所以这里将s2定义为list，得到的结果就是正确结果，无需进行逆序。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"数据结构和算法","slug":"笔记/数据结构和算法","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://mjean.life/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"http://mjean.life/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"数据结构：稀疏数组、队列、链表","slug":"datastructure1","date":"2021-06-10T03:11:34.000Z","updated":"2022-04-18T12:48:45.833Z","comments":true,"path":"posts/cc9b6bbf.html","link":"","permalink":"http://mjean.life/posts/cc9b6bbf.html","excerpt":"","text":"数据结构介绍数据结构是一门研究组织数据方式的学科。 数据结构包括：线性结构和非线性结构。 线性结构 线性结构作为最常用的数据结构，其特点是数据元素之间存在一对一的线性关系。 线性结构有两种不同的存储结构，即顺序存储结构(数组)和链式存储结构(链表)。顺序存储的线性表称为顺序表，顺序表中的存储元素是连续的。 链式存储的线性表称为链表，链表中的存储元素不一定是连续的，元素节点中存放数据元素以及相邻元素的地址信息 。 线性结构常见的有：数组、队列、链表和栈 非线性结构非线性结构包括：二维数组，多维数组，广义表，树结构，图结构。 稀疏数组实例引入在五子棋程序中，一般有存盘退出和续上盘的功能。 分析问题：因为该二维数组的很多值是默认值 0, 因此记录了很多没有意义的数据，所以可以使用稀疏数组来节省空间。 基本介绍当一个数组中大部分元素为０，或者为同一个值的数组时，可以使用稀疏数组来保存该数组。 稀疏数组的处理方法是: 记录数组一共有几行几列，有多少个不同的值 把具有不同值的元素的行列及值记录在一个小规模的数组中，从而缩小程序的规模 稀疏数组举例说明 应用实例 使用稀疏数组，来保留类似前面的二维数组(棋盘、地图等等) 把稀疏数组存盘，并且可以从新恢复原来的二维数组数 整体思路分析 二维数组 转 稀疏数组的思路 遍历 原始的二维数组，得到有效数据的个数 sum 根据sum 就可以创建 稀疏数组 sparseArr int[sum + 1] [3] 将二维数组的有效数据数据存入到 稀疏数组 稀疏数组转原始的二维数组的思路 先读取稀疏数组的第一行，根据第一行的数据，创建原始的二维数组，比如上面的 chessArr2 = int [11][11] 在读取稀疏数组后几行的数据，并赋给 原始的二维数组 即可. 代码实现import java.io.File; import java.io.FileWriter; import java.io.IOException; /** * @author xhc * @date 2021/5/15 11:37 */ public class SparseArray { public static void main(String[] args) { //创建一个原始的二维数组 11*11 // 0：表示没有棋子，1：表示黑子，2：表示蓝子 int[][] chessArr1 = new int[11][11]; chessArr1[1][2] = 1; chessArr1[2][3] = 2; //输出原始的二维数组 System.out.println(\"原始的二维数组\"); for (int[] row : chessArr1){ for (int data : row){ System.out.printf(\"%d\\t\",data); } System.out.println(); } //将二维数组 转 稀疏数组 // 1 先遍历二维数组 ，得到非零数据的个数 int sum = 0; for (int i = 0; i &lt; 11; i++) { for (int j = 0; j &lt; 11; j++) { if (chessArr1[i][j] != 0){ sum++; } } } System.out.println(\"sum=\"+sum); // 2 创建对应的稀疏数组 int[][] sparseArr = new int[sum + 1][3]; //给稀疏数组赋值 sparseArr[0][0] = 11; sparseArr[0][1] = 11; sparseArr[0][2] = sum; //存放稀疏数组的文件 File file = new File(\"d:\\\\array.txt\"); //文件写入流 try { FileWriter out = new FileWriter(file); out.write(11+\"\\t\"); out.write(11+\"\\t\"); out.write(sum+\"\\t\"); out.write(\"\\r\\n\"); //遍历二维数组，把非0的值放到 spareArr 中 int count = 0; //count 用于记录第几个非 0 数据 for (int i = 0; i &lt; 11; i++) { for (int j = 0; j &lt; 11; j++) { if (chessArr1[i][j] != 0){ count++; sparseArr[count][0] = i; out.write(i+\"\\t\"); sparseArr[count][1] = j; out.write(j+\"\\t\"); sparseArr[count][2] = chessArr1[i][j]; out.write(chessArr1[i][j]+\"\\t\"); out.write(\"\\r\\n\"); } } } out.close(); } catch (IOException e) { e.printStackTrace(); } // 输出稀疏数组的形式 System.out.println(); System.out.println(\"得到的稀疏数组为~~~~~\"); for (int i = 0;i &lt; sparseArr.length;i++){ System.out.printf(\"%d\\t%d\\t%d\\t\\n\",sparseArr[i][0],sparseArr[i][1],sparseArr[i][2]); } System.out.println(); //将稀疏数组 =》原始的二维数组 // 1 先读取稀疏数组的第一行，根据第一行的数据，创建原始的二维数组 int[][] chessArr2 = new int[sparseArr[0][0]][sparseArr[0][1]]; // 2 读取稀疏数组的几行数据，赋值给二维数组 for (int i =1;i &lt; sparseArr.length;i++){ chessArr2[sparseArr[i][0]][sparseArr[i][1]] = sparseArr[i][2]; } // 输出恢复后的二维数组 System.out.println(); System.out.println(\"恢复后的二维数组\"); for (int[] row : chessArr2){ for (int data : row){ System.out.printf(\"%d\\t\",data); } System.out.println(); } } } 队列队列介绍 队列是一个有序列表，可以用数组或是链表来实现。 遵循先入先出的原则。即：先存入队列的数据，要先取出。后存入的要后取出。 示意图：(使用数组模拟队列示意图) 数组模拟队列队列本身是有序列表，若使用数组的结构来存储队列的数据，则队列数组的声明如下图, 其中 maxSize 是该队列的最大容量。 因为队列的输出、输入是分别从前后端来处理，因此需要两个变量 front 及 rear 分别记录队列前后端的下标， front 会随着数据输出而改变，而 rear 则是随着数据输入而改变。 思路分析当我们将数据存入队列时称为”addQueue”，addQueue 的处理需要有两个步骤： 将尾指针往后移：rear+1 , 当 front == rear 【空】 若尾指针 rear 小于队列的最大下标 maxSize-1，则将数据存入 rear 所指的数组元素中，否则无法存入数据。 rear == maxSize - 1【满】 代码实现import java.util.Scanner; /** * @author xhc * @date 2021/5/19 10:22 */ public class ArrayQueueDemo { public static void main(String[] args) { //测试 //创建一个队列 ArrayQueue arrayQueue = new ArrayQueue(3); char key = ' ';//接收用户输入 Scanner scanner = new Scanner(System.in); boolean loop = true; //输出一个菜单 while (loop){ System.out.println(\"s(show): 显示队列\"); System.out.println(\"e(exit): 退出程序\"); System.out.println(\"a(add): 添加数据到队列\"); System.out.println(\"g(get): 从队列取出数据\"); System.out.println(\"h(head): 查看队列头的数据\"); key = scanner.next().charAt(0);//接收一个字符 switch (key){ case 's': arrayQueue.showQueue(); break; case 'a': System.out.println(\"输入一个数\"); int value = scanner.nextInt(); arrayQueue.addQueue(value); break; case 'g': try { int res = arrayQueue.getQueue(); System.out.printf(\"取出的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case 'h': try{ int res = arrayQueue.headQueue(); System.out.printf(\"队列头的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case 'e': scanner.close(); loop = false; break; default: break; } } System.out.println(\"程序退出~~\"); } } //使用数组模拟队列-编写一个ArrayQueue类 class ArrayQueue{ private int maxSize; //表示数组的最大容量 private int front; //队列头 private int rear; //队列尾 private int[] arr; //该数组用于存放数据，模拟队列 //创建队列的构造器 public ArrayQueue(int arrMaxSize){ maxSize = arrMaxSize; arr = new int[maxSize]; front = -1; //指向队列头部 rear = -1; //指向队列尾部 } //判断队列是否满 public boolean isFull(){ return rear == maxSize - 1; } //判断队列是否为空 public boolean isEmpty(){ return front == rear; } //添加数据到队列 public void addQueue(int n){ //判断队列是否满 if (isFull()){ System.out.println(\"队列满，不能加入数据~\"); return; } rear++; //让 rear 后移 arr[rear] = n; } //获取队列数据，出队列 public int getQueue(){ //判断队列是否空 if (isEmpty()){ //抛出异常 throw new RuntimeException(\"队列空，不能取数据\"); } front++;//让 front 后移 return arr[front]; } //显示队列的所有数据 public void showQueue(){ //遍历 if (isEmpty()){ System.out.println(\"队列为空，没有数据~~\"); return; } for (int i = 0; i &lt; arr.length; i++) { System.out.printf(\"arr[%d]=%d\\n\",i,arr[i]); } } //显示队列的头数据，注意不是取出数据 public int headQueue(){ //判断 if (isEmpty()){ throw new RuntimeException(\"队列空，不能取数据\"); } return arr[front + 1]; } } 问题分析并优化 问题：目前数组使用一次就不能用， 没有达到复用的效果 优化：将这个数组使用算法，改进成一个环形的队列。 取模：% 数组模拟环形队列对前面的数组模拟队列的优化，充分利用数组. 因此将数组看做是一个环形的。(取模的方式来实现) 思路分析 对front变量的含义做一个调整：front就指向队列的第一个元素，也就是说arr[front] 就是队列的第一个元素 front的初始值为0 对rear变量的含义做一个调整：rear指向队列的最后一个元素的后一个位置，因为希望空出一个空间（rear指向的空间）做约定（该约定用来判断队列是不是满了）rear 的初始值是0 当队列满时，条件是 (rear + 1) % maxSize == front 【满】 对队列为空的条件， rear == front 【空】 . 当我们这样分析， 队列中有效的数据的个数 (rear + maxSize - front) % maxSize 我们就可以在原来的队列上修改得到，一个环形队列 代码实现import java.util.Scanner; /** * @author xhc * @date 2021/5/19 11:38 */ public class CircleArrayQueueDemo { public static void main(String[] args) { System.out.println(\"测试数组模拟环形队列的案列~~~\"); CircleArrayQueue circleArrayQueue = new CircleArrayQueue(4); char key = ' ';//接收用户输入 Scanner scanner = new Scanner(System.in); boolean loop = true; //输出一个菜单 while (loop){ System.out.println(\"s(show): 显示队列\"); System.out.println(\"e(exit): 退出程序\"); System.out.println(\"a(add): 添加数据到队列\"); System.out.println(\"g(get): 从队列取出数据\"); System.out.println(\"h(head): 查看队列头的数据\"); key = scanner.next().charAt(0);//接收一个字符 switch (key){ case 's': circleArrayQueue.showQueue(); break; case 'a': System.out.println(\"输入一个数\"); int value = scanner.nextInt(); circleArrayQueue.addQueue(value); break; case 'g': try { int res = circleArrayQueue.getQueue(); System.out.printf(\"取出的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case 'h': try{ int res = circleArrayQueue.headQueue(); System.out.printf(\"队列头的数据是%d\\n\",res); }catch (Exception e){ System.out.println(e.getMessage()); } break; case 'e': scanner.close(); loop = false; break; default: break; } } System.out.println(\"程序退出~~\"); } } class CircleArrayQueue{ private int maxSize; //表示数组的最大容量 private int front; //队列头 private int rear; //队列尾的下一个位置 private int[] arr; //该数组用于存放数据，模拟队列 public CircleArrayQueue(int arrMaxSize){ maxSize = arrMaxSize; arr = new int[maxSize]; } //判断队列是否满 public boolean isFull(){ return (rear + 1) % maxSize == front; } //判断队列是否为空 public boolean isEmpty(){ return rear == front; } //添加数据到队列 public void addQueue(int n){ //判断队列是否满 if (isFull()){ System.out.println(\"队列满，不能加入数据~\"); return; } // 直接将数据加入 arr[rear] = n; //将 rear 后移，这里考虑到取模 rear = (rear + 1) % maxSize; } //获取队列数据，出队列 public int getQueue(){ //判断队列是否空 if (isEmpty()){ //抛出异常 throw new RuntimeException(\"队列空，不能取数据\"); } int value = arr[front]; front = (front + 1) % maxSize; return value; } //显示队列的所有数据 public void showQueue(){ //遍历 if (isEmpty()){ System.out.println(\"队列为空，没有数据~~\"); return; } // 从front开始遍历，遍历多少个元素 for (int i = front; i &lt; front + size(); i++) { System.out.printf(\"arr[%d]=%d\\n\",i % maxSize,arr[i % maxSize]); } } // 求出当前队列有效数据的个数 public int size(){ return (rear + maxSize - front) % maxSize; } //显示队列的头数据，注意不是取出数据 public int headQueue(){ //判断 if (isEmpty()){ throw new RuntimeException(\"队列空，不能取数据\"); } return arr[front]; } } 链表链表介绍链表是有序的列表，但是它在内存中是存储如下 (单链表) 链表是以节点的方式来存储,是链式存储 每个节点包含 data 域， next 域：指向下一个节点. 如图：发现链表的各个节点不一定是连续存储. 链表分带头节点的链表和没有头节点的链表，根据实际的需求来确定  单链表(带头结点) 逻辑结构示意图如下 单链表实例引入使用带 head 头节点的单向链表实现 ——水浒英雄排行榜管理完成对英雄人物的增删改查操作。 链表的创建 首先要先创建链表的节点 第一种方法，在添加英雄时，直接添加到链表的尾部 思路分析示意图： 思路： 先创建一个head 头节点， 作用就是表示单链表的头 后面我们每添加一个节点，就直接加入到 链表的最后 遍历：通过一个辅助变量遍历，帮助遍历整个链表 第二种方式在添加英雄时，根据排名将英雄插入到指定位置(如果有这个排名，则添加失败，并给出提示) 思路分析示意图 思路： 首先找到新添加的节点的位置, 是通过辅助变量(指针), 通过遍历来搞定 新的节点.next = temp.next 将temp.next = 新的节点 修改节点思路：先通过遍历根据编号找到该节点，后更新节点内容 删除节点 思路： 我们先找到 需要删除的这个节点的前一个节点 temp temp.next = temp.next.next 被删除的节点，将不会有其它引用指向，会被垃圾回收机制回收 代码实现import java.util.Stack; /** * @author xhc * @date 2021/5/20 10:33 */ public class SingleLinkedListDemo { public static void main(String[] args) { //进行测试 //先创建节点 HeroNode hero1 = new HeroNode(1, \"宋江\", \"及时雨\"); HeroNode hero2 = new HeroNode(2, \"卢俊义\", \"玉麒麟\"); HeroNode hero3 = new HeroNode(3, \"吴用\", \"智多星\"); HeroNode hero4 = new HeroNode(4, \"林冲\", \"豹子头\"); HeroNode hero5 = new HeroNode(5, \"关胜\", \"大刀\"); HeroNode hero6 = new HeroNode(6, \"秦明\", \"霹雳火\"); HeroNode hero7 = new HeroNode(7, \"呼延灼\", \"双鞭\"); HeroNode hero8 = new HeroNode(8, \"华荣\", \"小李广\"); //创建要给的链表 SingleLinkedList singleLinkedList1 = new SingleLinkedList(); SingleLinkedList singleLinkedList2 = new SingleLinkedList(); SingleLinkedList combineList = new SingleLinkedList(); //加入 singleLinkedList1.add(hero1); singleLinkedList1.add(hero3); singleLinkedList1.add(hero6); singleLinkedList1.add(hero7); singleLinkedList2.add(hero2); singleLinkedList2.add(hero4); singleLinkedList2.add(hero5); singleLinkedList2.add(hero8); //显示两个有序的链表 System.out.println(\"链表1~~\"); singleLinkedList1.list(); System.out.println(\"链表2~~\"); singleLinkedList2.list(); //测试合并链表功能 System.out.println(\"合并后的链表~~\"); combineList.setHead(combine(singleLinkedList1.getHead(),singleLinkedList2.getHead())); combineList.list(); System.out.println(); /** //测试一下反转功能 System.out.println(\"原来链表的情况~~\"); singleLinkedList.list(); //逆序打印单链表 System.out.println(\"逆序打印~~\"); reversePrint(singleLinkedList.getHead()); System.out.println(\"反转后~~\"); reverseList(singleLinkedList.getHead()); singleLinkedList.list(); */ /** //加入 按照编号的顺序 singleLinkedList.addByOrder(hero1); singleLinkedList.addByOrder(hero3); singleLinkedList.addByOrder(hero4); singleLinkedList.addByOrder(hero2); //显示 singleLinkedList.list(); //测试修改节点的代码 HeroNode newHeroNode = new HeroNode(2, \"小卢\", \"玉麒麟~~\"); singleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况~~\"); singleLinkedList.list(); //删除一个节点 singleLinkedList.del(1); singleLinkedList.del(4); System.out.println(\"删除后的链表情况~~\"); singleLinkedList.list(); //测试求单链表有效个数的方法 System.out.println(\"有效节点的个数=\"+getLength(singleLinkedList.getHead())); //测试是都得到了倒数第k个节点 HeroNode res = findLastIndexNode(singleLinkedList.getHead(), 2); System.out.println(\"res=\"+res); */ } //合并两个有序的链表，合并后链表依然有序 public static HeroNode combine(HeroNode head1,HeroNode head2){ //如果两个链表均为空，则无需合并，直接返回 if (head1.next == null &amp;&amp; head2.next == null){ return null; } HeroNode combineHead = new HeroNode(0,\"\",\"\"); //如果链表1为空，则合并后的链表指向链表2 if (head1.next == null){ combineHead.next = head2.next; return combineHead; }else{ // 将合并后的链表指向head1 combineHead.next = head1.next; //temp辅助变量 HeroNode temp = combineHead; HeroNode cur2 = head2.next; //next用来存放当前节点的下一个节点 HeroNode next = null; while (cur2 != null){ //合并后的链表遍历完后，可以直接将链表2剩下的节点连接至合并后的链表的末尾 if (temp.next == null){ temp.next = cur2; break; } //在合并链表中，找到第一个大于链表2的节点编号的节点 //因为是单链表，找到的节点是位于添加位置的前一个节点，否则无法加入 if (cur2.no &lt;= temp.next.no){ next = cur2.next; cur2.next = temp.next; temp.next = cur2; cur2 = next; } temp = temp.next; } return combineHead; } } //从尾到头遍历链表 //可以利用栈，将各个节点压入到栈中，然后利用栈的先进后出的特点，实现逆序打印的效果 public static void reversePrint(HeroNode head){ if (head.next == null){ return; //空链表，不能打印 } //创建一个栈，将各个节点压入栈 Stack&lt;HeroNode&gt; stack = new Stack&lt;&gt;(); HeroNode cur = head.next; //将链表的所有节点压入栈 while (cur != null){ stack.push(cur); cur = cur.next; // cur后移，这样就可以压入下一个结点 } //将栈中的节点进行打印，pop出栈 while (stack.size() &gt; 0){ System.out.println(stack.pop());//stack的特点是先进后出 } } //将单链表反转 public static void reverseList(HeroNode head){ //如果当前链表为空，或者只有一个节点，无需反转，直接返回 if (head.next == null || head.next.next == null){ return; } //定义一个辅助的指针，帮助我们遍历原来的链表 HeroNode cur = head.next; HeroNode next = null; //指向当前节点【cur】的下一个结点 HeroNode reverseHead = new HeroNode(0,\"\",\"\"); //遍历原来的链表，没遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端 while (cur != null){ next = cur.next; //先暂时保存当前节点的下一个结点，因为后面需要使用 cur.next = reverseHead.next; //将cur的下一个结点指向链表的最前端 reverseHead.next = cur; //将cur 连接到新的链表上 cur = next; //让cur后移 } //将 head.next 指向 reverseHead.next 实现单链表的反转 head.next = reverseHead.next; } //查找单链表中的倒数第k个节点 //思路 //1.编写一个方法，接收head节点，同时接收一个index //2.index 表示是倒数第index节点 //3.先把链表从头到尾遍历，得到链表的总的长度getLength //4.得到 size 后，我们从链表的第一个开始遍历（size - index）个，就可以得到 public static HeroNode findLastIndexNode(HeroNode head,int index){ //判断链表是否为空 if (head.next == null){ return null; //没有找到 } //第一个遍历得到链表的长度(节点个数) int size = getLength(head); //第二次遍历 size-index 位置，就是我们倒数的第k个节点 //先做一个 index 的校验 if (index &lt;=0 || index &gt; size){ return null; } //定义辅助变量，for 循环定位到倒数的index HeroNode cur = head.next; for (int i = 0; i &lt; size - index; i++) { cur = cur.next; } return cur; } //方法：获取到单链表的节点的个数（如果是带头结点的链表，需求不统计头结点） /** * * @param head 链表的头结点 * @return 返回的就是有效节点的个数 */ public static int getLength(HeroNode head){ if (head.next == null){ //空链表 return 0; } int length = 0; //定义一个辅助变量 HeroNode cur = head.next; while (cur != null){ length++; cur = cur.next; //遍历 } return length; } } //定义 SingleLinkedList 管理我们的英雄 class SingleLinkedList{ //先初始化一个头结点，头结点不要动，不存房具体的数据 private HeroNode head = new HeroNode(0,\"\",\"\"); //返回头结点 public HeroNode getHead() { return head; } public void setHead(HeroNode head) { this.head = head; } //添加节点到单向链表 //思路，当不考虑编号顺序时 //1.找到当前链表的最后节点 //2.将最后一个节点的next指向新的节点 public void add(HeroNode heroNode){ //因为head节点不能动，因此我们需要一个辅助遍历temp HeroNode temp = head; //遍历链表，找到最后 while (true){ //找到链表的最后 if (temp.next == null){ break; } //如果没有找到最后，就将temp后移 temp = temp.next; } //当退出 while 循环时，temp 就指向了链表的最后 //将最后一个节点的 next 指向新的节点 temp.next = heroNode; } //第二种方式在添加英雄时，根据排名将英雄插入到指定位置 //（如果有这个排名，则添加失败，并给出提示） public void addByOrder(HeroNode heroNode){ //因为头结点不能动，因此我们仍然通过一个辅助指针（变量）来帮助找到添加的位置 //因为单链表，因为我们找的 temp 是位于 添加位置的前一个节点，否则插入不了 HeroNode temp = head; boolean flag = false; // flag 标志添加的编号是否存在，默认为false while (true){ if (temp.next ==null){ break; } if (temp.next.no &gt; heroNode.no) {//位置找到，就在temp的后面插入 break; }else if (temp.next.no == heroNode.no){//说明希望房添加的 HeroNode 的编号已然存在 flag = true; //说明编号存在 break; } temp = temp.next; //后移，遍历当前链表 } //判断flag的值 if (flag){ //不能添加，说明编号存在 System.out.println(\"准备插入的英雄的编号\"+heroNode.no+\"已经存在，不能加入\"); }else { //插入到链表中，temp的后面 heroNode.next = temp.next; temp.next = heroNode; } } //修改节点的信息，根据no编号来修改，即 no 编号不能改 //说明 //1.根据newHeroNode 的 no 来修改即可 public void update(HeroNode newHeroNode){ //判断是否为空 if (head.next == null){ System.out.println(\"链表为空\"); return; } //找到需要修改的节点，根据no编号 //定义一个辅助变量 HeroNode temp =head.next; boolean flag = false; //表示是否找到该节点 while (true){ if (temp == null){ break;//已经遍历完链表 } if (temp.no == newHeroNode.no){ //找到 flag = true; break; } temp = temp.next; } //根据flag 判断是否找到要修改的节点 if (flag){ temp.name = newHeroNode.name; temp.nickName = newHeroNode.nickName; }else {//没有找到 System.out.printf(\"没有找到编号%d的节点，不能修改\\n\", newHeroNode.no); } } //删除节点 //思路 //1.head 不能动，因此我们需要一个辅助节点，找到待删除节点的前一个节点 //2.说明我们在比较时，是temp.next.no 和 删除的节点的no比较 public void del(int no){ HeroNode temp = head; boolean flag = false; //标志是否找到待删除的节点 while (true){ if (temp.next == null){//已经到链表的最后 break; } if (temp.next.no == no){ //找到的待删除节点的前一个节点temp flag = true; break; } temp = temp.next; //temp后移，遍历 } //判断flag if (flag){ //可以删除 temp.next = temp.next.next; }else { System.out.printf(\"要删除的节点不存在%d\\n\",no); } } //显示链表（遍历） public void list(){ //判断链表是否为空 if (head.next == null){ System.out.println(\"链表为空\"); return; } //因为头结点，不能动，因此我们需要一个辅助变量来遍历 HeroNode temp = head.next; while (true){ //判断是否到链表最后 if (temp == null){ break; } //输出节点的信息 System.out.println(temp); //将temp后移 temp = temp.next; } } } //定义 HeroNode ，每个 HeroNode 对象就是一个节点 class HeroNode{ public int no; public String name; public String nickName; public HeroNode next; // 指向下一个结点 //构造器 public HeroNode(int no,String name,String nickName){ this.no = no; this.name = name; this.nickName = nickName; } //为了显示方法，我们重写 toString @Override public String toString() { return \"HeroNode{\" + \"no=\" + no + \", name='\" + name + '\\'' + \", nickName='\" + nickName + '\\'' + '}'; } } 单链表相关问题求单链表中有效节点的个数 思路：定义一个辅助指针遍历链表，定义一个变量result，每遍历一个节点就result++ //方法：获取到单链表的节点的个数（如果是带头结点的链表，需求不统计头结点） /** * * @param head 链表的头结点 * @return 返回的就是有效节点的个数 */ public static int getLength(HeroNode head){ if (head.next == null){ //空链表 return 0; } int length = 0; //定义一个辅助变量 HeroNode cur = head.next; while (cur != null){ length++; cur = cur.next; //遍历 } return length; } 查找单链表中的倒数第k个节点 思路： 编写一个方法，接收head节点，同时接受一个index index表示是倒数第index个节点 先把链表从头到尾遍历，得到链表的总长度getLength（这一步可以另写一个求链表总长度的方法，方便使用） 得到size之后，我们从链表的第一个节点（非head）开始遍历（size-index）个，就可以得到 如果找到了，则返回该节点，否则返回null //查找单链表中的倒数第k个节点 //思路 //1.编写一个方法，接收head节点，同时接收一个index //2.index 表示是倒数第index节点 //3.先把链表从头到尾遍历，得到链表的总的长度getLength //4.得到 size 后，我们从链表的第一个开始遍历（size - index）个，就可以得到 public static HeroNode findLastIndexNode(HeroNode head,int index){ //判断链表是否为空 if (head.next == null){ return null; //没有找到 } //第一个遍历得到链表的长度(节点个数) int size = getLength(head); //第二次遍历 size-index 位置，就是我们倒数的第k个节点 //先做一个 index 的校验 if (index &lt;=0 || index &gt; size){ return null; } //定义辅助变量，for 循环定位到倒数的index HeroNode cur = head.next; for (int i = 0; i &lt; size - index; i++) { cur = cur.next; } return cur; } 从尾到头打印单链表（反向遍历） 思路： 方式1：先将单链表进行反转操作，然后再遍历即可，但是这样做的问题会破坏原来的单链表的结构，不建议 方式2：利用栈数据结构，将各个节点压入到栈中，利用栈的先进后出的特点实现了逆序打印的效果 //从尾到头遍历链表 //可以利用栈，将各个节点压入到栈中，然后利用栈的先进后出的特点，实现逆序打印的效果 public static void reversePrint(HeroNode head){ if (head.next == null){ return; //空链表，不能打印 } //创建一个栈，将各个节点压入栈 Stack&lt;HeroNode&gt; stack = new Stack&lt;&gt;(); HeroNode cur = head.next; //将链表的所有节点压入栈 while (cur != null){ stack.push(cur); cur = cur.next; // cur后移，这样就可以压入下一个结点 } //将栈中的节点进行打印，pop出栈 while (stack.size() &gt; 0){ System.out.println(stack.pop());//stack的特点是先进后出 } } 合并两个有序的单链表，合并之后的链表依然有序 可以将一条单链表作为主链，通过遍历另外一条链表，每遍历一个节点就将该节点插入到主链中 //合并两个有序的链表，合并后链表依然有序 public static HeroNode combine(HeroNode head1,HeroNode head2){ //如果两个链表均为空，则无需合并，直接返回 if (head1.next == null &amp;&amp; head2.next == null){ return null; } HeroNode combineHead = new HeroNode(0,\"\",\"\"); //如果链表1为空，则合并后的链表指向链表2 if (head1.next == null){ combineHead.next = head2.next; return combineHead; }else{ // 将合并后的链表指向head1 combineHead.next = head1.next; //temp辅助变量 HeroNode temp = combineHead; HeroNode cur2 = head2.next; //next用来存放当前节点的下一个节点 HeroNode next = null; while (cur2 != null){ //合并后的链表遍历完后，可以直接将链表2剩下的节点连接至合并后的链表的末尾 if (temp.next == null){ temp.next = cur2; break; } //在合并链表中，找到第一个大于链表2的节点编号的节点 //因为是单链表，找到的节点是位于添加位置的前一个节点，否则无法加入 if (cur2.no &lt;= temp.next.no){ next = cur2.next; cur2.next = temp.next; temp.next = cur2; cur2 = next; } temp = temp.next; } return combineHead; } } 单链表的反转 思路： 定义一个节点，用于做反转后的链表的头节点； 定义一个辅助节点，用于遍历； 定义一个节点，用来保存当前节点的下一个节点； 每遍历到一个节点，就将该节点放到新的链表的最前面； 遍历完后，将原来链表的头节点的next指向新链表的next即可 //将单链表反转 public static void reverseList(HeroNode head){ //如果当前链表为空，或者只有一个节点，无需反转，直接返回 if (head.next == null || head.next.next == null){ return; } //定义一个辅助的指针，帮助我们遍历原来的链表 HeroNode cur = head.next; HeroNode next = null; //指向当前节点【cur】的下一个结点 HeroNode reverseHead = new HeroNode(0,\"\",\"\"); //遍历原来的链表，没遍历一个节点，就将其取出，并放在新的链表reverseHead 的最前端 while (cur != null){ next = cur.next; //先暂时保存当前节点的下一个结点，因为后面需要使用 cur.next = reverseHead.next; //将cur的下一个结点指向链表的最前端 reverseHead.next = cur; //将cur 连接到新的链表上 cur = next; //让cur后移 } //将 head.next 指向 reverseHead.next 实现单链表的反转 head.next = reverseHead.next; } 双向链表实例引入管理单向链表的缺点分析: 单向链表，查找的方向只能是一个方向，而双向链表可以向前或者向后查找。 单向链表不能自我删除，需要靠辅助节点，而双向链表，则可以自我删除，所以前面我们单链表删除节点时，总是找到 temp,temp 是待删除节点的前一个节点。 双向链表的增删改查思路分析： 遍历和单链表一样，只是可以向前，也可以向后查找 添加 (默认添加到双向链表的最后 1）先找到双向链表的最后这个节点 2）temp.next = newHeroNode 3）newHeroNode.pre = temp; 修改思路和原来的单向链表一样. 删除 1）因为是双向链表，因此，我们可以实现自我删除某个节点 2）直接找到要删除的这个节点，比如 temp 3）temp.pre.next = temp.next 4）temp.next.pre = temp.pre; 代码实现/** * @author xhc * @date 2021/5/22 10:03 */ public class DoubleLinkedListDemo { public static void main(String[] args) { //测试 System.out.println(\"双向链表的测试\"); //先创建节点 HeroNode2 hero1 = new HeroNode2(1, \"宋江\", \"及时雨\"); HeroNode2 hero2 = new HeroNode2(2, \"卢俊义\", \"玉麒麟\"); HeroNode2 hero3 = new HeroNode2(3, \"吴用\", \"智多星\"); HeroNode2 hero4 = new HeroNode2(4, \"林冲\", \"豹子头\"); //创建一个双向链表 DoubleLinkedList doubleLinkedList = new DoubleLinkedList(); /** doubleLinkedList.add(hero1); doubleLinkedList.add(hero2); doubleLinkedList.add(hero3); doubleLinkedList.add(hero4); doubleLinkedList.list(); //修改 HeroNode2 newHeroNode = new HeroNode2(4, \"公孙胜\", \"入云龙\"); doubleLinkedList.update(newHeroNode); System.out.println(\"修改后的链表情况\"); doubleLinkedList.list(); //删除 doubleLinkedList.del(3); System.out.println(\"删除后的链表情况\"); doubleLinkedList.list(); */ //测试根据排名添加 HeroNode2 hero5 = new HeroNode2(5, \"关胜\", \"大刀\"); HeroNode2 hero8 = new HeroNode2(8, \"华荣\", \"小李广\"); HeroNode2 hero6 = new HeroNode2(6, \"秦明\", \"霹雳火\"); HeroNode2 hero7 = new HeroNode2(7, \"呼延灼\", \"双鞭\"); System.out.println(\"测试根据排名添加\"); doubleLinkedList.addByOrder(hero5); doubleLinkedList.addByOrder(hero8); doubleLinkedList.addByOrder(hero6); doubleLinkedList.addByOrder(hero7); doubleLinkedList.list(); } } class DoubleLinkedList{ //先初始化一个头结点，头结点不要动，不存房具体的数据 private HeroNode2 head = new HeroNode2(0,\"\",\"\"); //返回头结点 public HeroNode2 getHead() { return head; } public void setHead(HeroNode2 head) { this.head = head; } //修改一个节点的内容，可以看到双向链表的节点内容修改和单向链表的一样 public void update(HeroNode2 newHeroNode){ //判断是否为空 if (head.next == null){ System.out.println(\"链表为空\"); return; } //找到需要修改的节点，根据no编号 //定义一个辅助变量 HeroNode2 temp =head.next; boolean flag = false; //表示是否找到该节点 while (true){ if (temp == null){ break;//已经遍历完链表 } if (temp.no == newHeroNode.no){ //找到 flag = true; break; } temp = temp.next; } //根据flag 判断是否找到要修改的节点 if (flag){ temp.name = newHeroNode.name; temp.nickName = newHeroNode.nickName; }else {//没有找到 System.out.printf(\"没有找到编号%d的节点，不能修改\\n\", newHeroNode.no); } } //添加一个节点到双向链表的最后 public void add(HeroNode2 heroNode){ //因为head节点不能动，因此我们需要一个辅助遍历temp HeroNode2 temp = head; //遍历链表，找到最后 while (true){ //找到链表的最后 if (temp.next == null){ break; } //如果没有找到最后，就将temp后移 temp = temp.next; } //当退出 while 循环时，temp 就指向了链表的最后 //形成一个双向链表 temp.next = heroNode; heroNode.pre = temp; } //根据排名添加 public void addByOrder(HeroNode2 heroNode){ //因为头结点不能动，因此我们仍然通过一个辅助指针（变量）来帮助找到添加的位置 HeroNode2 temp = head; boolean flag = false; // flag 标志添加的编号是否存在，默认为false while (true){ if (temp.next ==null){ break; } if (temp.next.no &gt; heroNode.no) {//位置找到，就在temp的后面插入 break; }else if (temp.next.no == heroNode.no){//说明希望房添加的 HeroNode 的编号已然存在 flag = true; //说明编号存在 break; } temp = temp.next; //后移，遍历当前链表 } //判断flag的值 if (flag){ //不能添加，说明编号存在 System.out.println(\"准备插入的英雄的编号\"+heroNode.no+\"已经存在，不能加入\"); }else { //插入到链表中，temp的后面 heroNode.next = temp.next; temp.next = heroNode; if (heroNode.next != null) { heroNode.next.pre = heroNode; heroNode.pre = temp; }else { heroNode.pre = temp; } } } //从双向链表中删除一个节点 //说明 //1.对于双向链表，我们可以直接找到要删除的这个节点 //2.找到后，自我删除即可 public void del(int no){ //判断当前链表是否为空 if (head.next == null){ System.out.println(\"链表为空，无法删除\"); return; } HeroNode2 temp = head.next; //辅助变量 boolean flag = false; //标志是否找到待删除的节点 while (true){ if (temp == null){//已经到链表的最后 break; } if (temp.no == no){ //找到的待删除节点的前一个节点temp flag = true; break; } temp = temp.next; //temp后移，遍历 } //判断flag if (flag){ //可以删除 temp.pre.next = temp.next; //这里代码有问题 //如果是最后一个节点，就不需要执行下面这句话，否则会出现空指针异常 if (temp.next != null){ temp.next.pre = temp.pre; } }else { System.out.printf(\"要删除的节点不存在%d\\n\",no); } } //遍历双向链表的方法 //显示链表（遍历） public void list(){ //判断链表是否为空 if (head.next == null){ System.out.println(\"链表为空\"); return; } //因为头结点，不能动，因此我们需要一个辅助变量来遍历 HeroNode2 temp = head.next; while (true){ //判断是否到链表最后 if (temp == null){ break; } //输出节点的信息 System.out.println(temp); //将temp后移 temp = temp.next; } } } //定义 HeroNode ，每个 HeroNode 对象就是一个节点 class HeroNode2{ public int no; public String name; public String nickName; public HeroNode2 next; // 指向下一个结点 public HeroNode2 pre; //指向前一个节点 //构造器 public HeroNode2(int no,String name,String nickName){ this.no = no; this.name = name; this.nickName = nickName; } //为了显示方法，我们重写 toString @Override public String toString() { return \"HeroNode{\" + \"no=\" + no + \", name='\" + name + '\\'' + \", nickName='\" + nickName + '\\'' + '}'; } } 单向环形链表Josephu（约瑟夫/约瑟夫环）问题介绍 Josephu 问题为：设编号为 1，2，… n 的 n 个人围坐一圈，约定编号为 k（1&lt;=k&lt;=n）的人从 1 开始报数，数到 m 的那个人出列，它的下一位又从 1 开始报数，数到 m 的那个人又出列，依次类推，直到所有人出列为止，由此产生一个出队编号的序列。 构建单向环形链表示意图如下： 构建单向环形链表思路： 先创建第一个节点, 让 first 指向该节点，并形成环形 后面当我们每创建一个新的节点，就把该节点，加入到已有的环形链表中即可. 遍历环形链表 先让一个辅助指针(变量) curBoy，指向first节点 然后通过一个while循环遍历该环形链表即可。当 curBoy.next == first 结束。 Josephu问题 根据用户的输入，生成一个小孩出圈的顺序 示意图如下： 思路： 需求创建一个辅助指针(变量) helper , 事先应该指向环形链表的最后一个节点. 报数前，先让 first 和 helper 移动 k - 1次 当小孩报数时，让first 和 helper 指针同时的移动 m - 1 次 这时就可以将first 指向的小孩节点 出圈 first = first .next helper.next = first 原来first 指向的节点就没有任何引用，就会被回收 代码实现/** * @author xhc * @date 2021/5/25 9:46 */ public class Josephu { public static void main(String[] args) { //测试 看看构建环形链表，和遍历是否ok CircleSingleLinkedList circleSingleLinkedList = new CircleSingleLinkedList(); circleSingleLinkedList.addBoy(5); circleSingleLinkedList.showBoy(); //测试 小孩出圈是否正确 circleSingleLinkedList.countBoy(1,2,5); } } //创建一个环形的单向链表 class CircleSingleLinkedList{ //创建一个first节点，当前没有编号 private Boy first = null; //添加小孩节点，构建成一个环形的链表 public void addBoy(int nums){ //nums做一个数据校验 if (nums &lt; 1){ System.out.println(\"nums的值不正确\"); return; } Boy curBoy = null; //辅助指针，帮助构建环形链表 //使用for循环来创建环形链表 for (int i = 1; i &lt;= nums; i++) { //根据编号，创建小孩节点 Boy boy = new Boy(i); //如果是第一个小孩 if (i == 1){ first = boy; first.setNext(first);//构成环 curBoy = first; //让curBoy指向第一个小孩 }else { curBoy.setNext(boy); boy.setNext(first); curBoy = boy; } } } //遍历当前的环形链表 public void showBoy(){ //判断链表是否为空 if (first == null){ System.out.println(\"没有任何小孩~~\"); return; } //因为fiest不能动，因此我们仍然使用一个辅助指针完成遍历 Boy curBoy = first; while (true){ System.out.printf(\"小孩的编号 %d \\n\",curBoy.getNo()); if (curBoy.getNext() == first) {//说明已经遍历完毕 break; } curBoy = curBoy.getNext();//后移 } } //根据用户的输入，计算出小孩出圈的顺序 /** * * @param startNo 表示从第几个小孩开始数数 * @param countNum 表示数几下 * @param nums 表示最初有多少个小孩在圈中 */ public void countBoy(int startNo,int countNum,int nums){ //先对数据进行检验 if (first == null || startNo &lt; 1 || startNo &gt; nums){ System.out.println(\"参数输入有误，请重新输入\"); return; } //创建一个辅助指针，帮助完成小孩出圈 Boy helper = first; //需求创建一个辅助指针（变量）helper,事先应该指向环形链表的最后这个节点 while (true){ if (helper.getNext() == first){ //说明helper指向最后一个小孩节点 break; } helper = helper.getNext(); } //小孩报数前，先让first 和 helper 移动 k-1次 for (int j = 0; j &lt; startNo - 1; j++) { first = first.getNext(); helper = helper.getNext(); } //当小孩报数时，让first 和 helper 指针同时 移动 m-1 次，然后出圈 //这里是一个循环操作，直到圈中只有一个节点 while (true){ if (helper == first){//说明圈中只有一个节点 break; } //让 first 和 helper 指针同时移动 countNum - 1 for (int j = 0; j &lt; countNum - 1; j++) { first = first.getNext(); helper = helper.getNext(); } //这时first指向的节点，就是要出圈的小孩节点 System.out.printf(\"小孩%d出圈\\n\",first.getNo()); //这时将first指向的小孩节点出圈 first = first.getNext(); helper.setNext(first); } System.out.printf(\"最后留在圈中的小孩编号%d\\n\",first.getNo()); } } //创建一个Boy类，表示一个节点 class Boy{ private int no; //编号 private Boy next; //指向下一个节点，默认null public Boy(int no){ this.no = no; } public int getNo() { return no; } public void setNo(int no) { this.no = no; } public Boy getNext() { return next; } public void setNext(Boy next) { this.next = next; } }","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"数据结构和算法","slug":"笔记/数据结构和算法","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://mjean.life/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"http://mjean.life/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"项目总结：guli-college","slug":"guli-summary","date":"2021-06-02T08:33:34.000Z","updated":"2022-04-18T12:48:45.796Z","comments":true,"path":"posts/196bb79f.html","link":"","permalink":"http://mjean.life/posts/196bb79f.html","excerpt":"","text":"项目介绍在线教育项目采用B2C商业模式，使用微服务架构，项目采用前后端分离开发 项目的功能点后台管理系统功能登录功能（SpringSecurity框架）权限管理模块 菜单管理：列表、添加、修改、删除 角色管理 列表、添加、修改、删除、批量删除 为角色分配菜单 用户管理 列表、添加、修改、删除、批量删除 为用户分配角色 权限管理表和关系* 使用五张表：用户表、角色表、菜单表、用户角色中间表、角色菜单中间表 讲师管理模块​ 多条件查询分页列表、添加、修改、删除 课程分类模块 添加课程分类 读取Excel里面课程分类数据，添加到数据库中 课程分类列表 使用树形结构显示课程分类列表 课程管理模块 课程列表功能 添加课程 添加小节上传课程视频 课程发布流程：第一步填写课程基本信息，第二步添加课程大纲（章节和小节），第三步课程信息确认，最终课程发布 课程如何判断是否已经被发布了？使用status字段 课程添加过程中，中途把课程停止添加，重新去添加新的课程，如何找到之前没有发布完成课程，继续进行发布？ 到课程列表中根据课程状态查询未发布的课程，点击课程右边超链接把课程继续发布完成 统计分析模块 生成统计数据 统计数据图表显示 幻灯片管理模块​ 添加和删除 前台系统功能首页数据显示 显示幻灯片功能 显示热门课程 显示名师 注册功能​ 获取手机验证码 登录功能 普通登录和退出 SSO（单点登录） SSO（单点登录）是怎么实现的？ 使用的是token的方式，用户登录成功后，根据相关的信息生成token，然后返回给cookie，他每次访问的时候都会从请求头中获取token的值，并解析获取用户信息，判断是否已经登录。 使用什么方式生成Token的？ 使用Jwt生成token字符串 补充：1、token是按照一定规则生成的字符串，包含用户信息；2、Jwt是一种通用的规则 Jwt有几部分组成，分别为什么？ 三部分组成，分别为：jwt头信息、有效载荷，包含主体信息（用户信息）、签名哈希（防伪标志） 登录实现流程 登录调用登录接口返回token字符串，把返回token字符串放到cookie里面，创建前端拦截器进行判断，如果cookie里面包含token字符串，把token字符串放到header里面。调用接口根据token获取用户信息，把用户信息放到cookie里面，进行显示 微信扫描登录 OAuth2 是针对特定问题的一种解决方案 主要解决两个问题：开放系统间授权，分布式访问问题 如何获取扫描人信息过程？ 扫描二维码之后，微信接口返回code值（临时票据），拿着code值请求微信固定地址，得到两个值：access_token（访问凭证）和openid（微信唯一标识）,然后拿着这两个值再去请求微信固定的地址，得到微信扫码人的信息（比如昵称，头像等等） 名师列表功能 分页显示名师信息 名师详情功能 点击名师跳转到名师详情及其所教的课程 课程列表功能 根据课程分类分页查询课程 根据销量，价格等排序课程 课程列表分页显示 课程详情页 课程信息显示（包含课程基本信息，分类，讲师，课程大纲） 判断课程是否需要购买 课程评论 课程视频在线播放 阿里云视频点播、阿里云播放器 课程支付功能（微信支付） 生成课程订单 生成微信支付二维码 微信最终支付 微信支付实现流程 如果课程是收费课程，点击立即购买，生成课程订单 点击订单页面去支付，生成微信支付二维码 使用微信扫描支付二维码实现支付 支付之后，每隔3秒查询支付状态（是否支付成功），如果没有支付成功则等待，如果支付成功之后，更新订单状态（已经支付状态），向支付记录表添加支付成功记录 项目的技术点前后端分离开发后端写接口，前端调后端接口得到数据并显示 项目使用的前端技术vue 基本语法 常见指令 ： v-bind（单向绑定） 、v-model （双向绑定）、v-if 、v-for 、v-html 绑定事件： v-on-click 、 @click 生命周期：created()：页面渲染之前 、mounted()：页面渲染之后 ES6规范 Element-uiNodejs是JavaScript运行环境，不需要浏览器就能直接运行js代码，模拟服务器效果 NPM 包管理工具，类似于Maven npm命令： npm init 初始化、 npm install 依赖名称 Babel转码器，可以把ES6代码转换成ES5代码 前端模块化通过一个页面或者一个js文件，调用另外一个js文件里面的方法 问题：ES6的模块化无法在Node.js中执行，需要用Babel编辑成ES5后再执行 后台系统使用 vue-admin-template基于vue+Element-ui,默认端口 9528 前台系统使用 Nuxt基于vue，默认端口 3000；服务器渲染技术 Echarts图表工具 你能做全栈吗？（不要直接回答能或不能） 说：项目中有80%的后端都是我写的，前端都是cv的，对于前端技术有所了解 项目使用的后端技术【1】项目采用微服务架构将项目拆分为独立的模块，每个模块都有其端口号，模块与模块之间没有关系，是通过远程调用实现 SpringBoot SpringBoot本质是就是Spring，是快速构建Spring工程的脚手架 细节： # 启动类包扫描机制：从外往里扫，也可以设置扫描规则 @ComponentScan(\"包路径\") # 配置类 # SpringBoot配置文件类型：properties、yaml # 配置文件加载顺序： # 1.先bootstrap # 2.再properties或yaml # 3.再对应的环境如：dev、test、prod SpringCloud 是很多框架总称，使用这些框架来实现微服务架构，是基于SpringBoot实现的 组成的框架有： 服务注册——Netflix Eureka（nacos） 服务调用——Netflix Feign（nacos） 熔断器——Netflix Hystrix 服务网关——Spring Cloud GateWay 配置中心——Spring Cloud Config（nacos） 消息总线——Spring Cloud Bus（nacos） 项目中，使用阿里巴巴Nacos，替代SpringCloud一些组件 Nacos 使用Nacos作为注册中心 使用Nacos作为配置中心 Feign 服务调用，一个微服务调用另外一个微服务，实现远程调用 熔断器 Gateway网关（SpringCloud之前zuul网关，目前Gateway网关） 版本:H版 MyBatisPlus MyBatisPlus就是对MyBatis做增强 自动填充(@TableField) 乐观锁 逻辑删除(@TableLogic) 代码生成器 EasyExcel 阿里巴巴提供操作excel工具，代码简洁，效率很高 为什么效率高？ EasyExcel对poi进行封装，采用SAX方式解析 Dom：一次将所有数据放进内存中来 项目应用在添加课程分类，读取excel数据 项目使用的后端技术【2】Spring Security 在项目整合框架实现权限管理功能 SpringSecurity框架组成：认证和授权 SpringSecurity登录认证过程 SpringSecurity代码执行过程 Redis 首页数据通过Redis进行缓存 Redis数据类型:Set、List、Hash、String、Zset 使用Redis作为缓存，不太重要或者不经常改变数据适合放到Redis作为缓存 （如首页） Nginx 反向代理服务器 请求转发，负载均衡，动静分离 OAuth2+JWT OAuth2是针对特定问题的一种解决方案 JWT是一种通用的规则，包含三部分：jwt头信息、有效载荷，包含主体信息（用户信息）、签名哈希（防伪标志） HttpClient 发送请求和返回响应的工具，不需要浏览器就能完成请求和响应的过程 应用场景：微信登录获取扫码人信息，微信支付查询支付状态 CookieCookie特点： 客户端技术，存储在浏览器中 每次发送请求带着cookie值进行发送 cookie有默认会话级别，关闭浏览器cookie默认不存在了，但是可以设置cookie有效时长 微信登录、微信支付 可看上文描述 阿里云OSS 作为文件存储服务器 添加讲师的时候上传讲师头像功能中用到 阿里云视频点播 视频的上传、删除、播放 整合阿里云视频播放器进行视频播放 使用视频播放凭证播放 官方106三网短信注册时候，发送手机验证码，存储到redis中并且设置过期时间，用于校验 Git代码提交到远程Git仓库 Docker+Jenkins 手动打包运行 idea打包 jenkins自动化部署过程 项目遇到的问题1、前端问题-路由切换问题 多次路由跳转到同一个vue页面，页面中created()方法只会执行一次 （2）解决方案：使用vue监听(watch) 2、前端问题-ES6模块化运行问题 Nodejs不能直接运行ES6模块化代码，需要使用Babel把ES6模块化代码转换ES5代码 执行 3、mp生成19位id值 mp生成id值是19位，JavaScript处理数字类型值时候，只会处理到16位 解决方案：将Long类型改为String类型 4、跨域问题 访问协议，ip地址，端口号，这三个如果有任何一个不一样，就会产生跨域问题 跨域解决方案： 在Controller添加注解@CrossOrigin 通过Gateway网关解决，写一个配置类 注意：上面的方案不能一同使用 5、413问题 上传视频时候，因为Nginx有上传文件大小限制，如果超过Nginx大小，出现413 413原因：请求体过大 解决方案：在Nginx配置客户端提交文件大小 6、Maven加载问题 maven加载项目时候，默认不会加载src-java文件夹里面xml类型文件的 解决方案： 直接复制xml文件到target目录 通过配置实现 项目面试总结1、项目描述1. 对项目总体介绍在线教育项目采用B2C商业模式，使用微服务架构，项目采用前后端分离开发。 2.项目功能模块 自己负责的部分根据实际 在线教育项目分为前台系统和后台系统 前台系统包含：首页数据显示，课程列表和详情，课程支付，课程视频播放，微信登录，微信支付等等。 后台系统包含：权限管理、讲师管理、课程分类管理、课程管理、统计分析等等 3.项目涉及技术前端技术包含：vue、element-ui、nuxt、babel等等 后端技术包含：SpringBoot、SpringCloud、EasyExcel等等 第三方技术包含：阿里云OSS，视频点播，短信服务等等 在线教育计费案例： 小A是一名杭州的创业者，带领团队研发了一个在线教育平台。他希望把视频托管在阿里云上，存量视频大约1000个，占用存储空间近1T，每月预计新增视频100个，并新增存储约100G，课程视频的时长集中在20-40分钟，并且按照不同课程进行分类管理。为了保障各端的观看效果，计划为用户提供“标清480P”和“高清720P”两种清晰度。目前已有用户400人左右，每日平均视频观看次数1000次，在移动端和PC端观看次数比例大致为3:1 2、这是一个项目还是一个产品这是一个产品，项目是从0开始搭建的 3、测试要求首页和视频详情页QPS单机QPS要求 2000+ 经常用每秒查询率来衡量域名系统服务器的机器的性能，其即为QPS QPS = 并发量 / 平均响应时间 4、企业中的项目（产品）开发流程一个中大型项目的开发流程 1、需求调研（产品经理） 2、需求评审（产品/设计/前端/后端/测试/运营） 3、立项（项目经理、品管） 4、UI设计 5、开发 架构、数据库设计、API文档、MOCK数据、开发、单元测试 前端 后端 6、前端后端联调 7、项目提测：黑盒白盒、压力测试（qps） loadrunner 8、bug修改 9、回归测试 10、运维和部署上线 11、灰度发布 12、全量发布 13、维护和运营 5、系统中都有那些角色？数据库是怎么设计的？前台：会员（学员） 后台：系统管理员、运营人员 后台分库，每个微服务一个独立的数据库，使用了分布式id生成器 6、视频点播是怎么实现的（流媒体你们是怎么实现的）我们直接接入了阿里云的云视频点播。云平台上的功能包括视频上传、转码、加密、智能审核、监控统计等。 还包括视频播放功能，阿里云还提供了一个视频播放器。 7、前后端联调经常遇到的问题： 1、请求方式post、get 2、json、x-wwww-form-urlencoded混乱的错误 3、后台必要的参数，前端省略了 4、数据类型不匹配 5、空指针异常 6、分布式系统中分布式id生成器生成的id 长度过大（19个字符长度的整数），js无法解析（js智能解析16个长度：2的53次幂） ​ id策略改成 ID_WORKER_STR 8、前后端分离项目中的跨域问题是如何解决的后端服务器配置：我们的项目中是通过Spring注解解决跨域的 @CrossOrigin 也可以使用nginx反向代理、httpClient、网关 9、说说你做了哪个部分、遇到了什么问题、怎么解决的 问题1： 分布式id生成器在前端无法处理，总是在后三位进行四舍五入。 分布式id生成器生成的id是19个字符的长度，前端javascript脚本对整数的处理能力只有2的53次方，也就是最多只能处理16个字符 解决的方案是把id在程序中设置成了字符串的性质 问题2： 项目迁移到Spring-Cloud的时候，经过网关时，前端传递的cookie后端一只获取不了，看了cloud中zuul的源码，发现向下游传递数据的时候，zull默认过滤了敏感信息，将cookie过滤掉了 10、分布式系统的id生成策略https://www.cnblogs.com/haoxinyue/p/5208136.html 11、项目组有多少人，人员如何组成？ 不要太教条，说说人一任职务 12、分布式系统的CAP原理CAP定理： 指的是在一个分布式系统中，Consistency（一致性）、 Availability（可用性）、Partition tolerance（分区容错性），三者不可同时获得。 一致性（C）：在分布式系统中的所有数据备份，在同一时刻是否同样的值。（所有节点在同一时间的数据完全一致，越多节点，数据同步越耗时） 可用性（A）：负载过大后，集群整体是否还能响应客户端的读写请求。（服务一直可用，而且是正常响应时间） 分区容错性（P）：分区容错性，就是高可用性，一个节点崩了，并不影响其它的节点（100个节点，挂了几个，不影响服务，越多机器越好） CA 满足的情况下，P不能满足的原因： 数据同步(C)需要时间，也要正常的时间内响应(A)，那么机器数量就要少，所以P就不满足 CP 满足的情况下，A不能满足的原因： 数据同步(C)需要时间, 机器数量也多(P)，但是同步数据需要时间，所以不能再正常时间内响应，所以A就不满足 AP 满足的情况下，C不能满足的原因： 机器数量也多(P)，正常的时间内响应(A)，那么数据就不能及时同步到其他节点，所以C不满足 注册中心选择的原则： Zookeeper：CP设计，保证了一致性，集群搭建的时候，某个节点失效，则会进行选举行的leader，或者半数以上节点不可用，则无法提供服务，因此可用性没法满足 Eureka：AP原则，无主从节点，一个节点挂了，自动切换其他节点可以使用，去中心化 结论： 分布式系统中P,肯定要满足，所以我们只能在一致性和可用性之间进行权衡 如果要求一致性，则选择zookeeper，如金融行业 如果要求可用性，则Eureka，如教育、电商系统 没有最好的选择，最好的选择是根据业务场景来进行架构设计 13、前端渲染和后端渲染有什么区别前端渲染是返回json给前端，通过javascript将数据绑定到页面上 后端渲染是在服务器端将页面生成直接发送给服务器，有利于SEO的优化 14、能画一下系统架构图吗","categories":[{"name":"项目","slug":"项目","permalink":"http://mjean.life/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"guli-college","slug":"项目/guli-college","permalink":"http://mjean.life/categories/%E9%A1%B9%E7%9B%AE/guli-college/"}],"tags":[{"name":"项目总结","slug":"项目总结","permalink":"http://mjean.life/tags/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"}]},{"title":"Nginx学习笔记","slug":"nginx","date":"2021-04-16T08:01:36.000Z","updated":"2022-04-18T12:48:45.800Z","comments":true,"path":"posts/f5398568.html","link":"","permalink":"http://mjean.life/posts/f5398568.html","excerpt":"","text":"Nginx 简介前言本次学习作者是通过尚硅谷的Nginx教程进行的，链接 什么是NginxNginx (“engine x”)是一个高性能的HTTP和反向代理服务器，特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。Nginx专为性能优化而开发，性能是其最重要的考量，实现上非常注重效率，能经受高负载的考验，有报告表明能支持高达50000个并发连接数。 正向代理 反向代理 动静分离 Nginx相关概念正向和反向代理正向代理是一个位于客户端和目标服务器之间的代理服务器(中间服务器)。为了从原始服务器取得内容，客户端向代理服务器发送一个请求，并且指定目标服务器，之后代理向目标服务器转交并且将获得的内容返回给客户端。正向代理的情况下客户端必须要进行一些特别的设置才能使用。 反向代理正好相反。对于客户端来说，反向代理就好像目标服务器。并且客户端不需要进行任何设置。客户端向反向代理发送请求，接着反向代理判断请求走向何处，并将请求转交给客户端，使得这些内容就好似他自己一样，一次客户端并不会感知到反向代理后面的服务，也因此不需要客户端做任何设置，只需要把反向代理服务器当成真正的服务器就好了。 负载均衡负载均衡 客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。 这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？ 我们首先想到的可能是升级服务器的配置，比如提高 CPU 执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么办呢？ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡 动静分离为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 Nginx 安装 下面的操作是以Centos7为例 使用远程连接工具连接Centos7操作系统 安装nginx相关依赖 gcc pcre openssl zlib 安装 nginx 需要先将官网下载的源码进行编译，编译依赖 gcc 环境，如果没有 gcc 环境，则需要安装： $ yum install gcc-c++ PCRE(Perl Compatible Regular Expressions) 是一个Perl库，包括 perl 兼容的正则表达式库。nginx 的 http 模块使用 pcre 来解析正则表达式，所以需要在 linux 上安装 pcre 库，pcre-devel 是使用 pcre 开发的一个二次开发库。nginx也需要此库。命令： $ yum install -y pcre pcre-devel zlib 库提供了很多种压缩和解压缩的方式， nginx 使用 zlib 对 http 包的内容进行 gzip ，所以需要在 Centos 上安装 zlib 库。 $ yum install -y zlib zlib-devel OpenSSL 是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。nginx 不仅支持 http 协议，还支持 https（即在ssl协议上传输http），所以需要在 Centos 安装 OpenSSL 库。 $ yum install -y openssl openssl-devel 安装Nginx 下载nginx，两种方式 a. 直接下载.tar.gz安装包，地址：https://nginx.org/en/download.html b. 使用wget命令下载（推荐）。确保系统已经安装了wget，如果没有安装，执行 yum install wget 安装。 $ wget -c https://nginx.org/download/nginx-1.19.0.tar.gz 依然是直接命令： $ tar -zxvf nginx-1.19.0.tar.gz $ cd nginx-1.19.0 配置： 在 nginx-1.12.0 版本中不需要去配置相关东西，默认就可以了。当然，如果你要自己配置目录也是可以的。 使用默认配置 $ ./configure 自定义配置（不推荐） $ ./configure \\ --prefix=/usr/local/nginx \\ --conf-path=/usr/local/nginx/conf/nginx.conf \\ --pid-path=/usr/local/nginx/conf/nginx.pid \\ --lock-path=/var/lock/nginx.lock \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --with-http_gzip_static_module \\ --http-client-body-temp-path=/var/temp/nginx/client \\ --http-proxy-temp-path=/var/temp/nginx/proxy \\ --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \\ --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \\ --http-scgi-temp-path=/var/temp/nginx/scgi 编辑安装 $ make &amp;&amp; make install Nginx常用的命令和配置文件Nginx常用命令使用nginx操作命令前提条件:必须进入nginx的目录/usr/local/nginx/sbin 查看版本号 $ ./nginx -v 启动命令 $ ./nginx 关闭命令 $ ./nginx -s stop 重新加载命令 $ ./nginx -s reload 查看nginx进程(可在其他目录中使用) $ ps -ef|grep nginx 启动成功后，在浏览器可以看到这样的页面： nginx.conf 配置文件nginx 安装目录下，其默认的配置文件都放在这个目录的 conf 目录下，而主配置文件 nginx.conf 也在其中，后续对 nginx 的使用基本上都是对此配置文件进行相应的修改 nginx.conf 结构 全局块从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。 比如上面第一行配置的： worker_processes 1; 这是 Nginx 服务器并发处理服务的关键配置，worker_processes 值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约 events 块events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 events { worker_connections 1024; } 上述例子就表示每个 work process 支持的最大连接数为 1024. 这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。 http 块这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。 需要注意的是：http 块也可以包括 http 全局块、server 块。 http { include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } http全局块http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 upstream（上游服务器设置，主要为反向代理、负载均衡相关配置，upstream 的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡 server块这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。 而每个 server 块也分为全局 server 块，以及可以同时包含多个 locaton 块。 全局 server 块最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 location块一个 server 块可以配置多个 location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是 IP 别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 总结Nginx 配置文件主要分成四部分：main（全局设置）、server（主机设置）、upstream（上游服务器设置，主要为反向代理、负载均衡相关配置）和 location（URL匹配特定位置后的设置）。 main 部分设置的指令影响其他所有部分的设置； server 部分的指令主要用于制定虚拟主机域名、IP 和端口号； upstream 的指令用于设置一系列的后端服务器，设置反向代理及后端服务器的负载均衡； location 部分用于匹配网页位置（比如，根目录“/”，“/images”，等等）。 他们之间的关系：server 继承 main，location 继承 server；upstream 既不会继承指令也不会被继承。 Nginx 配置实例-反向代理反向代理实例一 实现效果：使用 nginx 反向代理，访问 www.123.com 直接跳转到 192.168.252.128:8080 实现过程 启动一个 tomcat，浏览器地址栏输入 192.168.252.128:8080，出现如下界面 通过修改本地 host 文件，将 www.123.com 映射到 192.168.252.128 在C:\\Windows\\System32\\drivers\\etc\\hosts文件末添加192.168.252.128 www.123.com 修改nginx的配置文件，在nginx.conf 配置文件中增加如下配置 如上配置，我们监听 80 端口，访问域名为 www.123.com，不加端口号时默认为 80 端口，故 访问该域名时会跳转到 127.0.0.1:8080 路径上。在浏览器端输入 www.123.com 结果如下： 反向代理实例二 实现效果：使用 nginx 反向代理，根据访问的路径跳转到不同端口的服务中 nginx 监听端口为 9001， 访问 http://192.168.252.128:9001/edu/直接跳转到 127.0.0.1:8080 访问 http://192.168.252.128:9001/vod/直接跳转到 127.0.0.1:8081 实现过程 第一步，准备两个 tomcat，一个 8080 端口，一个 8081 端口，并准备好测试的页面 修改nginx的配置文件，在nginx.conf 配置文件中增加如下配置 重启nginx服务器，使配置文件生效 最后测试结果如下： location 指令说明 Nginx location doc 该指令用于匹配 URL。 语法如下： location [ = | ~ | ~* | ^~ ] uri { } = ：用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求。 ~：用于表示 uri 包含正则表达式，并且区分大小写。 ~*：用于表示 uri 包含正则表达式，并且不区分大小写。 ^~：用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配。 注意：如果 uri 包含正则表达式，则必须要有 ~ 或者 ~\\* 标识。 Nginx 配置实例-负载均衡 浏览器地址栏输入地址http://192.168.252.128/edu/a.html，负载均衡效果，平均 8080 和 8081端口中 实现过程 准备两台 tomcat 服务器，一台 8080，一台 8081 在两台 tomcat 里面 webapps 目录中，创建名称是 edu 文件夹，在 edu 文件夹中创建 页面 a.html，用于测试 在 nginx 的配置文件中进行负载均衡的配置 负载均衡分配策略负载均衡（load balance）即是将负载分摊到不同的服务单元，既保证服务的可用性，又保证响应足够快，给用户很好的体验。 快速增长的访问量和数据流量催生了各式各样的负载均衡产品，很多专业的负载均衡硬件提供了很好的功能，但却价格不菲，这使得负载均衡软件大受欢迎，nginx 就是其中的一个，在 linux 下有 Nginx、 LVS、 Haproxy 等等服务可以提供负载均衡服务，而且 Nginx 提供了几种分配方式(策略) 轮询这是Ngnix负载均衡默认分配策略。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 加权weight 代表权重，默认为 1，权重越高被分配的客户端越多。指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。例如： upstream myserver{ server 192.168.252.128:8080 weight=8; server 192.168.252.128:8081 weight=2; } ip_hash每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 例如： upstream myserver{ ip_hash; server 192.168.252.128:8080; server 192.168.252.128:8081; } fair这是Ngnix负载均衡第三方分配策略。按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream myserver{ server 192.168.252.128:8080; server 192.168.252.128:8081; fair; } Nginx 配置实例-动静分离Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和 静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。 动静分离从目前实现角度来讲大致分为两种： 一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。 通过 location 指定不同的后缀名实现不同的请求转发。 通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可， 所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件， 不建议使用 Expires 来缓存），假如将其设置为 3d，表示在这 3 天之内访问这个 URL，发送 一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。 实现过程 在linux系统中准备静态资源，用于进行访问 修改nginx的配置文件，在nginx.conf 配置文件中增加如下配置 测试： 浏览器中输入地址 http://192.168.252.128/image/zm.jpg 浏览器中输入地址 http://192.168.252.128/image/ 因为配置文件 autoindex on,可查阅/image/目录下的文件列表 浏览器中输入地址 http://192.168.252.128/www/a.html Nginx 配置高可用的集群（高可用主备模式） 为什么要配置nginx高可用？以防单一nginx挂了，另一个nginx能担当重任。 配置高可用的准备工作 需要两台服务器 192.168.17.129 和 192.168.17.131 在两台服务器安装 Nginx 在两台服务器安装 keepalived 需要虚拟ip 在两台服务器安装 keepalived 使用 yum 命令进行安装yum install keepalived –y 安装之后，在 etc 里面生成目录 keepalived，有文件 keepalived.conf 完成高可用配置(主从配置) 修改 /etc/keepalived/keepalived.conf 配置文件 global_defs { notification_email { acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc } notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.17.129 smtp_connect_timeout 30 router_id LVS_DEVEL } vrrp_script chk_http_port { script \"/usr/local/src/nginx_check.sh\" interval 2 #（检测脚本执行的间隔） weight 2 } vrrp_instance VI_1 { state BACKUP # 备份服务器上将 MASTER 改为 BACKUP interface ens33 //网卡 virtual_router_id 51 # 主、备机的 virtual_router_id 必须相同 priority 90 # 主、备机取不同的优先级，主机值较大，备份机值较小 advert_int 1 authentication { auth_type PASS auth_pass 1111 } virtual_ipaddress { 192.168.17.50 // VRRP H 虚拟地址 } } 在/usr/local/src 添加检测脚本 #!/bin/bash A=`ps -C nginx – no-header |wc -l` if [ $A -eq 0 ];then /usr/local/nginx/sbin/nginx sleep 2 if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then killall keepalived fi fi 把两台服务器上 Nginx 和 keepalived 启动 启动 Nginx： ./nginx 启动 keepalived： systemctl start keepalived.service 测试 在浏览器地址栏输入 虚拟 ip 地址 192.168.17.50 把主服务器（192.168.17.129） Nginx 和 keepalived 停止，再输入 192.168.17.50 Nginx 原理解析master 和 worker 一个master和多个woker有好处首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断， master 进程则很快启动新的worker进程。当然， worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。 可以使用 ./nginx –s reload 热部署，利用nginx进行热部署操作 每个worker是独立的进程，如果有其中的一个worker出现问题，其他worker独立的，继续进行争抢，实现请求过程，不会造成服务中断 设置多少个worker合适Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。 所以 worker 数和服务器的cpu数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗。 #设置 worker 数量。 worker_processes 4 #work 绑定 cpu(4 work 绑定 4cpu)。 worker_cpu_affinity 0001 0010 0100 1000 #work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 worker_cpu_affinity 0000001 00000010 00000100 00001000 连接数worker_connection这个值是表示每个 worker 进程所能建立连接的最大值，所以，一个 nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。当然，这里说的是最大连接数，对于 HTTP请求本地资源来说，能够支持的最大并发数量是 worker_connections * worker_processes。 如果是支持 http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是： worker_connections * worker_processes /2，而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections *worker_processes/4。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，各会占用两个连接。 第一个：发送请求，占用了worker 的几个连接数？ 答案：2或者4个 第二个：nginx有一个master，有四个worker，每个worker支持最大的连接数1024，支持的最大并发数是多少？ 普通的静态访问最大并发数是： worker_connections * worker_processes /2， 而如果是HTTP作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/4。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Nginx","slug":"笔记/Nginx","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Nginx/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://mjean.life/tags/Nginx/"}]},{"title":"Redis学习笔记","slug":"redis","date":"2021-04-14T11:09:47.000Z","updated":"2022-04-18T12:48:45.836Z","comments":true,"path":"posts/8eda3648.html","link":"","permalink":"http://mjean.life/posts/8eda3648.html","excerpt":"","text":"前言本次学习是从狂神的Redis教程视频中进行的，感谢狂神的分享。视频地址 NoSQL概述为什么要用NoSQL 单机MySQL的年代！ 90年代，一个基本的网站访问量一般不会太大，单个数据库完全足够！那个时候，更多的是去使用静态网页html~服务器根本没有太大的压力！ 思考一下，这种情况下：整个网站的瓶颈是什么？ 1. 数据量如果太大，一个机器放不下 2. 数据的索引(B+ Tree)，一个机器内存也放不下 3. 访问量巨大(读写混合)，一个服务器承受不了 只要开始出现以上的三种情况之一，就必须要升级！ Memcached(缓存) + MySQL + 垂直拆分(读写分离) 网站80%的情况都是在读，每次都是去查阅数据库的话就十分的麻烦！所以说我们希望减轻数据的压力，我们可以使用缓存来保证效率！ 发展过程：优化数据结构和索引–&gt;文件缓存(IO)–&gt;Memcached(当时最热门的技术！) 分库分表 + 水平拆分 + MySQL集群 技术和业务在发展的同时，对人的要求也越来越高！ 本质：数据库(读，写) 早些年MyISAM：表锁，十分影响效率！高并发下就会出现严重的锁问题 转战Innodb：行锁，慢慢的就开始使用分库分表来解决写的压力！ 如今的年代 2010-2020 十年之间，世界已经发生了翻天覆地的变化；(定位，也是一种数据，音乐，热榜！) MySQL 等关系型数据库就不够用了！数据量很大，变化很快~！ MySQL 有的使用它来存储一些比较大的文件，博客，图片！数据库表很大，效率低！如果有一种数据库来专门处理这种数据， MySQL 压力就变得十分小(研究如何处理这些问题！)大数据的IO压力下，表几乎没法更改！ 目前一个基本的互联网项目！ 为什么要用NoSQL！ 用户的个人信息，社交网络，地理位置。用户自己产生的数据，用户日志等等爆发式增长！ 这时候我们就需要使用NoSQL数据库，NoSQL 可以很好的处理以上的情况！ 什么是NoSQL NoSQL NoSQL = Not Only SQL (不仅仅是SQL) 关系型数据库：表格，行，列 泛指非关系型数据库的，随着web2.0 互联网的诞生！传统的关系型数据库很难对付web2.0 时代！尤其是超大规模的高并发的社区！暴露出来很多难以克服的问题，NoSQL在当今大数据环境下发展的十分迅速，Redis是发展最快的，而且是我们当下必须要掌握的一个技术！ 很多数据类型用户的个人信息，社交网络，地理位置。这些数据类型的存储不需要一个固定的格式！不需要多余的操作就可以横向扩展！Redis通过Map&lt;String,Object&gt;使用键值对来控制！ NoSQL 特点 解耦！ 方便扩展(数据之间没有关系，很好扩展！) 大数据量高性能(Redis 一秒8万次，读取11万，NoSQL的缓存记录级，是一种细粒度的缓存，性能会比较慢！) 数据类型是多样性的！(不需要事先设计数据库！随取随用！如果是数据量十分大的表，很多人就无法设计了！) 传统RDBMS 和 NoSQL 传统的RDBMS - 结构化组织 - SQL - 数据和关系都存在单独的表中rowcol - 操作，数据定义语言 - 严格的一致性 - 基础的事务 - ...... NoSQL - 不仅仅是数据 - 没有固定的查询语言 - 键值对存储，列存储，文档存储，图形数据库(社交关系) - 最终一致性 - CAP定理和BASE - 高性能，高可用，高可扩 - ...... 了解：3V + 3高 大数据时代的3V：主要是描述问题的 海量Volume 多样Variety 实时Velocity 大数据时代的3高：主要是对程序的要求 高并发 高可扩 高性能 真正在公司中的实践：NoSQL + RDBMS 一起使用才是最强的，阿里巴巴的架构演进！ 技术没有高低之分，就看如何去用！(提升内功，思维的提高！) 阿里巴巴演进分析我们查看一下淘宝网站 思考问题：这么多东西难道都是在一个数据库中的吗？ 这显然是不可能的，是使用了多种数据库才实现的 # 1.商品的基本信息 名称、价格、商家信息。关系型数据库就可以解决了！MySQL/Oracle # 2.商品的描述、评论(文字比较多) 文档型数据库中，MongoDB # 3.图片 分布式文件系统 FastDFS - 淘宝自己的 TFS - Google的 GFs - Hadoop HDFS - 阿里云的 OSS # 4.商品的关键字(搜索) - 搜索引擎solrelasticsearch - Isearch # 5.商品热门的波段信息 - 内存数据库 - Redis、Tair、Memcache # 6.商品的交易，外部的支付接口 - 第三方应用 要知道，一个简单地网页背后的技术一定不是大家所想的那么简单！ 大型互联网应用问题： 数据类型太多了！ 数据源繁多，经常重构！ 数据要改造，大面积改造？ 解决方案： NoSQL的四大分类KV键值对： 新浪：Redis 美团：Redis + Tair 阿里、百度：Redis + Memcache 文档型数据库(bson格式和json一样)： MongoDB(一般必须要掌握) MongoDB 是一个基于分布式文件存储的数据库，C++ 编写，主要用来处理大量的文档！ MongoDB 是一个介于关系型数据库和非关系型数据库中间的产品！MongoDB 是非关系型数据库中功能最丰富，最像关系型数据库的！ ConthDB 列存储数据库： HBase 分布式文件系统 图型关系数据库： 他不是存放图形，存放的是关系，比如：社交网络，广告推荐！ Neo4j，InfoGrid； 四者对比！ Redis入门概述 Redis 是什么？ Redis (Remote Dictionary Server )，即远程字典服务 ! Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串(strings)， 散列(hashes)， 列表(lists)， 集合(sets)， 有序集合(sorted sets) 与范围查询， bitmaps， hyperloglogs 和 地理空间(geospatial) 索引半径查询。 Redis 内置了 复制(replication)，LUA脚本(Lua scripting)， LRU驱动事件(LRU eviction)，事务(transactions) 和不同级别的 磁盘持久化(persistence)， 并通过 Redis哨兵(Sentinel)和自动 分区(Cluster)提供高可用性(high availability)。 是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 Redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 免费和开源！是当下最热门的 NoSQL 技术之一！也被人们称之为结构化数据库！ Redis 能干嘛？ 内存存储、持久化，内存中是断电即失、所以说持久化很重要 (rdb、aof) 效率高，可以用于高速缓存 发布订阅系统 地图信息分析 计时器、计数器 (浏览量！) …….. 特性 多样的数据类型 持久化 集群 事务 …… 官网：https://redis.io/ 中文网：http://www.redis.cn/ 下载地址：通过官网下载即可！ Linux安装Redis 推荐都是在Linux服务器上搭建的，所以是基于Linux学习的！ 下载安装包 redis-6.2.1.tar.gz 解压安装包 tar -zxvf redis-6.2.1.tar.gz 进入解压后的文件夹，可以看到 redis 的配置文件 基本的环境安装 查看gcc环境 如果没有环境的话，使用 yum install gcc-c++ 安装环境 使用 make 命令，下载需要的文件 之后使用 make install 命令，确认所需要的文件已经安装成功 redis 的默认安装路径 /usr/local/bin 将 redis 的配置文件。复制到新建的目录下 redis 默认不是后台启动的，修改配置文件， vim redis.conf 启动Redis 服务，测试 查看 redis 服务是否开启 关闭 Redis 服务 再次查看 redis 服务是否开启 后面会使用单机Redis集群进行测试 性能测试redis-benchmark 是一个压力测试工具。官方自带的性能测试工具 使用 redis-benchmark -命令参数 即可 图片来源于菜鸟教程 简单测试一下 # 测试： 100个并发连接 100000请求 redis-benchmark -h localhost -p 6379 -c 100 -n 100000 如何查看这些数据？ 基础知识Redis默认有16个数据库 默认使用的是第0个数据库 可以使用select 进行切换 127.0.0.1:6379&gt; select 3 # 切换数据库 OK 127.0.0.1:6379[3]&gt; dbsize # 查看数据库大小 (integer) 0 127.0.0.1:6379[3]&gt; keys * # 查看数据库所有的key 1) \"name\" 清楚当前数据库 flushdb 127.0.0.1:6379[3]&gt; flushdb OK 127.0.0.1:6379[3]&gt; keys * (empty array) 清除全部的数据库flushall 127.0.0.1:6379&gt; keys * 1) \"key:__rand_int__\" 2) \"mylist\" 3) \"name\" 4) \"counter:__rand_int__\" 5) \"myhash\" 127.0.0.1:6379&gt; select 3 OK 127.0.0.1:6379[3]&gt; flushall OK 127.0.0.1:6379[3]&gt; select 0 OK 127.0.0.1:6379&gt; keys * (empty array) 127.0.0.1:6379&gt; Redis是单线程的明白Redis是很快的,官方表示, Redis是基于内存操作, CPU不是Redis的性能瓶颈, Redis的瓶颈是根据机器的内存和网络带宽，既然可以使用单线程来实现,就使用单线程了!所以就使用了单线程了! Redis是C语言写的,官方提供的数据为100000+ 的QPS ,完全不比同样是使用key-value的Memcache差! Redis为什么单线程还这么快? 误区1 :高性能的服务器一定是多线程的? 误区2 :多线程(CPU上下文会切换! )一定比单线程效率高! CPU&gt;内存&gt;硬盘的速度 核心: Redis是将所有的数据全部放在内存中的,所以说使用单线程去操作效率就是最高的,多线程(CPU上下文会切换:耗时的操作! ! ! ) , 对于内存系统来说,如果没有上下文切换,效率就是最高的!多次读写都是在一个CPU上的,在内存情况下,这个就是最佳的方案! 五大数据类型 官方文档 全文翻译： Redis 是一个开源（BSD许可）的，内存中的数据结构存储系统，它可以用作数据库、缓存和消息中间件。 它支持多种类型的数据结构，如 字符串(strings)， 散列(hashes)， 列表(lists)， 集合(sets)， 有序集合(sorted sets) 与范围查询， bitmaps， hyperloglogs 和 地理空间(geospatial) 索引半径查询。 Redis 内置了 复制(replication)，LUA脚本(Lua scripting)， LRU驱动事件(LRU eviction)，事务(transactions) 和不同级别的 磁盘持久化(persistence)， 并通过 Redis哨兵(Sentinel)和自动 分区(Cluster)提供高可用性(high availability)。 Redis-Key常用命令Redis命令不区分大小写 127.0.0.1:6379&gt; keys * (empty array) 127.0.0.1:6379&gt; clear 127.0.0.1:6379&gt; set name xhc # 设置k-v键值对 OK 127.0.0.1:6379&gt; keys * 1) \"name\" 127.0.0.1:6379&gt; set age 1 OK 127.0.0.1:6379&gt; keys * 1) \"name\" 2) \"age\" 127.0.0.1:6379&gt; exists name # 判断key是否存在 (integer) 1 127.0.0.1:6379&gt; exists name1 (integer) 0 127.0.0.1:6379&gt; move name 1 #移除key，1 表示当前库 (integer) 1 127.0.0.1:6379&gt; keys * 1) \"age\" 127.0.0.1:6379&gt; set name xhc OK 127.0.0.1:6379&gt; keys * 1) \"name\" 2) \"age\" 127.0.0.1:6379&gt; get name \"xhc\" 127.0.0.1:6379&gt; expire name 10 #设置key的过期时间，单位是秒 (integer) 1 127.0.0.1:6379&gt; ttl name #查看key的过期时间 -2表示已经过期 (integer) 6 127.0.0.1:6379&gt; ttl name (integer) 2 127.0.0.1:6379&gt; get name (nil) 127.0.0.1:6379&gt; 127.0.0.1:6379&gt; type name #查看key的类型！！ string 127.0.0.1:6379&gt; type age string 如果遇到不会的命令，可以在官网查看帮助文档 String(字符串)################################################################################################################## 127.0.0.1:6379&gt; set key1 v1 # 设置键值对 OK 127.0.0.1:6379&gt; get key1 # 获取值 \"v1\" 127.0.0.1:6379&gt; keys * # 查看所有的key 1) \"key1\" 127.0.0.1:6379&gt; EXISTS key1 # 判断key是否存在 (integer) 1 127.0.0.1:6379&gt; APPEND key1 \"hello\" # 向指定的key追加字符串，如果当前key不存在就相当于创建一个 (integer) 7 127.0.0.1:6379&gt; get key1 \"v1hello\" 127.0.0.1:6379&gt; strlen key1 # 获取字符串的长度 (integer) 7 127.0.0.1:6379&gt; APPEND key1 \",xhc\" (integer) 11 127.0.0.1:6379&gt; strlen key1 (integer) 11 127.0.0.1:6379&gt; get key1 \"v1hello,xhc\" ################################################################################################################## 127.0.0.1:6379&gt; set views 0 # 初始化浏览量为0 OK 127.0.0.1:6379&gt; get views \"0\" 127.0.0.1:6379&gt; incr views # 自增1 (integer) 1 127.0.0.1:6379&gt; incr views (integer) 2 127.0.0.1:6379&gt; get views \"2\" 127.0.0.1:6379&gt; decr views # 自减1 (integer) 1 127.0.0.1:6379&gt; decr views (integer) 0 127.0.0.1:6379&gt; get views \"0\" 127.0.0.1:6379&gt; incrby views 10 # 可以设置步长，指定增量！ (integer) 10 127.0.0.1:6379&gt; incrby views 10 (integer) 20 127.0.0.1:6379&gt; decrby views 5 (integer) 15 127.0.0.1:6379&gt; ################################################################################################################# # 获取指定的范围的字符 range 127.0.0.1:6379&gt; set key1 \"hello,xhc\" # 设置key1的值 OK 127.0.0.1:6379&gt; get key1 \"hello,xhc\" 127.0.0.1:6379&gt; getrange key1 0 3 # 截取字符串，[0,3] \"hell\" 127.0.0.1:6379&gt; getrange key1 0 -1 # 获取全部的字符串 \"hello,xhc\" # 替换 127.0.0.1:6379&gt; set key2 abcdefg OK 127.0.0.1:6379&gt; get key2 \"abcdefg\" 127.0.0.1:6379&gt; setrange key2 1 xx # 替换指定位置开始的字符串 (integer) 7 127.0.0.1:6379&gt; get key2 \"axxdefg\" ################################################################################################################# # setex(set with expire) 设置k-v并设置过期时间 # setnx(set if not exist) 当key不存在时再设置 127.0.0.1:6379&gt; setex key3 30 \"hello\" # 设置key3的值为 hello 30秒后过期 OK 127.0.0.1:6379&gt; ttl key3 (integer) 26 127.0.0.1:6379&gt; get key3 \"hello\" 127.0.0.1:6379&gt; setnx mykey \"redis\" # 如果mykey不存在，创建mykey (integer) 1 127.0.0.1:6379&gt; keys * 1) \"key2\" 2) \"key1\" 3) \"mykey\" 127.0.0.1:6379&gt; ttl key3 (integer) -2 127.0.0.1:6379&gt; setnx mykey \"MongoDB\" # 如果mykey存在，则创建失败 (integer) 0 127.0.0.1:6379&gt; get mykey \"redis\" 127.0.0.1:6379&gt; ################################################################################################################# # mset 批量设置多个值 # mget 批量获取多个值 127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 # mset 批量设置多个值 OK 127.0.0.1:6379&gt; keys * 1) \"k3\" 2) \"k2\" 3) \"k1\" 127.0.0.1:6379&gt; mget k1 k2 k3 # 批量获取多个值 1) \"v1\" 2) \"v2\" 3) \"v3\" 127.0.0.1:6379&gt; msetnx k1 v1 k4 v4 # msetnx 是一个原子性的操作，要么一起成功，要么一起失败！ (integer) 0 127.0.0.1:6379&gt; get k4 (nil) 127.0.0.1:6379&gt; # 对象，如何存放在Redis中 # 这里的key是一个巧妙的设计：user：{ud}:{filed},如此设计在Redis中是完全OK的 127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 2 OK 127.0.0.1:6379&gt; mget user:1:name user:1:age 1) \"zhangsan\" 2) \"2\" 127.0.0.1:6379&gt; ################################################################################################################# # getset 先get然后再set 127.0.0.1:6379&gt; getset db redis # 如果值不存在，则返回 nil (nil) 127.0.0.1:6379&gt; get db \"redis\" 127.0.0.1:6379&gt; getset db mongodb # 如果值存在，获取原来的值，并设置新的值 \"redis\" 127.0.0.1:6379&gt; get db \"mongodb\" 127.0.0.1:6379&gt; String的使用场景：value除了是字符串还可以使数字 计数器 统计多单位的数量 粉丝数 对象缓存存储！ List(列表)在Redis里面，我们可以把 List 玩成 栈、队列、阻塞队列 在Redis里关于List的命令都是L开头的 ################################################################################################################# 127.0.0.1:6379&gt; lpush list one # 将一个值或者多个值，插入到列表头部（左） (integer) 1 127.0.0.1:6379&gt; lpush list two (integer) 2 127.0.0.1:6379&gt; lpush list three (integer) 3 127.0.0.1:6379&gt; lrange list 0 -1 # 获取list中的值 1) \"three\" 2) \"two\" 3) \"one\" 127.0.0.1:6379&gt; lrange list 0 1 # 通过区间获取具体的值 1) \"three\" 2) \"two\" 127.0.0.1:6379&gt; rpush list right # 将一个值或者多个值，插入到列表尾部（右） (integer) 4 ################################################################################################################# # LPOP 移除list的第一个元素 # RPOP 移除list的最后一个元素 127.0.0.1:6379&gt; lrange list 0 -1 1) \"three\" 2) \"two\" 3) \"one\" 4) \"right\" 127.0.0.1:6379&gt; lpop list # 移除list的第一个元素 \"three\" 127.0.0.1:6379&gt; rpop list # 移除list的最后一个元素 \"right\" 127.0.0.1:6379&gt; lrange list 0 -1 1) \"two\" 2) \"one\" ################################################################################################################# # index 通过下标获取list中的某一个值 127.0.0.1:6379&gt; lrange list 0 -1 1) \"two\" 2) \"one\" 127.0.0.1:6379&gt; lindex list 1 # 通过下标获取list中的某一个值 \"one\" 127.0.0.1:6379&gt; lindex list 0 \"two\" 127.0.0.1:6379&gt; ################################################################################################################# # Llen 获取列表的长度 127.0.0.1:6379&gt; lpush list one (integer) 1 127.0.0.1:6379&gt; lpush list two (integer) 2 127.0.0.1:6379&gt; lpush list three (integer) 3 127.0.0.1:6379&gt; llen list # 获取列表的长度 (integer) 3 127.0.0.1:6379&gt; ################################################################################################################# # lrem 移除指定的值 127.0.0.1:6379&gt; lrange list 0 -1 1) \"three\" 2) \"three\" 3) \"two\" 4) \"one\" 127.0.0.1:6379&gt; lrem list 1 one # 移除list集合中指定个数的value，精确匹配 (integer) 1 127.0.0.1:6379&gt; lrange list 0 -1 1) \"three\" 2) \"three\" 3) \"two\" 127.0.0.1:6379&gt; lrem list 1 three (integer) 1 127.0.0.1:6379&gt; lrange list 0 -1 1) \"three\" 2) \"two\" 127.0.0.1:6379&gt; lpush list three (integer) 3 127.0.0.1:6379&gt; lrem list 2 three (integer) 2 127.0.0.1:6379&gt; lrange list 0 -1 1) \"two\" 127.0.0.1:6379&gt; ################################################################################################################# # Ltrim 截取 127.0.0.1:6379&gt; rpush mylist \"hello\" (integer) 1 127.0.0.1:6379&gt; rpush mylist \"hello1\" (integer) 2 127.0.0.1:6379&gt; rpush mylist \"hello2\" (integer) 3 127.0.0.1:6379&gt; rpush mylist \"hello3\" (integer) 4 127.0.0.1:6379&gt; ltrim mylist 1 2 # 通过下标截取指定区间的list，这个list已经改变了，list只剩下截取的元素了 OK 127.0.0.1:6379&gt; lrange mylist 0 -1 1) \"hello1\" 2) \"hello2\" ################################################################################################################# # rpoplpush 移除列表的最后一个元素，并将它移动到新的列表中 127.0.0.1:6379&gt; rpush mylist \"hello\" (integer) 1 127.0.0.1:6379&gt; rpush mylist \"hello1\" (integer) 2 127.0.0.1:6379&gt; rpush mylist \"hello2\" (integer) 3 127.0.0.1:6379&gt; rpoplpush mylist myotherlist # 移除列表的最后一个元素，并将它移动到新的列表中 \"hello2\" 127.0.0.1:6379&gt; lrange mylist 0 -1 1) \"hello\" 2) \"hello1\" 127.0.0.1:6379&gt; lrange myotherlist 0 -1 1) \"hello2\" ################################################################################################################# # lset 将列表指定下标的值替换为另一个值，更新操作 127.0.0.1:6379&gt; exists list # 判断这个列表是否存在 (integer) 0 127.0.0.1:6379&gt; lset list 0 item # 如果不存在，执行lset命令 就会报错 (error) ERR no such key 127.0.0.1:6379&gt; lpush list value1 (integer) 1 127.0.0.1:6379&gt; lrange list 0 0 1) \"value1\" 127.0.0.1:6379&gt; lset list 0 item # 如果存在，更新当前下标的值 OK 127.0.0.1:6379&gt; lrange list 0 0 1) \"item\" 127.0.0.1:6379&gt; lset list 1 other # 如果不存在，就会报错 (error) ERR index out of range ################################################################################################################# # linsert 将某个具体的value插入到列表中指定的某个元素的前面或者后面 127.0.0.1:6379&gt; rpush mylist \"hello\" (integer) 1 127.0.0.1:6379&gt; rpush mylist \"world\" (integer) 2 127.0.0.1:6379&gt; linsert mylist before \"world\" \"other\" (integer) 3 127.0.0.1:6379&gt; lrange mylist 0 -1 1) \"hello\" 2) \"other\" 3) \"world\" 127.0.0.1:6379&gt; linsert mylist after \"world\" \"new\" (integer) 4 127.0.0.1:6379&gt; lrange mylist 0 -1 1) \"hello\" 2) \"other\" 3) \"world\" 4) \"new\" 127.0.0.1:6379&gt; 小结 他实际上是一个链表，before Node after，left right 都可以插入值 如果list不存在，创建新的链表 如果list存在，新增内容 如果移除了所有值，空链表，也代表不存在！ 在两边插入或者改动值，效率最高！中间元素，相对来说效率会低一点~ 消息排队！消息队列(Lpush Rpop)，栈(Lpush Lpop)! Set(集合)set中的值不可以重复 ################################################################################################################# # sadd 向set集合中添加元素 # smembers 查看set元素中的所有值 # sismember 判断某一个值是不是在set集合中 127.0.0.1:6379&gt; sadd myset \"hello\" # 向set集合中添加元素 (integer) 1 127.0.0.1:6379&gt; sadd myset \"xhc\" (integer) 1 127.0.0.1:6379&gt; sadd myset \"lovexhc\" (integer) 1 127.0.0.1:6379&gt; smembers myset # 查看set元素中的所有值 1) \"hello\" 2) \"xhc\" 3) \"lovexhc\" 127.0.0.1:6379&gt; sismember myset hello # 判断某一个值是不是在set集合中 1表示存在，0表示不存在 (integer) 1 127.0.0.1:6379&gt; sismember myset world (integer) 0 ################################################################################################################# # scard 获取set集合中的元素个数！ 127.0.0.1:6379&gt; scard myset (integer) 4 ################################################################################################################# # srem 移除set集合中的指定元素 127.0.0.1:6379&gt; srem myset \"hello\" # 移除set集合中的指定元素 (integer) 1 127.0.0.1:6379&gt; scard myset (integer) 3 127.0.0.1:6379&gt; smembers myset 1) \"xhc\" 2) \"lovexhc2\" 3) \"lovexhc\" ################################################################################################################# # srandmember 随机抽取元素 127.0.0.1:6379&gt; smembers myset 1) \"xhc\" 2) \"lovexhc2\" 3) \"lovexhc\" 127.0.0.1:6379&gt; srandmember myset # 随机抽选出一个元素 \"xhc\" 127.0.0.1:6379&gt; srandmember myset \"lovexhc2\" 127.0.0.1:6379&gt; srandmember myset \"lovexhc\" 127.0.0.1:6379&gt; srandmember myset 2 # 随机抽选出指定个数的元素 1) \"lovexhc\" 2) \"lovexhc2\" 127.0.0.1:6379&gt; srandmember myset 2 1) \"xhc\" 2) \"lovexhc\" 127.0.0.1:6379&gt; srandmember myset \"lovexhc2\" ################################################################################################################# # 随机删除元素（spop)，删除指定的元素 127.0.0.1:6379&gt; smembers myset 1) \"xhc\" 2) \"lovexhc2\" 3) \"lovexhc\" 127.0.0.1:6379&gt; spop myset # 随机删除set集合中的元素！ \"xhc\" 127.0.0.1:6379&gt; spop myset \"lovexhc2\" 127.0.0.1:6379&gt; smembers myset 1) \"lovexhc\" 127.0.0.1:6379&gt; ################################################################################################################# # smove 将一个指定的值，移动到另外一个set集合 127.0.0.1:6379&gt; sadd myset hello (integer) 1 127.0.0.1:6379&gt; sadd myset world (integer) 1 127.0.0.1:6379&gt; sadd myset xhc (integer) 1 127.0.0.1:6379&gt; sadd myset2 set2 (integer) 1 127.0.0.1:6379&gt; smove myset myset2 xhc # 将一个指定的值，移动到另外一个set集合 (integer) 1 127.0.0.1:6379&gt; smembers myset 1) \"world\" 2) \"hello\" 127.0.0.1:6379&gt; smembers myset2 1) \"xhc\" 2) \"set2\" ################################################################################################################# 微博，B站，共同关注！（并集） 数字集合类： - 差集 SDIFF - 交集 SINTER - 并集 SUNION 127.0.0.1:6379&gt; sadd key1 a (integer) 1 127.0.0.1:6379&gt; sadd key1 b (integer) 1 127.0.0.1:6379&gt; sadd key1 c (integer) 1 127.0.0.1:6379&gt; sadd key2 c (integer) 1 127.0.0.1:6379&gt; sadd key2 d (integer) 1 127.0.0.1:6379&gt; sadd key2 e (integer) 1 127.0.0.1:6379&gt; sdiff key1 key2 # 差集 1) \"a\" 2) \"b\" 127.0.0.1:6379&gt; sinter key1 key2 # 交集 1) \"c\" 127.0.0.1:6379&gt; sunion key1 key2 # 并集 1) \"b\" 2) \"c\" 3) \"d\" 4) \"a\" 5) \"e\" 微博 A用户将所有关注的人放在一个set集合中将它的粉丝也放在一个集合中！ 共同关注 Hash(哈希)################################################################################################################# 127.0.0.1:6379&gt; hset myhash field1 xhc # 向map集合中插入一个键值对 key-value (integer) 1 127.0.0.1:6379&gt; hget myhash field1 # 从map集合获取一个值 \"xhc\" 127.0.0.1:6379&gt; hmset myhash field1 hello field2 world # 向map集合中插入多个键值对 key-value OK 127.0.0.1:6379&gt; hmget myhash field1 field2 # 从map集合获取多个值 1) \"hello\" 2) \"world\" 127.0.0.1:6379&gt; hgetall myhash # 获取map中全部值 1) \"field1\" 2) \"hello\" 3) \"field2\" 4) \"world\" ################################################################################################################# # hdel 删除 127.0.0.1:6379&gt; hdel myhash field1 # 删除指定的键值对 (integer) 1 127.0.0.1:6379&gt; hgetall myhash 1) \"field2\" 2) \"world\" ################################################################################################################# # hlen 获取map的长度 127.0.0.1:6379&gt; hmset myhash field1 hello field2 world OK 127.0.0.1:6379&gt; hgetall myhash 1) \"field2\" 2) \"world\" 3) \"field1\" 4) \"hello\" 127.0.0.1:6379&gt; hlen myhash # 获取map的长度 (integer) 2 ################################################################################################################# # hexists 判断map中key是否存在 127.0.0.1:6379&gt; hexists myhash field1 # 判断hash中指定的字段是否存在 (integer) 1 127.0.0.1:6379&gt; hexists myhash field3 (integer) 0 ################################################################################################################# # hkeys 只获得所有的key # hvals 只获得所有的value 127.0.0.1:6379&gt; hkeys myhash # 只获得所有的key 1) \"field2\" 2) \"field1\" 127.0.0.1:6379&gt; hvals myhash # 只获得所有的value 1) \"world\" 2) \"hello\" ################################################################################################################# 127.0.0.1:6379&gt; hset myhash field3 5 (integer) 1 127.0.0.1:6379&gt; hincrby myhash field3 1 (integer) 6 127.0.0.1:6379&gt; hincrby myhash field3 -1 (integer) 5 127.0.0.1:6379&gt; hsetnx myhash field4 hello # 如果不存在则能设置 (integer) 1 127.0.0.1:6379&gt; hsetnx myhash field4 world # 如果存在则不能设置 (integer) 0 hash存放变更的数据，尤其是是用户信息之类的，经常变动的信息! hash 更适合于对象的存储，String更加适合字符串存储! Zset(有序集合)在set的基础上,增加了一个值, set k1 v1 。 zset k1 score1 V1，通过score的大小来排序 127.0.0.1:6379&gt; zadd myset 1 one # 添加一个值 (integer) 1 127.0.0.1:6379&gt; zadd myset 2 two 3 three # 添加多个值 (integer) 2 127.0.0.1:6379&gt; zrange myset 0 -1 1) \"one\" 2) \"two\" 3) \"three\" 127.0.0.1:6379&gt; ################################################################################################################# # 排序如何实现 127.0.0.1:6379&gt; zadd salary 2500 xiaohong # 添加3个用户 (integer) 1 127.0.0.1:6379&gt; zadd salary 5000 zhangsan (integer) 1 127.0.0.1:6379&gt; zadd salary 500 xhc (integer) 1 127.0.0.1:6379&gt; zrangebyscore salary -inf +inf # 显示全部的用户 从小到大排序 1) \"xhc\" 2) \"xiaohong\" 3) \"zhangsan\" 127.0.0.1:6379&gt; zrevrange salary 0 -1 # 显示全部的用户 从打倒小排序 1) \"zhangsan\" 2) \"xhc\" 127.0.0.1:6379&gt; zrangebyscore salary -inf +inf withscores # 显示全部的用户，并且附带score 1) \"xhc\" 2) \"500\" 3) \"xiaohong\" 4) \"2500\" 5) \"zhangsan\" 6) \"5000\" 127.0.0.1:6379&gt; zrangebyscore salary -inf 2500 withscores # 显示工资小于2500员工的升序排序 1) \"xhc\" 2) \"500\" 3) \"xiaohong\" 4) \"2500\" ################################################################################################################# # zrem 移除Zset中的元素 127.0.0.1:6379&gt; zrange salary 0 -1 1) \"xhc\" 2) \"xiaohong\" 3) \"zhangsan\" 127.0.0.1:6379&gt; zrem salary xiaohong # 移除有序集合中的指定元素 (integer) 1 127.0.0.1:6379&gt; zrange salary 0 -1 1) \"xhc\" 2) \"zhangsan\" 127.0.0.1:6379&gt; 127.0.0.1:6379&gt; zcard salary # 获取有序集合中的个数 (integer) 2 ################################################################################################################# 127.0.0.1:6379&gt; zadd myset 1 hello (integer) 1 127.0.0.1:6379&gt; zadd myset 2 world 3 xhc (integer) 2 127.0.0.1:6379&gt; zcount myset 1 3 # 获取score在指定区间的成员数量 (integer) 3 127.0.0.1:6379&gt; zcount myset 1 2 (integer) 2 其余的一些API ，通过我们的学习，剩下的如果工作中有需要，这个时候可以去查查看官方文档! 案例思路: set排序存储班级成绩表,工资表排序! 普通消息 1，重要消息 2 ,带权重进行判断! 排行榜应用实现 三种特殊数据类型Geospatial 地理位置日常生活中的，朋友圈的定位、附近的人、打车距离的计算。是如何实现的呢？ 可以通过Redis的Geospatial 数据类型实现。Redis的Geo在Redis3.2版本就推出了!这个功能可以推算地理位置的信息，两地之间的距离、方圆几里的人! geoadd 添加地理位置 # geoadd 添加地理位置 # 规则: 两级无法直接添加，我们一-般会下载城市数据，直接通过java程序一次性导入! # 有效的经度从-180度到180度。 # 有效的纬度从-85.05112878度到85.05112878度。 # 当坐标位置超出上述指定范围时，该命令将会返回一个错误。 # 127.0.0.1:6379&gt; geoadd china:city 39.40 116.40 beijing (error) ERR invalid longitude,latitude pair 39.400000,116.400000 # 将指定的地理空间位置（纬度、经度、名称）添加到指定的key中。这些数据将会存储到sorted set # 参数 key 值（纬度、经度、名称） 127.0.0.1:6379&gt; geoadd china:city 116.40 39.90 beijing (integer) 1 127.0.0.1:6379&gt; geoadd china:city 121.47 31.23 shanghai (integer) 1 127.0.0.1:6379&gt; geoadd china:city 106.50 29.53 chongqin 114.05 22.52 shengzhen (integer) 2 (1.78s) 127.0.0.1:6379&gt; geoadd china:city 120.16 30.24 hangzhou 108.96 34.26 xian (integer) 2 geopos 从key里返回所有给定位置元素的位置（经度和纬度） # 获取指定的城市的经度和纬度! # 获得当前定位: 一定是一个坐标值! 127.0.0.1:6379&gt; geopos china:city beijing 1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\" 127.0.0.1:6379&gt; geopos china:city beijing chongqin 1) 1) \"116.39999896287918091\" 2) \"39.90000009167092543\" 2) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\" geodist 返回两个给定位置之间的距离 应用场景：微信中两个人的距离 单位： m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 127.0.0.1:6379&gt; geodist china:city beijing shanghai km \"1067.3788\" 127.0.0.1:6379&gt; geodist china:city beijing chongqin km \"1464.0708\" georadius 以给定的经纬度为中心，找出某一半径内的元素 应用场景：我附近的人 ( 获得所有附近的人的地址,定位! ) 通过半径来查询 ! 获得指定数量的人,，200 所有数据应该都录入: china:city ，才会让结果更加正确! 127.0.0.1:6379&gt; georadius china:city 110 30 1000 km # 以110,30 这个经纬度为中心，寻找方圆1000km内的城市 1) \"chongqin\" 2) \"xian\" 3) \"shengzhen\" 4) \"hangzhou\" 127.0.0.1:6379&gt; georadius china:city 110 30 500 km 1) \"chongqin\" 2) \"xian\" 127.0.0.1:6379&gt; georadius china:city 110 30 500 km withdist # 显示到中心的距离 1) 1) \"chongqin\" 2) \"341.9374\" 2) 1) \"xian\" 2) \"483.8340\" 127.0.0.1:6379&gt; georadius china:city 110 30 500 km withcoord # 显示他人的定位信息 1) 1) \"chongqin\" 2) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\" 2) 1) \"xian\" 2) 1) \"108.96000176668167114\" 2) \"34.25999964418929977\" 127.0.0.1:6379&gt; georadius china:city 110 30 500 km withdist withcoord count 1 # 指定显示的数量 1) 1) \"chongqin\" 2) \"341.9374\" 3) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\" 127.0.0.1:6379&gt; georadius china:city 110 30 500 km withdist withcoord count 2 1) 1) \"chongqin\" 2) \"341.9374\" 3) 1) \"106.49999767541885376\" 2) \"29.52999957900659211\" 2) 1) \"xian\" 2) \"483.8340\" 3) 1) \"108.96000176668167114\" 2) \"34.25999964418929977\" georadiusbymember 找出位于指定范围内的元素，中心点是由给定的位置元素决定的 # 找出位于指定元素周围的其他元素 127.0.0.1:6379&gt; georadiusbymember china:city beijing 1000 km 1) \"beijing\" 2) \"xian\" 127.0.0.1:6379&gt; georadiusbymember china:city shanghai 400 km 1) \"hangzhou\" 2) \"shanghai\" 127.0.0.1:6379&gt; geohash 返回一个或多个位置元素的geohash表示 该命令将返回11个字符的geohash字符串 127.0.0.1:6379&gt; geohash china:city beijing chongqin 1) \"wx4fbxxfke0\" 2) \"wm5xzrybty0\" geo 底层的实现原理其实就是Zset！我们可以使用Zset命令来操作geo 127.0.0.1:6379&gt; zrange china:city 0 -1 1) \"chongqin\" 2) \"xian\" 3) \"shengzhen\" 4) \"hangzhou\" 5) \"shanghai\" 6) \"beijing\" 127.0.0.1:6379&gt; zrem china:city beijing (integer) 1 127.0.0.1:6379&gt; zrange china:city 0 -1 1) \"chongqin\" 2) \"xian\" 3) \"shengzhen\" 4) \"hangzhou\" 5) \"shanghai\" Hyperloglog 基数是什么 A{1,3,5,7,8,7} B{1,3,5,7,8} 基数(不重复的元素) =5, 可以接受误差! 简介 Redis 2.8.9版本就更新了Hyperloglog 数据结构! Redis Hyperloglog基数统计的算法! 优点:占用的内存是固定，2^64不同的元素的基数,只需要废12KB内存!如果要从内存角度来比较的话Hyperloglog 首选! 网页的 UV 网站访问量 (一个人访问一个网站多次,但是还是算作一个人! ) 传统的方式，set 保存用户的id ，然后就可以统计set中的元素数量作为标准判断! 这个方式如果保存大量的用户id ，就会比较麻烦 ! 浪费内存。我们的目的是为了计数，而不是保存用户id ; 0.81%错误率!统计UV任务,可以忽略不计的! 测试使用 127.0.0.1:6379&gt; pfadd mykey a b c d e f g h i j # 创建第一组数据 mykey (integer) 1 127.0.0.1:6379&gt; pfcount mykey # 统计mykey 元素的基数数量 (integer) 10 127.0.0.1:6379&gt; pfadd mykey2 i j z x c v b n m # 创建第一组数据 mykey2 (integer) 1 127.0.0.1:6379&gt; pfcount mykey2 (integer) 9 127.0.0.1:6379&gt; pfmerge mykey3 mykey mykey2 # 合并mykey mykey2 -&gt; mykey3 并集 OK 127.0.0.1:6379&gt; pfcount mykey3 # 查看mykey3的基数数量 (integer) 15 如果允许容错，那么一定可以使用Hyperloglog ! 如果不允许容错，就使用set或者自己的数据类型即可! Bitmaps 位存储 统计用户信息。活跃、不活跃 ! 登录、末登录 ! 两个状态的,都可以使用Bitmaps ! Bitmaps位图，数据结构！操作二进制位来进行记录，就只有0和1两个状态！ 记录365天的打卡信息 需要 365 bit 。1字节= 8bit 46 个字节左右! 测试 使用bitmap来记录周一到周日的打卡! 周一(0) : 1 周二(1) : 0 周三(2) : 0 周四(3) : 1 ……… 127.0.0.1:6379&gt; setbit sign 0 1 (integer) 0 127.0.0.1:6379&gt; setbit sign 1 0 (integer) 0 127.0.0.1:6379&gt; setbit sign 2 0 (integer) 0 127.0.0.1:6379&gt; setbit sign 3 1 (integer) 0 127.0.0.1:6379&gt; setbit sign 4 1 (integer) 0 127.0.0.1:6379&gt; setbit sign 5 0 (integer) 0 127.0.0.1:6379&gt; setbit sign 6 0 (integer) 0 127.0.0.1:6379&gt; 查看某一天是否有打卡 127.0.0.1:6379&gt; getbit sign 3 (integer) 1 127.0.0.1:6379&gt; getbit sign 6 (integer) 0 统计操作，统计打卡的天数 127.0.0.1:6379&gt; bitcount sign (integer) 3 事务Redis事务本质:一组命令的集合!一个事务中的所有命令都会被序列化，在事务执行过程的中，会按照顺序执行! 一次性、 顺序性、排他性 ! 执行一系列的命令 ! ——————— 队列 set命令 set命令 set命令 执行————————— Redis事务没有没有隔离级别的概念 ! 所有的命令在事务中,并没有直接被执行!只有发起执行命令的时候才会执行! Exec Redis单条命令式保存原子性的,但是事务不保证原子性! redis的事务： 开启事务（multi） 命令入队（……其他命令） 执行事务（exec） 正常执行事务 127.0.0.1:6379&gt; multi # 开启事务 OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; get k2 QUEUED 127.0.0.1:6379(TX)&gt; set k3 v3 QUEUED 127.0.0.1:6379(TX)&gt; exec # 执行事务 1) OK 2) OK 3) \"v2\" 4) OK 取消事务 127.0.0.1:6379&gt; multi # 开启事务 OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; set k4 v4 QUEUED 127.0.0.1:6379(TX)&gt; discard # 取消事务 OK 127.0.0.1:6379&gt; get k4 # 事务队列中的命令都不会被执行 (nil) 编译型异常（代码有问题！命令有错误！），事务中所有的命令都不会被执行！ 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; set k1 v1 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; set k3 v3 QUEUED 127.0.0.1:6379(TX)&gt; getset k3 # 错误的命令 (error) ERR wrong number of arguments for 'getset' command 127.0.0.1:6379(TX)&gt; set k4 v4 QUEUED 127.0.0.1:6379(TX)&gt; set k5 v5 QUEUED 127.0.0.1:6379(TX)&gt; exec # 执行事务报错 (error) EXECABORT Transaction discarded because of previous errors. 127.0.0.1:6379&gt; get k5 # 所有的命令都不会被执行 (nil) 运行时报错（1/0），如果事务队列中存在语法性错误 , 那么执行命令的时候 , 其他命令是可以正常执行的 , 错误命令抛出异常 ! 127.0.0.1:6379&gt; set k1 \"v1\" OK 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; incr k1 # 执行的时候会失败 QUEUED 127.0.0.1:6379(TX)&gt; set k2 v2 QUEUED 127.0.0.1:6379(TX)&gt; set k3 v3 QUEUED 127.0.0.1:6379(TX)&gt; get k3 QUEUED 127.0.0.1:6379(TX)&gt; exec 1) (error) ERR value is not an integer or out of range # 虽然第一条命令报错了，但是依旧正常执行成功了 2) OK 3) OK 4) \"v3\" 127.0.0.1:6379&gt; get k2 \"v2\" 127.0.0.1:6379&gt; get k3 \"v3\" 监控！Watch 悲观锁： 很悲观，认为什么时候都会出问题，无论做什么都会加锁！ 乐观锁： 很乐观，认为什么时候都不会出问题，所以不会上锁!更新数据的时候去判断一下，在此期间是否有人修改过这个数据。 获取version 更新的时候比较version Redis 监控测试 正常执行成功： 127.0.0.1:6379&gt; set money 100 OK 127.0.0.1:6379&gt; set out 0 OK 127.0.0.1:6379&gt; watch money # 监控 money 对象，获取 money 的值 OK 127.0.0.1:6379&gt; multi # 事务正常结束，执行期间数据没有发生变动。这个时候就正常执行成功 OK 127.0.0.1:6379(TX)&gt; decrby money 20 QUEUED 127.0.0.1:6379(TX)&gt; incrby out 20 QUEUED 127.0.0.1:6379(TX)&gt; exec 1) (integer) 80 2) (integer) 20 测试多线程修改值。使用watch可以当做redis的乐观锁操作！ 127.0.0.1:6379&gt; watch money # 监控 money OK 127.0.0.1:6379&gt; multi OK 127.0.0.1:6379(TX)&gt; decrby money 10 QUEUED 127.0.0.1:6379(TX)&gt; incrby out 10 QUEUED 127.0.0.1:6379(TX)&gt; exec # 在执行之前，另外一个线程。修改了money的值。这个时候，就会导致事务执行失败 (nil) 如果修改失败， 重新监控即可。在此之前要解除监控 小结 multi ：开启Redis的事务,置客户端为事务态。 exec ：提交事务，执行从multi到此命令前的命令队列，置客户端为非事务态。 discard ：取消事务，置客户端为非事务态。 watch：监视键值对，作用是如果事务提交exec时发现监视的对像发生变化,事务将被取消。 Jedis我们要使用Java来操作Redis ，知其然并知其所以然，授人以渔！学习不能急躁，慢慢来会很快！ 什么是Jedis，Jedis是Redis官方推荐的java连接开发工具 ! 是操作Redis的中间件!如果你要使用java操作redis ,那么一定要对Jedis十分的熟悉! 测试 导入依赖 &lt;!--导入jedis的包--&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--fastjson--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.62&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 编码测试 连接数据库 public class TestMain { public static void main(String[] args) { // 1、 new Jedis 对象即可。 192.168.252.128 是Linux主机地址 Jedis jedis = new Jedis(\"192.168.252.128\", 6379); // jedis 所有的方法就是我们之前学习的所有指令! 所以之前的指令学习很重要! System.out.println(jedis.ping()); } } 操作命令 断开连接 常用API 对key操作命令 public class TestKey { public static void main(String[] args) { Jedis jedis = new Jedis(\"192.168.252.128\", 6379); //对key操作命令 System.out.println(\"清空数据： \"+jedis.flushDB()); System.out.println(\"判断某个键是否存在： \"+jedis.exists(\"username\")); System.out.println(\"新增&lt;'username','xhc'&gt;的键值对： \"+jedis.set(\"username\",\"xhc\")); System.out.println(\"新增&lt;'password','password'&gt;的键值对： \"+jedis.set(\"password\",\"password\")); System.out.println(\"系统中所有的键如下： \"); Set&lt;String&gt; keys =jedis.keys(\"*\"); System.out.println(keys); System.out.println(\"删除键password：\"+jedis.del(\"password\")); System.out.println(\"判断键password是否存在：\"+jedis.exists(\"password\")); System.out.println(\"查看键username所存储的值的类型：\"+jedis.type(\"username\")); System.out.println(\"随机返回key空间的一个：\"+jedis.randomKey()); System.out.println(\"重命名key：\"+jedis.rename(\"username\",\"name\")); System.out.println(\"取出改后的name：\"+jedis.get(\"name\")); System.out.println(\"按索引查询：\"+jedis.select(0)); System.out.println(\"删除当前选择数据库中的所有key：\"+jedis.flushDB()); System.out.println(\"返回当前数据库中key的数目：\"+jedis.dbSize()); System.out.println(\"删除所有数据库中的所有key：\"+jedis.flushAll()); } } 其他的命令就不意义演示了，所有的api命令,就是我们对应的上面学习的指令,一个都没有变化 事务 public class TestTX { public static void main(String[] args) { Jedis jedis = new Jedis(\"192.168.252.128\", 6379); jedis.flushDB(); JSONObject jsonObject = new JSONObject(); jsonObject.put(\"hello\",\"world\"); jsonObject.put(\"name\",\"xhc\"); // 开启事务 Transaction multi = jedis.multi(); String result = jsonObject.toJSONString(); try { multi.set(\"user1\",result); multi.set(\"user2\",result); int i = 1/0; //代码抛出异常，事务执行失败 multi.exec(); // 执行事务 }catch (Exception e){ multi.discard(); //放弃事务 e.printStackTrace(); }finally { System.out.println(jedis.get(\"user1\")); System.out.println(jedis.get(\"user2\")); jedis.close(); //关闭连接 } } } 正常情况下： 出现异常： SpringBoot整合SpringBoot操作数据 : spring-data jpa jdbc mongodb redis ! SpringData也是和SpringBoot齐名的项目 ! SpringData是对操作数据的整合 说明:在SpringBoot2.x之后，原来使用的jedis被替换为了lettuce jedis : 采用的直连，多个线程操作的话，是不安全的，如果想要避免不安全的，使用jedis pool 连接池!更像BIO 模式 lettuce : 采用netty ，实例可以再多个线程中进行共享，不存在线程不安全的情况！可以减少线程数量了，更像NIO模式 源码： @Configuration(proxyBeanMethods = false) @ConditionalOnClass(RedisOperations.class) @EnableConfigurationProperties(RedisProperties.class) @Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class }) public class RedisAutoConfiguration { @Bean @ConditionalOnMissingBean(name = \"redisTemplate\") // 不存在这个bean才生效。也就是说我们可以自己定义一个redisTemplate来替换这个默认的! @ConditionalOnSingleCandidate(RedisConnectionFactory.class) public RedisTemplate&lt;Object, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { // 默认的RedisTemplate 没有过多的设置，redis 对象都是需要序列化! // 两个泛型都是object， object 的类型，我们后使用需要强制转换&lt;String， object&gt; RedisTemplate&lt;Object, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); return template; } @Bean @ConditionalOnMissingBean // 由于string是redis中最常使用的类型，所以说单独提出来了一个bean! @ConditionalOnSingleCandidate(RedisConnectionFactory.class) public StringRedisTemplate stringRedisTemplate(RedisConnectionFactory redisConnectionFactory) { StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(redisConnectionFactory); return template; } } 整合测试 导入依赖 &lt;dependencies&gt; &lt;!--操作redis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置连接 # SpringBoot所有的配置类，都有一个 XXXAutoConfiguration 自动配置类 RedisAutoConfiguration # 自动配置类都会绑定一个xxxProperties配置类,通过这个配置类来绑定配置文件 RedisProperties # 配置Redis spring.redis.host=192.168.252.128 spring.redis.port=6379 测试 @SpringBootTest class Redis02SpringbootApplicationTests { @Autowired @Qualifier(\"redisTemplate\") private RedisTemplate redisTemplate; @Test void contextLoads() { // redisTemplate 操作不同的数据类型，api和我们的指令是一样的 // opsForValue 操作字符串 类似String // opsForList 操作List 类似List // 除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务，和基本的CRUD // opsForSet 操作Set // opsForHash 操作hash // opsForZSet 操作Zset // opsForGeo 操作Geo // opsForHyperLogLog 操作HyperLogLog //除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务，和基本的CRUD //获取redis的连接对象 // RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); // connection.flushDb(); // connection.flushAll(); redisTemplate.opsForValue().set(\"mykey\",\"xhc\"); System.out.println(redisTemplate.opsForValue().get(\"mykey\")); } } 查看，redis数据库。数据库中的数据是转义字符 查看源码 创建实体类User @Component @AllArgsConstructor @NoArgsConstructor @Data public class User{ private String name; private int age; } 关于对象的保存 实体类实现序列化 public class User implements Serializable { private String name; private int age; } 再次测试 自定义RedisTemplete。这是一个固定的模板 @Configuration public class RedisConfig { // 编写我们自己的 redisTemplate @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { // 我们为了自己开发方便 一般直接使用 &lt;String, Object&gt; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(redisConnectionFactory); // json序列化配置 Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper objectMapper = new ObjectMapper(); objectMapper.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); objectMapper.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(objectMapper); // String 的序列化 StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用Jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用Jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } 使用自定义的RedisTemplete，进行测试。可以发现没有再出现转义字符了 Redis.conf 配置文件详解启动Redis的时候，就通过配置文件来启动！在工作中，一些小小的配置，可以让你脱颖而出！ 单位 Redis 不区分大小写 可以使用 include 组合多个配置文件 网络配置 通用配置 快照 持久化，在规定的时间内，执行了多少次操作，则会持久化到 rdb文件 或者 aof文件 Redis 是内存数据库，如果没有持久化，那么数据断电即失！ 主从复制 REPLICATION ，在主从复制再进行解释 安全 SECURITY 可以在这里设置的redis密码，默认是没有密码的 127.0.0.1:6379&gt;ping PONG 127.0.0.1:6379&gt; config get requirepass #获取 redis的密码 1)\"requirepass\" 2)\"\" 127.0.0.1:6379&gt; config set requirepass \"123456\" #设置 redis的密码OK 127.0.0.1:6379&gt; config get requirepass #发现所有的命令都没有权限了 (error) NoAUTH Authentication required 127.0.0.1:6379&gt;ping （error） NOAUTH Authentication required 127.0.0.1:6379&gt;auth 123456 #使用密码进行登录！ OK 127.0.0.1:6379&gt; config get requirepass 1)\"requirepass\" 2)\"123456\" 客户端 CLIENTS 内存管理 MEMORY MANAGEMENT APPEND ONLY 模式 aof配置 具体的配置，我们在Redis持久化中给大家详细的详解！ Redis 持久化Redis是内存数据库，如果不将内存中的数据库状态保存到磁盘，那么一旦Redis服务器进程退出，服务器中的数据库状态也会消失。所以Redis提供了持久化功能！ RDB(Redis DataBase) 什么是RDB 在主从复制中，rdb是备用在从机上面！ 在指定的时间间隔内将内存中的数据集快照写入磁盘，也就是行话里讲的 snashot 快照，恢复时是将快照文件直接读到内存中。 Redis会单独创建(fork)一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。整个过程中，主进程是不进行任何 I/O 操作的。这就确保了极髙的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。我们默认的就是RDB，一般情况下不需要修改这个配置。 有时候在生产环境我们会将这个文件进行备份！ rdb保存的文件是 dump.rdb 测试 修改配置文件，关于rdb的操作都可以在这里配置 向Redis中插入5个键值对 查看是否生成dump.rdb文件 退出Redis再查看，数据是否存在 触发规则 save的规则满足的情况下，会自动触发rdb 执行 flushall命令，也会触发我们的rdb 退出redis，也会产生rdb文件 备份自动生成一个dump.rdb文件 如何恢复rdb文件 只需要将rdb文件放在我们redis 启动目录中就可以，redis启动的时候会自动检查dump.rdb文件，恢复其中的数据！ 查看Redis启动目录的位置 到这里可以知道，Redis默认的配置已经够用了，但是我们还是需要去学习！ 优点： 适合大规模的数据恢复 对数据的完整性要求不高 缺点： 需要一定的时间间隔的进程操作！如果redis意外宕机了，这个最后一次修改数据就没有了 fork进程的时候，会占用一定的内存空间！！ AOF(Append Only File)将我们的所有命令都记录下来，恢复的时候就把这个文件全部再执行一遍！ 是什么 以曰志的形式来记录每个写操作，将 Redis执行过的所有指令都记录下来（读操作不记录），只许追加文件但不可以改写文件， redis启动之初会读取该文件重新构建数据，换言之， redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作 AOF保存的是appendonly.aof文件 APPEND ONLY MODE 默认是不开启的，我们需要手动进行配置！我们只需要将 appendonly改为yes就开启了aof！ 重启Redis就可以生效了 向Redis中插入键值对，查看 appendonly.aof 文件 如果aof文件有错误，这时候redis是启动不起来的。 redis 给我们提供了一个工具 redis-check-aof --fix 用来修复aof文件 修复aof文件，其实就是丢弃，错误的内容 如果文件正常，重启就可以直接恢复了！ 重写规则 aof默认就是文件的无限追加，文件会越来越大！ 如果aof文件大于64mb，太大了！fork一个新的进程来将我们的文件进行重写 优点和缺点 appendonly no #默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分所有的情况下，rdb完全够用！ appendfi1ename \"appendonly.aof\" #持久化的文件的名字 # appendfsync always #每次修改都会sync。消耗性能 appendfsync everysec #每秒执行一次sync，可能会丢失这1s的数据！ # appendfsync no #不执行sync，这个时候操作系统自己同步数据，速度最快！ 优点： 每一次修改都同步，文件的完整性会更加好！ 每秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点： 相对于数据文件来说，aof远远大于rdb，修复的速度也比rdb慢 aof运行效率要比rdb慢，所以我们redis默认的配置就是rdb持久化 总结 RDB持久化方式能够在指定的时间间隔内对数据进行快照存储 AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以 Redis协议追加保存每次写的操作到文件末尾， Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大 只做缓存，如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化 同时开启两种持久化方式在这种情况下： 当 redis重启的时候会优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。 RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件，那要不要只使用AOF呢？作者建议不要，因为RDB更适合用于备份数据库（AOF在不断变化不好备份），快速重启，而且不会有AOF可能潜在的Bug，留着作为一个万一的手段。 性能建议 因为RDB文件只用作后备用途，建议只在Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。 如果 Enable aof，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了，代价一是带来了持续的IO，二是 AOF rewrite的最后将 rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。只要硬盘许可，应该尽量减少 AOF rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上，默认超过原大小100%大小重写可以改到适当的数值。 如果不 Enable aof，仅靠 Master-Slave Replication实现高可用性也可以，能省掉一大笔lO，也减少了 rewrite时带来的系统波动。代价是如果 Master/slave同时倒掉，会丟失十几分钟的数据，启动脚本也要比较两个 Master/ Slave中的RDB文件，载入较新的那个，微博就是这种架构。 Redis 发布订阅Redis发布订阅（pub/sub）是一种消息通信模式∶发送者（ρub）发送消息，订阅者（sub）接收消息。微信、微博、关注系统 Redis客户端可以订阅任意数量的频道。 订阅发布消息图： 第一个：消息发送者，第二个：频道，第三个：消息订阅者 下图展示了频道 channel1，以及订阅这个频道的三个客户端一— client2、cent5和 client1之间的关系 当有新消息通过 PUBLISH命令发送给频道 channe1时，这个消息就会被发送给订阅它的三个客户端 命令 测试 订阅端： 127.0.0.1:6379&gt; subscribe xhc # 订阅一个频道 xhc Reading messages... (press Ctrl-C to quit) 1) \"subscribe\" 2) \"xhc\" 3) (integer) 1 # 等待读取推送的消息 1) \"message\" # 消息 2) \"xhc\" # 频道名称 3) \"hello xhc\" # 消息内容 1) \"message\" 2) \"xhc\" 3) \"hello redis\" 发送端： 127.0.0.1:6379&gt; publish xhc \"hello xhc\" # 发布者发布消息到频道 (integer) 1 127.0.0.1:6379&gt; publish xhc \"hello redis\" (integer) 1 原理 Redis是使用C实现的，通过分析 Redis源码里的 pubsub.C文件，了解发布和订阅机制的底层实现，籍此加深对 Redis的理解。 Redis通过 PUBLISH、 SUBSCRIBE和 PSUBSCRIBE等命令实现发布和订阅功能。 通过 SUBSCRIBE命令订阅某频道后， redis-server里维护了个字典，字典的键就是一个个 频道（channel），而字典的值则是一个链表，链表中保存了所有订阅这个 channel的客户端。 SUBSCRIBE命令的关键，就是将客户端添加到给定 channel的订阅链表中。 通过 PUBLISH命令向订阅者发送消息， redis-server会使用给定的频道作为键，在它所维护的 channel字典中査找记录了订阅这个频道的所有客户端的链表，遍历这个链表，将消息发布给所有订阅者 Pub/Sub从字面上理解就是发布（ Publish）与订阅（ Subscribe），在 Redis中，你可以设定对某一个key值进行消息发布及消息订阅，当一个key值上进行了消息发布后，所有订阅它的客户端都会收到相应的消息。这一功能最明显的用法就是用作实时消息系统，比如普通的即时聊天，群聊等功能。 使用场景： 实时消息系统 实时聊天！（频道当做聊天室，将信息回显给所有人即可！） 订阅，关注系统都是可以的！ 稍微复杂的场景我们就会使用消息中间件 MQ Redis 主从复制概念主从复制，是指将一台 Redis服务器的数据，复制到其他的 Redis服务器。前者称为主节点(master/ leader) ，后者称为从节点(slave/ follower)；数据的复制是单向的，只能由主节点到从节点。 Master以写为主，Slave以读为主。 默认情况下，每台 Redis服务器都是主节点；且一个主节点可以有多个从节点（或没有从节点），但一个从节点只能有一个主节点。 主从复制的作用主要包括： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式 故障恢复：当主节点岀现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写 Redis数据时应用连接主节点，读 redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis服务器的并发量 高可用（集群）基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是 Redis高可用的基础。 一般来说，要将 Redis运用于工程项目中，只使用一台 Redis是万万不能的，原因如下 从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大； 从容量上，单个 Redis服务器内存容量有限，就算一台Redis服务器内存容量为256G，也不能将所有内存用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过20G 电商网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是”多读少写”。 对于这种场景，我们可以使如下这种架构 主从复制，读写分离！80%的情况下都是在进行读操作！减缓服务器的压力！架构中经常使用！ 环境配置只配置从库，不用配置主库！ 127.0.0.1:6379&gt; info replication #查看当前库的信息 # Replication role:master #角色 master connected_slaves:0 #没有从机 master_failover_state:no-failover master_replid:99879018a425c3c644f6792220c8147000b70c1a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 复制3个配置文件，然后修改对应的信息 端口号 pid名 log文件名 rdb文件名 修改完成之后，启动我们的3个redis服务器，通过进程信息查看！ 一主二从架构图： 默认情况下，每台 Redis服务器都是主节点。我们一般情况下只用配置从机就好了! 一主（6379）二从（6380,6381） # 6380从机配置 127.0.0.1:6380&gt; slaveof 127.0.0.1 6379 # slaveof host 6379 找谁当自己的老大即主机！ OK 127.0.0.1:6380&gt; info replication # Replication role:slave # 当前角色是从机 master_host:127.0.0.1 # 可以看到主机的信息 master_port:6379 master_link_status:up master_last_io_seconds_ago:7 master_sync_in_progress:0 slave_repl_offset:14 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:bc38dc1397b5fb55ca36055851a278d7b4a7b23a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:14 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:14 # 6381从机配置 127.0.0.1:6381&gt; slaveof 127.0.0.1 6379 # slaveof host 6379 找谁当自己的老大即主机！ OK 127.0.0.1:6381&gt; info replication # Replication role:slave # 当前角色是从机 master_host:127.0.0.1 # 可以看到主机的信息 master_port:6379 master_link_status:up master_last_io_seconds_ago:2 master_sync_in_progress:0 slave_repl_offset:252 slave_priority:100 slave_read_only:1 connected_slaves:0 master_failover_state:no-failover master_replid:bc38dc1397b5fb55ca36055851a278d7b4a7b23a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:252 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:239 repl_backlog_histlen:14 # 在主机中查看 127.0.0.1:6379&gt; info replication # Replication role:master connected_slaves:2 # 多了从机的配置 slave0:ip=127.0.0.1,port=6380,state=online,offset=280,lag=0 # 从机的信息 slave1:ip=127.0.0.1,port=6381,state=online,offset=280,lag=0 # 从机的信息 master_failover_state:no-failover master_replid:bc38dc1397b5fb55ca36055851a278d7b4a7b23a master_replid2:0000000000000000000000000000000000000000 master_repl_offset:280 second_repl_offset:-1 repl_backlog_active:1 repl_backlog_size:1048576 repl_backlog_first_byte_offset:1 repl_backlog_histlen:280 真实的从主配置应该在配置文件中配置，这样的话是永久的，我们这里使用的是命令，暂时的 细节 主机可以写，从机不能写只能读！主机中的所有信息和数据，都会自动被从机保存！ 主机写： 从机只能读取内容！ 当主机关闭了，从机依旧连接到主机的，可以进行读操作。但是没有写操作，这个时候，主机如果回来了，从机依旧可以直接获取到主机写的信息！ 如果是使用命令行，来配置的主从，这个时候如果从机重启了，从机就会变回主机！只要重新变为从机，立马就会从主机中获取值！ 复制原理 Slave启动成功连接到 master后会发送一个sync同步命令 Master接到命令，启动后台的存盘进程，同时收集所有用于修改数据集命令，在后台进程执行完毕之后， master将传送 整个数据文件到slave，并完成一次完全同步。 全量复制：slave服务在接收到数据库文件数据后，将其存盘并加载到内存中 增量复制：Master继续将所有新的收集到的修改命令依次传给save，完成同步 但是只要是重新连接 master，一次完全同步（全量复制）将被自动执行！我们的数据一定可以在从机中看到！ 层层链路 上一个M链接下一个S！ 这时候也可以完成我们的主从复制！80会把从79接收的修改命令，发给81，完成同步 如果没有老大了，这个时候能不能选择一个老大出来呢？手动！ 谋朝篡位 如果主机断开了连接，我们可以使用slaveof no one让自己变成主机！其他的节点就可以手动连接到最新的这个主节点（手动）！如果这个时候老大修复了，那就要重新配置了，此时它是没有从机的 哨兵模式（自动选举老大的模式） 概述 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费时费力，还会造成短时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 Redis从2.8开始正式提供了 Sentinel（哨兵）架构来解决这个问题 谋朝篡位的自动版，能够后台监控主机是否故暲，如果故障了根据投票数自动将从库转换为主库。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是—个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待 Redis服务器响应，从而监控运行的多个 Redis实例的状态。 这里的哨兵有两个作用 通过发送命令，让 Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到 master宕机，会自动将 slave切换成 master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机 然而一个哨兵进程对 Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。 假设主服务器宕机哨兵1先检测到这个结果，系统并不会马上进行failover【故障转移】过程，仅仅是哨兵1主观的认为主服务器不可用，这个现象成为主观下线，当别的哨兵也检测到主服务器不可用，并且数量达到一定值时，那么哨兵之间就会进行一次投票，投票的结果由一个哨兵发起，进行 failover 【故障转移】操作。切换成功后，就会通过发布订阅模式，让各个哨兵把自己监控的从服务器实现切换主机，这个过程称为客观下线 测试 我们目前的状态是一主二从！ 配置哨兵配置文件 sentinel.conf # sentinel monitor 主服务器的名称 host port 1 sentinel monitor myredis 127.0.0.1 6379 1 启动sentinel [root@xhc bin]# redis-sentinel myconfig/sentinel.conf 5366:X 14 Apr 2021 14:31:51.861 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo 5366:X 14 Apr 2021 14:31:51.861 # Redis version=6.2.1, bits=64, commit=00000000, modified=0, pid=5366, just started 5366:X 14 Apr 2021 14:31:51.861 # Configuration loaded 5366:X 14 Apr 2021 14:31:51.862 * Increased maximum number of open files to 10032 (it was originally set to 1024). 5366:X 14 Apr 2021 14:31:51.862 * monotonic clock: POSIX clock_gettime _._ _.-``__ ''-._ _.-`` `. `_. ''-._ Redis 6.2.1 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ ''-._ ( ' , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|'` _.-'| Port: 26379 | `-._ `._ / _.-' | PID: 5366 `-._ `-._ `-./ _.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | http://redis.io `-._ `-._`-.__.-'_.-' _.-' |`-._`-._ `-.__.-' _.-'_.-'| | `-._`-._ _.-'_.-' | `-._ `-._`-.__.-'_.-' _.-' `-._ `-.__.-' _.-' `-._ _.-' `-.__.-' 5366:X 14 Apr 2021 14:31:52.000 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. 5366:X 14 Apr 2021 14:31:52.001 # Sentinel ID is 67fe927aeb18b3f363a121c47758115f37ceef3e 5366:X 14 Apr 2021 14:31:52.001 # +monitor master myredis 127.0.0.1 6379 quorum 1 5366:X 14 Apr 2021 14:31:52.002 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 6379 5366:X 14 Apr 2021 14:31:52.029 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 6379 关闭主机，查看从机信息 等一会，查看sentinel日志 查看6381的信息 如果 Master节点断开了，这个时候就会从从机中随机选择一个服务器作为Master！（这里面有一个投票算法！）如果主机此时回来了，只能归并到新的主机下，当做从机，这就是哨兵模式的规则！ 优缺点 优点： 哨兵集群，基于主从复制模式，所有的主从配置优点，它全有 主从可以切换，故障可以转移，系统的可用性就会更好 哨兵模式就是主从模式的升级，手动到自动，更加健壮！ 缺点： Redis不好在线扩容的，集群容量一旦到达上限，在线扩容就十分麻烦 实现哨兵模式的配置其实是很麻烦的，里面有很多选择！ 哨兵模式的全部配置 # Example sentinel.conf # 哨兵sentinel实例运行的端口 默认26379 port 26379 # 哨兵sentinel的工作目录 dir /tmp # 哨兵sentinel监控的redis主节点的 ip port # master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符\".-_\"组成。 # quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了 # sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; sentinel monitor mymaster 127.0.0.1 6379 1 # 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码 # 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码 # sentinel auth-pass &lt;master-name&gt; &lt;password&gt; sentinel auth-pass mymaster MySUPER--secret-0123passw0rd # 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒 # sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt; sentinel down-after-milliseconds mymaster 30000 # 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步， 这个数字越小，完成failover所需的时间就越长， 但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。 可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。 # sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt; sentinel parallel-syncs mymaster 1 # 故障转移的超时时间 failover-timeout 可以用在以下这些方面： #1. 同一个sentinel对同一个master两次failover之间的间隔时间。 #2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。 #3.当想要取消一个正在进行的failover所需要的时间。 #4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了 # 默认三分钟 # sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt; sentinel failover-timeout mymaster 180000 # SCRIPTS EXECUTION #配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。 #对于脚本的运行结果有以下规则： #若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10 #若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。 #如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。 #一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 #通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本， #这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数， #一个是事件的类型， #一个是事件的描述。 #如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。 #通知脚本 # sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel notification-script mymaster /var/redis/notify.sh # 客户端重新配置主节点参数脚本 # 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。 # 以下参数将会在调用脚本时传给脚本: # &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt; # 目前&lt;state&gt;总是“failover”, # &lt;role&gt;是“leader”或者“observer”中的一个。 # 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的 # 这个脚本应该是通用的，能被多次调用，不是针对性的。 # sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt; sentinel client-reconfig-script mymaster /var/redis/reconfig.sh Redis 缓存穿透和雪崩（面试高频，工作常用） 服务的高可用问题 Redis缓存的使用，极大的提升了应用程序的性能和效率，特别是数据査询方面。但同时也带来了一些问题。其中，最要害的问题就是数据的一致性问题，从严格意义上讲，这个问题无解。如果对数据的一致性要求很高，那么就不能使用缓存。 另外的一些典型问题就是，缓存穿透、缓存雪崩和缓存击穿。目前，业界也都有比较流行的解决方案。 缓存穿透（查不到） 概念 缓存穿透的概念很简单，用户想要査询一个数据，发现 redis内存数据库没有，也就是缓存没有命中，于是冋持久层数据库査询。发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中（比如：秒杀场景！），于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就出现了缓存穿透。 解决方案 布隆过滤器 布隆过滤器是一种数据结构，对所有可能査询的参数以hash形式存储，客户端请求先在控制层先进行校验，不符合则丟弃，从而避免了对底层存储系统的查询压力 绶存空对象 当存储层不命中后，及时返回的空对象也将其缓存起来，同时会设置一个过期时间，之后再访问这个数据将会从缓存中获取，保护了后端数据源； 但是这种方法会存在两个问题 如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响 缓存击穿（查太多了） 概述 这里需要注意和缓存穿透的区别，缓存击穿，是指一个key非常热门，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。 当某个key在过期的瞬间，有大量的请求并发访问，这类数据一般是热点数据，由于缓存过期，会同时访问数据库来查询最新数据，并且回写缓存，会导使数据库瞬间压力过大 解决方案 设置热点数据永不过期 从缓存层面来看，没有设置过期时间，所以不会出现热点key过期后产生的问题。 加互斥锁 分布式锁：使用分布式锁，保证对于每个key同时只有—个线程去査询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。 缓存雪崩 概念 缓存雪崩，是指在某一个时间段，缓存集中过期失效。Redis宕机！ 产生雪崩的原因之一，比如，马上就要到双十二零点，很快就会迎来一波抢购，这波商品时间比较集中的放入了缓存，假设缓存—个小时。那么到了凌晨一点钟的时候，这批商品的缓存就都过期了。而对这批商品的访问査询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。 其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。 解决方案 redis高可用 这个思想的含义是，既然 redis有可能挂掉，那我多增设几台 redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。 限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"笔记/Redis","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://mjean.life/tags/Redis/"}]},{"title":"SpringCloud笔记：Seata-分布式事务处理","slug":"cloud12","date":"2021-04-07T02:28:04.000Z","updated":"2022-04-18T12:48:45.803Z","comments":true,"path":"posts/62090af6.html","link":"","permalink":"http://mjean.life/posts/62090af6.html","excerpt":"","text":"Seata分布式事务的问题 在分布式之前 是一台电脑上包含所有的东西 —— 所有的数据、程序所有的内容 …… 慢慢向分布式演变 从 1 对 1 （一个程序对应一个数据库） 到 1 对 N （分库，一个程序对应多个数据库） 再 N 对 N （分布式微服务，多个微服务对应多个数据库） 分布式之后举例： ​用户购买商品的业务逻辑。整个业务逻辑由3个微服务提供支持； 仓储服务：对给定的商品扣除仓储数量。 ​订单服务：根据采购需求创建订单。 ​账户服务：从用户账户中扣除余额。 架构图： 单体应用被拆分成微服务应用，原来的三个模块被拆分成三个独立的应用，分别使用三个独立的数据源，业务操作需要调用三个服务来完成。 此时每个服务内部的数据一致性由本地事务来保证，但是全局的数据一致性问题没法保证。 一次业务操作需要跨多个数据源或需要跨多个系统进行远程调用，就会产生分布式事务问题 Seata简介 Seate 处理分布式事务。 官网： http://seata.io/zh-cn/ Seata 是一款开源的分布式事务解决方案，致力于在微服务架构下提供高性能和简单易用的分布式事务服务。 微服务模块，连接多个数据库，多个数据源，而数据库之间的数据一致性需要被保证。 Seata术语： 一个 ID + 三个组件 Transaction ID XID ：全局唯一的事务ID Transaction Coordinator(TC) ：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚; Transaction Manager™ ：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议; Resource Manager(RM) ：控制分支事务，负责分支注册，状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚 分布式事务处理过程 TM向TC申请开启一个全局事务，全局事务创建成功并生成一个全局唯一的XID XID在微服务调用链路的上下文中传播 RM向TC注册分支事务，将其纳入XID对应全局事务的管辖 TM向TC发起针对XID的全局提交或回滚决议 TC调度XID下管辖的全部分支事务完成提交或回滚请求。 Seata-Server下载安装 下载地址 ： https://github.com/seata/seata/releases/download/v1.0.0/seata-server-1.0.0.zip 初始化操作 修改 conf/file.conf 文件： 主要修改自定义事务组名称 + 事务日志存储模式为db + 数据库连接信息 创建名和 file.conf 指定一致的数据库。 在新建的数据库里面创建数据表，db_store.sql文件在 conf 目录下（1.0.0有坑，没有sql文件，下载0.9.0的，使用它的sql文件即可） 修改 conf/registry.conf 文件内容： 先启动 nacos Server 服务，再启动seata Server 。 案例数据库环境搭建 这里我们会创建三个服务 —— 一个订单服务，一个库存服务，一个账户服务。 当用户下单时，会在订单服务中创建一个订单，然后通过远程调用库存服务来扣减下单商品的库存， 再通过远程调用账户服务来扣减用户账户里面的余额， 最后在订单服务中修改订单状态为已完成。 该操作跨越三个数据库，有两次远程调用，很明显会有分布式事务问题。 启动 Nacos 、Seata 创建业务数据库 seata_order: 存储订单的数据库 seata_storage:存储库存的数据库 seata_account: 存储账户信息的数据库 建表SQL ： CREATE DATABASE seata_order; CREATE DATABASE seata_storage; CREATE DATABASE seata_account; seata_order 库下建 t_order 表 CREATE TABLE t_order( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `count` INT(11) DEFAULT NULL COMMENT '数量', `money` DECIMAL(11,0) DEFAULT NULL COMMENT '金额', `status` INT(1) DEFAULT NULL COMMENT '订单状态：0：创建中; 1：已完结' ) ENGINE=INNODB AUTO_INCREMENT=7 DEFAULT CHARSET=utf8; SELECT * FROM t_order; seata_storage 库下建 t_storage 表 CREATE TABLE t_storage( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY, `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id', `total` INT(11) DEFAULT NULL COMMENT '总库存', `used` INT(11) DEFAULT NULL COMMENT '已用库存', `residue` INT(11) DEFAULT NULL COMMENT '剩余库存' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_storage.t_storage(`id`,`product_id`,`total`,`used`,`residue`) VALUES('1','1','100','0','100'); SELECT * FROM t_storage; seata_account 库下建 t_account 表 CREATE TABLE t_account( `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id', `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id', `total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度', `used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', `residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度' ) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8; INSERT INTO seata_account.t_account(`id`,`user_id`,`total`,`used`,`residue`) VALUES('1','1','1000','0','1000') SELECT * FROM t_account; 建立回滚日志表 找到 Seata中回滚日志建表 SQL 脚本 ：\\seata\\conf\\db_undo_log.sql 三个数据库都需要执行该脚本 CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `context` varchar(128) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 最终效果： 代码环境搭建 实现 下订单-&gt; 减库存 -&gt; 扣余额 -&gt; 改（订单）状态 需要注意的是，下面做了 seata 与 mybatis 的整合，所以注意一下，和以往的mybatis的使用不太一样。 订单模块新建模块 seata-order-service2001 ： pom依赖： &lt;dependencies&gt; &lt;!-- seata --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!-- springcloud alibaba nacos 依赖,Nacos Server 服务注册中心 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- open feign 服务调用 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 持久层支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql-connector-java--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml配置： server: port: 2001 spring: application: name: seata-order-service cloud: alibaba: seata: #自定义事务组名称需要与seata-server中的对应 tx-service-group: xhc_group nacos: discovery: server-addr: localhost:8848 datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/seata_order username: root password: 123456 # 注意，这是自定义的，原来的是mapper_locations mybatis: mapperLocations: classpath:mapper/*.xml logging: level: io: seata: info 在resource目录下新建 file.conf文件： service { #transaction service group mapping vgroup_mapping.xhc_group = \"default\" #only support when registry.type=file, please don't set multiple addresses default.grouplist = \"127.0.0.1:8091\" #disable seata disableGlobalTransaction = false } ## transaction log store, only used in seata-server store { ## store mode: file、db mode = \"db\" ## file store property file { ## store location dir dir = \"sessionStore\" } ## database store property db { ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc. datasource = \"dbcp\" ## mysql/oracle/h2/oceanbase etc. db-type = \"mysql\" driver-class-name = \"com.mysql.jdbc.Driver\" url = \"jdbc:mysql://127.0.0.1:3306/seata\" user = \"root\" password = \"123456\" } } 在resource目录下新建 registry.conf文件： registry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \"nacos\" nacos { serverAddr = \"localhost:8848\" namespace = \"\" cluster = \"default\" } eureka { serviceUrl = \"http://localhost:8761/eureka\" application = \"default\" weight = \"1\" } redis { serverAddr = \"localhost:6379\" db = \"0\" } zk { cluster = \"default\" serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } consul { cluster = \"default\" serverAddr = \"127.0.0.1:8500\" } etcd3 { cluster = \"default\" serverAddr = \"http://localhost:2379\" } sofa { serverAddr = \"127.0.0.1:9603\" application = \"default\" region = \"DEFAULT_ZONE\" datacenter = \"DefaultDataCenter\" cluster = \"default\" group = \"SEATA_GROUP\" addressWaitTime = \"3000\" } file { name = \"file.conf\" } } config { # file、nacos 、apollo、zk、consul、etcd3 type = \"file\" nacos { serverAddr = \"localhost\" namespace = \"\" } consul { serverAddr = \"127.0.0.1:8500\" } apollo { app.id = \"seata-server\" apollo.meta = \"http://192.168.1.204:8801\" } zk { serverAddr = \"127.0.0.1:2181\" session.timeout = 6000 connect.timeout = 2000 } etcd3 { serverAddr = \"http://localhost:2379\" } file { name = \"file.conf\" } } 创建 domain 实体类 ： Order 和 CommonResult 两个实体类 CommonResult @Data @NoArgsConstructor @AllArgsConstructor public class CommonResult &lt;T&gt;{ private Integer code; private String message; private T data; public CommonResult(Integer code,String message){ this(code,message,null); } } Order @Data @AllArgsConstructor @NoArgsConstructor public class Order { private Long id; private Long userId; private Long productId; private Integer count; private BigDecimal money; //订单状态，0：创建中；1:已完结 private Integer status; } dao层 : OrderDao @Mapper public interface OrderDao { //1 新建订单 void create(Order order); //2 修改订单状态 从0改为1 void update(@Param(\"userId\")Long userId,@Param(\"status\")Integer status); } OrderMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.xhc.springcloud.alibaba.dao.OrderDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.xhc.springcloud.alibaba.domain.Order\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"count\" property=\"count\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"money\" property=\"money\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"status\" property=\"status\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;insert id=\"create\"&gt; insert into t_order(id,user_id,product_id,count,money,status) values(null,#{userId},#{productId},#{count},#{money},0); &lt;/insert&gt; &lt;update id=\"update\"&gt; update t_order set status = 1 where user_id=#{userId} and status = #{status}; &lt;/update&gt; &lt;/mapper&gt; Service接口及实现类： OrderService public interface OrderService { void create(Order order); void update(Long userId, Integer status); } StorageService @FeignClient(value = \"seata-storage-service\") public interface StorageService { @PostMapping(value = \"/storage/decrease\") CommonResult decrease(@RequestParam(\"productId\")Long productId,@RequestParam(\"count\")Integer count); } AccountService @FeignClient(value = \"seata-account-service\") public interface AccountService { @PostMapping(value = \"/account/decrease\") CommonResult decrease(@RequestParam(\"userId\")Long userId, @RequestParam(\"money\") BigDecimal money); } OrderServiceImpl @Service @Slf4j public class OrderServiceImpl implements OrderService { @Resource private OrderDao orderDao; @Resource private StorageService storageService; @Resource private AccountService accountService; @Override @GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) public void create(Order order) { log.info(\"------&gt;开始创建订单\"); // 1 新建订单 orderDao.create(order); log.info(\"-------&gt;订单微服务开始调用库存，做扣减count\"); // 2 扣减库存 storageService.decrease(order.getProductId(),order.getCount()); log.info(\"-------&gt;订单微服务开始调用库存，做扣减end\"); log.info(\"-------&gt;订单微服务开始调用账户，做扣减money\"); // 3 扣减账户 accountService.decrease(order.getUserId(),order.getMoney()); log.info(\"-------&gt;订单微服务开始调用账户，做扣减end\"); //4 修改订单的状态 从 0 到 1 ，1代表已经完成 log.info(\"------&gt;修改订单状态开始\"); orderDao.update(order.getUserId(),0); log.info(\"------&gt;修改订单状态结束\"); log.info(\"------&gt;下订单结束了\"); } @Override public void update(Long userId, Integer status) { } } 注意，红框标记的是通过 open-feign 远程调用微服务的service Controller:OrderController @RestController public class OrderController { @Resource private OrderService orderService; @GetMapping(\"/order/create\") public CommonResult create(Order order){ orderService.create(order); return new CommonResult(200,\"订单创建成功\"); } } 配置数据源，替换掉 SpringBoot 默认的，换上 Seata 的 config （特殊点）: //下面是两个配置类，这个是和mybatis整合需要的配置 @Configuration @MapperScan({\"com.xhc.springcloud.alibaba.dao\"}) public class MyBatisConfig { } //这个是配置使用 seata 管理数据源，所以必须配置 package com.xhc.springcloud.alibaba.config; import com.alibaba.druid.pool.DruidDataSource; import io.seata.rm.datasource.DataSourceProxy; import org.apache.ibatis.session.SqlSessionFactory; import org.mybatis.spring.SqlSessionFactoryBean; import org.mybatis.spring.transaction.SpringManagedTransactionFactory; import org.springframework.beans.factory.annotation.Value; import org.springframework.boot.context.properties.ConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.core.io.support.PathMatchingResourcePatternResolver; import javax.sql.DataSource; @Configuration public class DataSourceProxyConfig { @Value(\"${mybatis.mapperLocations}\") private String mapperLocations; @Bean @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource(){ return new DruidDataSource(); } @Bean public DataSourceProxy dataSourceProxy(DataSource dataSource){ return new DataSourceProxy(dataSource); } @Bean public SqlSessionFactory sqlSessionFactoryBean(DataSourceProxy dataSourceProxy)throws Exception{ SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean(); sqlSessionFactoryBean.setDataSource(dataSourceProxy); sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations)); sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory()); return sqlSessionFactoryBean.getObject(); } } 主启动类： //这里必须排除数据源自动配置，因为写了配置类，让 seata 管理数据源 @EnableDiscoveryClient @EnableFeignClients @SpringBootApplication(exclude = DataSourceAutoConfiguration.class)//取消数据源的自动创建 public class SeataOrderMainApp2001 { public static void main(String[] args) { SpringApplication.run(SeataOrderMainApp2001.class,args); } } 先启动 nacos –&gt;再启动 seata –&gt; 再启动此order服务，测试，可以启动。 仿照上面 创建 seata-storage-service2002 和 seata-account-service2003 两个模块，唯一大的区别就是这两个不需要导入 open-feign 远程调用其它模块。 库存模块pom依赖、yml文件及file.conf、registry.conf文件和2001的基本一致 创建 domain 实体类 ： Storage和 CommonResult 两个实体类 CommonResult 和2001模块的一样 Storage @Data @AllArgsConstructor @NoArgsConstructor public class Storage { private Long id; private Long productId; private Integer total; private Integer used; private Integer residue; } dao层 : StorageDao @Mapper public interface StorageDao { //扣减库存 void decrease(@Param(\"productId\") Long productId, @Param(\"count\") Integer count); } StorageMapper.xnl &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.xhc.springcloud.alibaba.dao.StorageDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.xhc.springcloud.alibaba.domain.Storage\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"INTEGER\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"INTEGER\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_storage SET used = used + #{count},residue = residue - #{count} WHERE product_id = #{productId} &lt;/update&gt; &lt;/mapper&gt; Service接口及实现类： StorageService public interface StorageService { void decrease(Long productId,Integer count); } StorageServiceImpl @Service public class StorageServiceImpl implements StorageService { private static final Logger LOGGER = LoggerFactory.getLogger(StorageServiceImpl.class); @Resource private StorageDao storageDao; @Override public void decrease(Long productId, Integer count) { LOGGER.info(\"---------&gt;storage-service中扣减库存开始\"); storageDao.decrease(productId,count); LOGGER.info(\"---------&gt;storage-service中扣减库存结束\"); } } Controller:StorageController @RestController public class StorageController { @Autowired private StorageService storageService; @RequestMapping(\"/storage/decrease\") public CommonResult decrease(@RequestParam(\"productId\") Long productId, @RequestParam(\"count\") Integer count){ storageService.decrease(productId, count); return new CommonResult(200, \"成功减扣库存---\"); } } 数据源配置改用Seata的，和2001模块一样 主启动类： @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataStorageServiceApplication2002 { public static void main(String[] args) { SpringApplication.run(SeataStorageServiceApplication2002.class,args); } } 启动测试，完毕！ 账户模块pom依赖、yml文件及file.conf、registry.conf文件和2001的基本一致 创建 domain 实体类 ： Account 和 CommonResult 两个实体类 CommonResult 和2001模块的一样 Account @Data @AllArgsConstructor @NoArgsConstructor public class Account { private Long id; private Long userId; private BigDecimal total; private BigDecimal used; private BigDecimal residue; } dao层 : AccountDao @Mapper public interface AccountDao{ void decrease(@Param(\"userId\")Long userId, @Param(\"money\")BigDecimal money); } AccountMapper.xnl &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.xhc.springcloud.alibaba.dao.AccountDao\"&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.xhc.springcloud.alibaba.domain.Account\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/&gt; &lt;result column=\"total\" property=\"total\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"used\" property=\"used\" jdbcType=\"DECIMAL\"/&gt; &lt;result column=\"residue\" property=\"residue\" jdbcType=\"DECIMAL\"/&gt; &lt;/resultMap&gt; &lt;update id=\"decrease\"&gt; UPDATE t_account SET residue = residue - #{money},used = used + #{money} WHERE user_id = #{userId}; &lt;/update&gt; &lt;/mapper&gt; Service接口及实现类： AccountService public interface AccountService { void decrease(@RequestParam(\"userId\")Long userId, @RequestParam(\"money\")BigDecimal money); } AccountServiceImpl @Service public class AccountServiceImpl implements AccountService { private static final Logger LOGGER = LoggerFactory.getLogger(AccountServiceImpl.class); @Resource AccountDao accountDao; @Override public void decrease(Long userId, BigDecimal money) { LOGGER.info(\"--------&gt;account-service中扣减账户余额开始\"); accountDao.decrease(userId,money); LOGGER.info(\"--------&gt;account-service中扣减账户余额结束\"); } } Controller:AccountController @RestController public class AccountController { @Resource AccountService accountService; @RequestMapping(\"/account/decrease\") public CommonResult decrease(@RequestParam(\"userId\")Long userId, @RequestParam(\"money\")BigDecimal money){ accountService.decrease(userId, money); return new CommonResult(200,\"扣减账户余额成功\"); } } 数据源配置改用Seata的，和2001模块一样 主启动类： @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableDiscoveryClient @EnableFeignClients public class SeataAccountMainApp2003 { public static void main(String[] args) { SpringApplication.run(SeataAccountMainApp2003.class,args); } } 启动测试，完毕！ 整合Seata测试 上面已经把环境都搭建完成了，下面就是整合 Seata 进行测试使用了 下面的测试都是针对 2001 模块的 成功执行的测试 访问：http://localhost:2001/order/create?userId=1&amp;productId=1&amp;count=10&amp;money=100 模拟异常 在AccountServiceImpl中加上如下代码 //模拟超时异常，全局事务回滚 //暂停几秒钟线程 try { TimeUnit.SECONDS.sleep(20); } catch (InterruptedException e) { e.printStackTrace(); } 重启2003项目 访问：http://localhost:2001/order/create?userId=1&amp;productId=1&amp;count=10&amp;money=100 查看订单表 再查看库存表跟账户表，表的数据都改变了 错误情况 当库存和账户余额扣减后，订单状态并没有设置为已经完成，没有从零改为1 而且由于 feign 的重试机制，账户余额还有可能被多次扣减，（Account 就出现了重复扣减的情况） 在 2001 中需要进行事务的方法上添加 @GlobalTransactional @GlobalTransactional(name = \"fps-create-order\", rollbackFor = Exception.class) @Override @GlobalTransactional(name = \"fsp-create-order\",rollbackFor = Exception.class) public void create(Order order) { log.info(\"------&gt;开始创建订单\"); // 1 新建订单 orderDao.create(order); log.info(\"-------&gt;订单微服务开始调用库存，做扣减count\"); // 2 扣减库存 storageService.decrease(order.getProductId(),order.getCount()); log.info(\"-------&gt;订单微服务开始调用库存，做扣减end\"); log.info(\"-------&gt;订单微服务开始调用账户，做扣减money\"); // 3 扣减账户 accountService.decrease(order.getUserId(),order.getMoney()); log.info(\"-------&gt;订单微服务开始调用账户，做扣减end\"); //4 修改订单的状态 从 0 到 1 ，1代表已经完成 log.info(\"------&gt;修改订单状态开始\"); orderDao.update(order.getUserId(),0); log.info(\"------&gt;修改订单状态结束\"); log.info(\"------&gt;下订单结束了\"); } ​ ​ 重启2003项目 ​ 访问：http://localhost:2001/order/create?userId=1&amp;productId=1&amp;count=10&amp;money=100 ​ 发生了和刚才一样的异常，查看数据库发现三个数据表的数据都没有改变 Seata原理TC/TM/RM三组件 分布式事务执行流程 TM开启分布式事务(TM向TC注册全局事务记录) ; 按业务场景，编排数据库、服务等事务内资源(RM向TC汇报资源准备状态) ; TM结束分布式事务,事务一阶段结束(TM通知TC提交/回滚分布式事务) ; TC汇总事务信息，决定分布式事务是提交还是回滚; TC通知所有RM提交/回滚资源,事务二阶段结束。 AT模式如何做到对业务的无侵入 一阶段加载 在一阶段, Seata会拦截“业务SQL\" 解析SQL语义，找到“业务SQL” 要更新的业务数据,在业务数据被更新前，将其保存成”before image”, 执行“业务SQL” 更新业务数据,在业务数据更新之后, 其保存成”after image” ，最后生成行锁。 以上操作全部在一个数据库事务内完成这样保证了一阶段操作的原子性。 二阶段提交 二阶段如是顺利提交的话, 因为“业务SQL”在-阶段已经提交至数据库,所以Seata框架只需将一阶段保存的快照数据和行锁删掉, 完成数据清理即可. 二阶段回滚 二阶段如果是回滚的话, ISeata就需要回滚一阶段已经执行的“业务SQL” ，还原业务数据。 回滚方式便是用”before image” 还原业务数据;但在还原前要首先要校验脏写,对比“数据库当前业务据”和”after image” ,如果两份数据完全一致就说明没有脏写,可以还原业务数据，如果不一 致就说明有脏写,出现脏写就需要转人工处理。 过程图","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：Sentinel-流量控制","slug":"cloud11","date":"2021-03-30T08:48:42.000Z","updated":"2022-04-18T12:48:45.811Z","comments":true,"path":"posts/53b3549e.html","link":"","permalink":"http://mjean.life/posts/53b3549e.html","excerpt":"","text":"Sentinel概述 官网 ：https://github.com/alibaba/Sentinel 中文文档 ：https://github.com/alibaba/Sentinel/wiki/%E4%BB%8B%E7%BB%8D 是一个轻量级的流量控制、熔断降级 Java 库 主要特性 Sentinel控制台 Sentinel 组件由 2 部分组成 核心库(Java客户端）不依赖任何框架/库，能够运行于所有Java运行时环境，同时对 Dubbo /Spring Cloud等框架也有较好的支持。 控制台(Dashboard)基于Spring Boot 开发，打包后可以直接运行，不需要额外的Tomcat等应用容器。 下载地址： https://github.com/alibaba/Sentinel/releases/download/1.7.1/sentinel-dashboard-1.7.1.jar 下载jar包以后，使用【java -jar】命令启动即可。(前提：确保有 Java 8 的环境，且 8080 端口没有被占用) 它使用 8080 端口，用户名和密码都为 ： sentinel 工程环境搭建 新建模块 cloudalibaba-sentinel-service8401 ，使用nacos作为服务注册中心，来测试Sentinel的功能。 pom依赖： &lt;dependencies&gt; &lt;!--springcloud alibaba nacos--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springcloud alibaba sentinel-datasource-nacos 后续做持久化用到--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springcloud alibaba sentinel--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--openfeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 配置： server: port: 8401 spring: application: name: cloudalibaba-sentinel-service cloud: nacos: discovery: server-addr: localhost:8848 #nacos服务注册中心地址 sentinel: transport: dashboard: localhost:8080 #配置sentinel dashboard地址 port: 8719 #默认8719端口，假如被占用会自动从8719开始依次+1扫描，直至找到未被占用的端口 management: endpoints: web: exposure: include: '*' 主启动类： @SpringBootApplication @EnableDiscoveryClient public class MainApp8401 { public static void main(String[] args) { SpringApplication.run(MainApp8401.class,args); } } Controller层： @RestController public class FlowLimitController { @GetMapping(\"/testA\") public String testA() { return \"------testA\"; } @GetMapping(\"/testB\") public String testB() { return \"------testB\"; } } 1.启动Nacos、Sentinel控制台 2.启动cloudalibaba-sentinel-service8401项目 3.查看Sentinel控制台 因为 Sentinel 采用的是懒加载 执行一下请求http://localhost:8401/testAhttp://localhost:8401/testB 再刷新 Sentinel 控制台 流控规则流控规则介绍 资源名: 唯一名称，默认请求路径 针对来源: Sentinel可以针对调用者进行限流，填写微服务名，默认default (不区分来源) 阈值类型/单机阈值 : QPS ：表示每秒钟的请求数量，当调用该 api 的 QPS 达到阈值的时候，进行限流。 线程数 : 当调用该 api 的线程数达到阈值的时候，进行限流 流控模式 直接 : api 达到限流条件时，直接限流 关联 : 当关联的资源达到阈值时，就限流自己 链路 : 只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流)【api级别的针对来源】 流控效果: 快速失败 : 直接失败，抛异常 Warm Up : 根据codeFactor(冷加载因子，默认3)的值，从阈值codeFactor，经过预热时长，才达到设置的QPS阈值 排队等待 : 匀速排队，让请求以匀速的速度通过，阈值类型必须设置为QPS，否则无效 流控模式演示流控模式–直接 api 达到限流条件时，直接限流 为 /testA 请求设置流控规则 查看流控规则 发出请求，体验限流 先是一秒点一次，可以正常访问 连续点几次，出现提示语句 流控模式–关联 当关联的资源达到阈值时，就限流自己 实际场景 ：对于同级别的服务，比如 下单、支付 两个服务，当 支付 流量过高，撑不住了，就限制一下 下单 服务，把资源留给 支付 服务，先撑过去。 修改上面建立的流控规则 使用 PostMan 发出请求，体验限流 访问 /testA 流控模式–链路 只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流)【api级别的针对来源】 修改上面建立的流控规则 使用 Postman 对 /testB 进行连续访问 访问 /testA 因为从 资源入口 进入的请求过多，所以 testA 被限流 流控效果演示流控效果–快速失败(默认的) 就是上面一直出现的提示界面 流控效果–预热(Warm Up) 官方说明 ：https://github.com/alibaba/Sentinel/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6 Warm Up（RuleConstant.CONTROL_BEHAVIOR_WARM_UP）方式，即预热/冷启动方式。当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过”冷启动”，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。详细文档可以参考 流量控制 - Warm Up 文档 冷加载因子 ：默认 coldFactor 为 3，即请求 QPS 从 threshold/3 开始，经预热时长逐渐升至设定的QPS阈值。 限流 冷启动 ：https://github.com/alibaba/Sentinel/wiki/%E9%99%90%E6%B5%81—%E5%86%B7%E5%90%AF%E5%8A%A8 修改流控效果 一直发出 /testA 请求 发现刚开始提示 Blocked by Sentinel(flow limiting) 的频率比较高 越往后频率越低 最后几乎不会出现 这就是阈值再慢慢预热的过程 流控效果–排队等待匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。 详细文档可以参考 流量控制 - 匀速器模式 该方式的作用如下图所示： 这种方式主要用于处理间隔性突发的流量，例如消息队列。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒 则处于空闲状态，我们希望系统 能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。 注意：匀速排队模式暂时不支持 QPS &gt; 1000 的场景 总而言之 让请求以匀速的速度通过，阈值类型必须设置为QPS，否则无效 每个请求，愿意等就等，不愿意等就超时重试 修改 流控效果 在 Controller 中添加一条语句打印日志，打印线程名 使用 Postman 模拟大量请求 观察控制台 熔断降级介绍 官方文档 ：https://github.com/alibaba/Sentinel/wiki/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7 熔断策略： 慢调用比例 (SLOW_REQUEST_RATIO)： 选择以慢调用比例作为阈值，需要设置允许的 慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。 当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。 经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态） 若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断。 异常比例 (ERROR_RATIO)： 当单位统计时长（statIntervalMs）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。 经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。 **异常数 (ERROR_COUNT)**： 当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（HALF-OPEN 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。 降级策略–慢调用比例（RT） 先在 Controller 中添加一个方法 @GetMapping(\"/testD\") public String testD(){ try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { e.printStackTrace(); } log.info(\"testD 测试RT\"); return \"----------testD\"; } 设置降级规则 使用 JMeter 进行压力测试 观察结果 启动JMeter，访问该请求 停止JMeter，访问该请求 降级策略–异常比例 修改 Controller ，添加一个运行时异常 修改 降级规则 启动 JMeter ，去浏览器上访问该请求，查看结果 停止 JMeter 后，再访问该请求 降级测录–异常数 修改 降级规则 连续发出请求，当刷新第六次的时候被熔断了 过一段时间后再次访问 说明： @SentinelResource：处理的是Sentinel控制台配置的违规情况，有blockHandler方法配置的兜底处理； RuntimeException：int age =10/0，这个是java运行时报出的运行时异常RuntimeException，@SentinelResource不管。 热点Key限流简介 官方文档 ：https://github.com/alibaba/Sentinel/wiki/热点参数限流 何为热点？ 热点即经常访问的数据。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制。比如： 商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制 用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制 热点参数限流会统计入传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，仅包含热点参数的资源调用生效。 备选方案 在 Hystrix 中某个方法被降级了、熔断了，都有一个备选方案兜底，这里也类似 每次服务出现问题页面都会提示 Blocked by Sentinel(flow limiting) ，能不能把它替换成我们自己的方案 可以，需要用到注解 —— @SentinelResource controller层写一个demo: @GetMapping(\"/testhotkey\") @SentinelResource(value = \"testhotkey\", blockHandler = \"deal_testhotkey\") //这个value是随意的值，并不和请求路径必须一致 //在填写热点限流的 资源名 这一项时，可以填 /testhotkey 或者是 @SentinelResource的value的值 public String testHotKey( @RequestParam(value=\"p1\", required = false) String p1, @RequestParam(value = \"p2\", required = false) String p2 ){ return \"testHotKey__success\"; } //类似Hystrix 的兜底方法 public String deal_testhotkey(String p1, String p2, BlockException e){ return \"testhotkey__fail\"; } 发出请求并带上 p1 参数 访问 ：http://localhost:8401/testHotKey?p1=a 如果 1 秒点一下，可以正常访问，但是 1 秒内，连续请求，就会走备选方案 参数例外项 上述情况，不论被监控的参数传入的是何值，都会进行判断，并限流 但是有些时候有些特殊值，希望它的阈值和其他不一样，就要使用该配置 比如说：p1 传入 5 时的阈值可以允许达到 200，但是其他值只能达到 1 修改 热 Key 配置 添加 参数例外项 先传入普通值测试 ：http://localhost:8401/testHotKey?p1=a 会发现访问一秒内访问两次或以上就报错 再传入特殊值测试 ：http://localhost:8401/testHotKey?p1=5 会发现一秒内怎么点都不会出错，这是因为我们的阈值设置了200 系统规则 一般配置在网关或者入口应用中，但是这个东西有点危险，不但值不合适，就相当于系统瘫痪。 官方文档 ：https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81 Sentinel系统自适应限流从整体维度对应用入口流量进行控制，结合应用的Load、CPU使用率、总体平均RT、入口QPS和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。 系统规则的配置说明： Load 自适应（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 maxQps * minRt 估算得出。设定参考值一般是 CPU cores * 2.5。 CPU usage（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。 平均 RT：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。 并发线程数：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。 入口 QPS：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。 @SentinelResource两种配置备选方案 @SentinelResource 注解在限流时，有两种配置备选方案的方式： 按资源名称限流 + 备选方案 按Url地址限流 + 备选方案 主要是指定资源名（也可以用请求路径作为资源名），和指定降级处理方法的。 例如： package com.xhc.springcloud.controller; import com.alibaba.csp.sentinel.annotation.SentinelResource; import com.alibaba.csp.sentinel.slots.block.BlockException; import com.dkf.springcloud.entities.CommonResult; import com.dkf.springcloud.entities.Payment; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class RateLimitController { @GetMapping(\"/byResource\") //value=“资源名称” //处理降级的方法名 @SentinelResource(value = \"byResource\", blockHandler = \"handleException\") public CommonResult byResource(){ return new CommonResult(200, \"按照资源名限流测试0K\", new Payment(2020L,\"serial001\")); } //降级方法 public CommonResult handleException(BlockException e){ return new CommonResult(444, e.getClass().getCanonicalName() + \"\\t 服务不可用\"); } } 测试后同时也会发现上面 两个配置备选方案的方式 的问题 系统默认的，没有体现我们自己的业务要求。 依照现有条件，我们自定义的处理方法又和业务代码耦合在一块，不直观。 每个业务方法都添加一个兜底的，那代码膨胀加剧。 全局统—的处理方法没有体现。 自定义全局BlockHandler处理类 修改 alibaba-sentinel-service-8401 自定义一个限流处理类 ：CustomerBlockHandler public class CustomerBlockHandler { public static CommonResult handlerException(BlockException exception){ return new CommonResult(4444,\"按客户自定义,global handlerException----1\"); } public static CommonResult handlerException2(BlockException exception){ return new CommonResult(4444,\"按客户自定义,global handlerException----2\"); } } 修改 Controller ：RateLimitController @GetMapping(\"/rateLimit/customerBlockHandler\") @SentinelResource(value = \"customerBlockHandler\", blockHandlerClass = CustomerBlockHandler.class, blockHandler = \"handlerException2\") public CommonResult customerBlockHandler(){ return new CommonResult(200,\"按客户自定义测试OK\",new Payment(2020L,\"serial003\")); } 重启 8401 访问 ：http://localhost:8401/rateLimit/customerBlockHandler 配置限流规则后再测试 @SentinelResource 注解属性说明 value：资源名称，必需项（不能为空） entryType：entry 类型，可选项（默认为 EntryType.OUT） blockHandler: 处理BlockException的函数名称。函数要求： ​ 1、必须是 public ​ 2、返回类型与原方法一致 ​ 3、参数类型需要和原方法相匹配，并在最后加 BlockException 类型的参数。 ​ 4、默认需和原方法在同一个类中。若希望使用其他类的函数，可配置 blockHandlerClass ，并指定blockHandlerClass里面的方法。 blockHandlerClass ：存放blockHandler的类。对应的处理函数必须static修饰，否则无法解析，其他要求：同blockHandler。 fallback ：fallback 函数名称，可选项，用于在抛出异常的时候提供 fallback 处理逻辑。fallback 函数可以针对所有类型的异常（除了 里面排除掉的异常类型）进行处理。fallback 函数签名和位置要求： ​ 1、返回值类型必须与原函数返回值类型一致； ​ 2、方法参数列表需要和原函数一致，或者可以额外多一个 Throwable 类型的参数用于接收对应的异常。 ​ 3、fallback 函数默认需要和原方法在同一个类中。若希望使用其他类的函数，则可以指定 fallbackClass 为对应的类的 Class 对象，注意对应的函数必 需为 static 函数，否则无法解析。 exceptionsToTrace ：需要trace的异常 服务熔断前言 之前有 open-feign 和 hystrix 的整合，现在来实现sentinel 整合 ribbon + open-feign + fallback 进行服务熔断。 新建三个模块，两个提供者 cloudalibaba-provider-payment9003/9004，和一个消费者 cloudalibaba-consumer-nacos-order84 目的： fallback管运行异常 blockHandler管配置异常 上面使用sentinel有一个很明显的问题，就是sentinel，对程序内部异常（各种异常，包括超时）这种捕捉，显得很乏力，它主要是针对流量控制，系统吞吐量，或者是异常比例这种，会发生降级或熔断，但是当程序内部发生异常，直接返回给用户错误页面，根本不会触发异常比例这种降级。所以才需要整合open-feign 来解决程序内部异常时，配置相应的兜底方法 两个提供者模块一致，如下： pom依赖： &lt;dependencies&gt; &lt;!-- springcloud alibaba nacos 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml配置： server: port: 9004 # /9003 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 management: endpoints: web: exposure: include: '*' 主启动类: @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9004 { public static void main(String[] args) { SpringApplication.run(PaymentMain9004.class,args); } } controller : @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; public static HashMap&lt;Long, Payment&gt; hashMap = new HashMap&lt;&gt;(); static{ hashMap.put(1L,new Payment(1L,\"sadawdasd545a1d3aw54das32d5aw\")); hashMap.put(2L,new Payment(2L,\"54dawdasd545a1d3aw54das32d5aw\")); hashMap.put(3L,new Payment(3L,\"d68735asd545a1d3aw54das32d5aw\")); } @GetMapping(value = \"/paymentSQL/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id){ Payment payment =hashMap.get(id); CommonResult&lt;Payment&gt; result = new CommonResult(200,\"from mysql,serverPort: \"+serverPort,payment); return result; } } 消费者： pom依赖： &lt;dependencies&gt; &lt;!-- 加入open-feign --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 后续做Sentinel的持久化会用到的依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- sentinel --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springcloud alibaba nacos 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml配置： server: port: 84 spring: cloud: nacos: discovery: server-addr: localhost:8848 sentinel: transport: dashboard: localhost:8080 port: 8719 application: name: nacos-order-consumer # 自定义的一个属性，提供者服务地址 service-url: nacos-user-service: http://nacos-payment-provider 主启动类: @SpringBootApplication @EnableDiscoveryClient public class OrderNacosMain84 { public static void main(String[] args) { SpringApplication.run(OrderNacosMain84.class,args); } } config类里面注入 RestTemplate： @Configuration public class ApplicationContextConfig { @Bean @LoadBalanced public RestTemplate getRestTemplate(){ return new RestTemplate(); } } controller 层： @RestController @Slf4j public class CircleBreakerController { public static final String SERVICE_URL = \"http://nacos-payment-provider\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/consumer/fallback/{id}\") public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id){ CommonResult&lt;Payment&gt; result = restTemplate.getForObject(SERVICE_URL+\"/paymentSQL/\"+id,CommonResult.class,id); if (id == 4){ throw new IllegalArgumentException(\"IllegalArgumentException,非法参数异常。。。\"); }else if (result.getData()==null){ throw new NullPointerException(\"NullPointerException,该ID没有对应记录，空指针异常\"); } return result; } } 上面只实现了 以nacos 作为服务注册中心，消费者使用ribbon 实现负载均衡调用提供者的效果。 熔断降级配置只配置 fallback: @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\",fallback = \"handlerFallback\")//fallback只负责业务异常 public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id){ CommonResult&lt;Payment&gt; result = restTemplate.getForObject(SERVICE_URL+\"/paymentSQL/\"+id,CommonResult.class,id); if (id == 4){ throw new IllegalArgumentException(\"IllegalArgumentException,非法参数异常。。。\"); }else if (result.getData()==null){ throw new NullPointerException(\"NullPointerException,该ID没有对应记录，空指针异常\"); } return result; } //兜底方法 //本例是fallback public CommonResult handlerFallback(@PathVariable Long id,Throwable e){ Payment payment = new Payment(id,\"null\"); return new CommonResult&lt;&gt;(444,\"兜底异常handlerFallback，exception内容 \"+e.getMessage(),payment); } 业务异常会被 fallback 处理，返回我们自定义的提示信息，而如果给它加上流控，并触发阈值，只能返回sentinel默认的提示信息。 只配置blockHandler: @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\",blockHandler = \"blockHandler\")//blockHandler只负责sentinel控制台配置异常 public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id){ CommonResult&lt;Payment&gt; result = restTemplate.getForObject(SERVICE_URL+\"/paymentSQL/\"+id,CommonResult.class,id); if (id == 4){ throw new IllegalArgumentException(\"IllegalArgumentException,非法参数异常。。。\"); }else if (result.getData()==null){ throw new NullPointerException(\"NullPointerException,该ID没有对应记录，空指针异常\"); } return result; } //本例是blockHandler public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment(id, \"null\"); return new CommonResult&lt;&gt;(445, \"blockHandler-sentinel限流，无此流水： blockException \" + blockException.getMessage(), payment); } 这时候的效果就是，运行异常直接报错错误页面。在sentinel上添加一个降级规则，设置2s内触发异常2次，触发阈值以后，返回的是我们自定义的 blockhanlder 方法返回的内容。 fallback和blockHandler两者都配置： @RequestMapping(\"/consumer/fallback/{id}\") @SentinelResource(value = \"fallback\",fallback = \"handlerFallback\",blockHandler = \"blockHandler\") public CommonResult&lt;Payment&gt; fallback(@PathVariable Long id){ CommonResult&lt;Payment&gt; result = restTemplate.getForObject(SERVICE_URL+\"/paymentSQL/\"+id,CommonResult.class,id); if (id == 4){ throw new IllegalArgumentException(\"IllegalArgumentException,非法参数异常。。。\"); }else if (result.getData()==null){ throw new NullPointerException(\"NullPointerException,该ID没有对应记录，空指针异常\"); } return result; } //本例是fallback public CommonResult handlerFallback(@PathVariable Long id,Throwable e){ Payment payment = new Payment(id,\"null\"); return new CommonResult&lt;&gt;(444,\"兜底异常handlerFallback，exception内容 \"+e.getMessage(),payment); } //本例是blockHandler public CommonResult blockHandler(@PathVariable Long id, BlockException blockException) { Payment payment = new Payment(id, \"null\"); return new CommonResult&lt;&gt;(445, \"blockHandler-sentinel限流，无此流水： blockException \" + blockException.getMessage(), payment); } 明显两者都是有效的，可以同时配置。 异常忽略 这是 @SentinelResource 注解的一个值： 全局降级(整合Feign) 上面是单个进行 fallback 和 blockhandler 的测试，下面是整合 openfeign 实现把降级方法解耦。和Hystrix 几乎一摸一样！ 还是使用上面 84 这个消费者做测试： 先添加open-feign依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; yml 追加如下配置： # 激活Sentinel对Feign的支持 feign: sentinel: enabled: true 主启动类添加注解 ： @EnableFeignClients 激活open-feign service : @FeignClient(value = \"nacos-payment-provider\",fallback = PaymentFallbackService.class) public interface PaymentService { @GetMapping(value = \"/paymentSQL/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\") Long id); } service 实现类： @Component public class PaymentFallbackService implements PaymentService{ @Override public CommonResult&lt;Payment&gt; paymentSQL(Long id) { return new CommonResult&lt;&gt;(44444,\"服务降级返回，-----PaymentFallbackService\",new Payment(id,\"errorSerial\")); } } controller 层： @Resource private PaymentService paymentService; @GetMapping(\"/consumer/paymentSQL/{id}\") public CommonResult&lt;Payment&gt; paymentSQL(@PathVariable(\"id\")Long id){ return paymentService.paymentSQL(id); } 测试，关闭提供者9003、9004，会触发 service 实现类的方法。 总结: 这种全局熔断，是针对 “访问提供者” 这个过程的，只有访问提供者过程中发生异常才会触发降级，也就是这些降级，是给service接口上这些提供者的方法加的，以保证在远程调用时能顺利进行。而且这明显是 fallback ，而不是 blockHandler，注意区分。 fallback 和 blockHandler 肤浅的区别： F ：不需要指定规则，程序内部异常均可触发（超时异常需要配置超时时间） B ：配上也没用，必须去 Sentinel 上指定规则才会被触发。 熔断降级框架对比 Sentinel Hystrix Resilience4j 隔离策略 信号量隔离（并发线程数限流） 线程池隔离/信号量隔离 信号量隔离 熔断降级策略 基于响应时间、异常比、异常数 基于异常比 基于异常比、响应时间 实时统计实现 滑动窗口（LeapArray） 滑动窗口（Rxjava） Ring Bit Buffer 动态规则配置 支持多种数据源 支持多种数据源 有限支持 扩展性 多个扩展点 插件形式扩展 接口形式扩展 限流 基于QPS、支持基于调用关系的限流 有限支持 Rate Limiter 流量整形 支持预热、匀加速、预热排队模式 不支持 简单的 Rate Limit 系统自适应保护 支持 不支持 不支持 控制台 提供开箱即用的控制台，可以配置规则、查看秒级监控、机器发现等 简单的监控查看 不提供控制台，可对接其他监控系统 基于注解的支持 支持 支持 支持 Sentinel规则持久化 一旦我们重启应用，Sentinel规则将消失 生产环境需要将配置规则进行持久化 将限流配置规则持久化进 Nacos 保存 只要刷新 8401 某个 rest 地址，sentinel 控制台的流控规则就能看到，只要 Nacos 里面的配置不删除，针对 8401 上 Sentinel 上的流控规则持续有效 具体操作步骤 修改 cloudalibaba-sentinel-service8401 pom依赖： &lt;dependency&gt; &lt;groupId&gt;com.alibaba.csp&lt;/groupId&gt; &lt;artifactId&gt;sentinel-datasource-nacos&lt;/artifactId&gt; &lt;/dependency&gt; yml配置： spring: cloud: sentinel: datasource: ds1: nacos: server-addr: localhost:8848 dataId: ${spring.application.name} group: DEFAULT_GROUP data-type: json rule-type: flow 去nacos上创建一个dataid ,名字和yml配置的一致 json格式，内容如下： [ { \"resource\": \"/rateLimit/byUrl\", \"limitApp\": \"default\", \"grade\": 1, \"count\": 1, \"strategy\": 0, \"controlBehavior\": 0, \"clusterMode\": false } ] resource:：资源名称 limitApp：来源应用 grade：阈值类型，0表示线程数，1表示QPS count：单机阈值 strategy：流控模式，0表示直接，1表示关联，2表示链路 controlBehavior：流控效果，0表示快速失败，1表示Warm Up，2表示排队等待 clusterMode：是否集群 启动应用，发现存在 关于 /rateLimit/byUrl 请求路径的流控规则。 总结: 就是在 sentinel 启动的时候，去 nacos 上读取相关规则配置信息，实际上它规则的持久化，就是第三、第四步，粘贴到nacos上保存下来，就算以后在 sentinel 上面修改了，重启应用以后也是无效的。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：Nacos-服务注册与配置中心","slug":"cloud10","date":"2021-03-25T04:56:10.000Z","updated":"2022-04-18T12:48:45.780Z","comments":true,"path":"posts/2c8aae46.html","link":"","permalink":"http://mjean.life/posts/2c8aae46.html","excerpt":"","text":"SpringCloud Alibaba GITHUB ：https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md 大简介 能做什么 服务限流降级:默认支持Servlet、Feign、RestTemplate、Dubbo和RocketMQ限流降级功能的接入，可以在运行时通过控制台 实时修改限流降级规则，还支持查看限流降级Metrics监控。 服务注册与发现:适配Spring Cloud服务注册与发现标准，默认集成了Ribbon的支持。 分布式配置管理:支持分布式系统中的外部化配置，配置更改时自动刷新。 消息驱动能力:基于Spring Cloud Stream为微服务应用构建消息驱动能力。 阿里云对象存储:阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。 分布式任务调度:提供秒级、精准、高可靠、高可用的定时(基于Cron表达式)任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有Worker (schedulerx-client)上执行。 相应的组件 Sentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Nacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。 RocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。 Dubbo：Apache Dubbo™ 是一款高性能 Java RPC 框架。 Seata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。 Alibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。 Alibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。 Alibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。 Alibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道 官网 官网 ：https://spring.io/projects/spring-cloud-alibaba#overview Github ：https://github.com/alibaba/spring-cloud-alibaba 中文网站 ：https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md Nacos简介 Github ：https://github.com/alibaba/Nacos 官网 ：https://nacos.io/zh-cn/index.html 官方文档 ：https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_nacos_discovery 是什么？ 一个更易于构建云原生应用的动态服务发现，配置管理和服务管理中心 Nacos就是注册中心+配置中心的组合 等价于 Netflix 中的 Eureka+Config+Bus 能干嘛？ 替代 Eureka 做服务注册中心 替代 Config 做服务配置中心 与其他注册中心的对比 下载安装并运行 下载地址： https://github.com/alibaba/nacos/releases/tag/1.1.4 直接下载网址： https://github.com/alibaba/nacos/releases/download/1.1.4/nacos-server-1.1.4.zip 解压安装包，直接运行bin目录下的startup.cmd 命令运行成功后直接访问 http://localhost:8848/nacos 用户名 、密码 都是 nacos 服务注册发现提供者新建模块 cloudalibaba-provider-payment9001 pom依赖： &lt;dependencies&gt; &lt;!-- springcloud alibaba nacos 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 配置： server: port: 9001 spring: application: name: nacos-payment-provider cloud: nacos: discovery: server-addr: localhost:8848 #配置nacos地址 management: endpoints: web: exposure: include: '*' 主启动类: @SpringBootApplication @EnableDiscoveryClient public class PaymentMain9001 { public static void main(String[] args) { SpringApplication.run(PaymentMain9001.class,args); } } controller层： @RestController public class PaymentController { @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/nacos/{id}\") public String getPayment(@PathVariable(\"id\")Integer id){ return \"nacos registry ,serverport :\"+serverPort+\"\\t id\"+id; } } 测试 启动 Nacos、alibaba-provider-payment-9001 查看 Nacos 界面 Nacos 自带负载均衡机制，下面创建第二个提供者。 在 alibaba-provider-payment-9001 的基础上再创建一个一模一样的项目 alibaba-provider-payment-9002 ，为了搭建一个简单的集群 如果不想创建新项目，可以使用以下方法 再查看 Nacos 的界面 消费者新建消费者 模块： cloudalibaba-customer-order80 pom文件： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml文件： server: port: 83 spring: application: name: nacos-order-consumer cloud: nacos: discovery: server-addr: localhost:8848 #消费者将要去访问的微服务名称（注册成功进nacos的微服务提供者） service-url: nacos-user-service: http://nacos-payment-provider nacos底层也是ribbon，注入ReatTemplate @Configuration public class ApplicationContextConfig { @Bean @LoadBalanced public RestTemplate getRestTemplate(){ return new RestTemplate(); } } controller : @RestController @Slf4j public class OrderNacosController { @Resource private RestTemplate restTemplate; //在yml里面写的提供者服务路径， 值为：nacos-payment-provider @Value(\"${service-url.nacos-user-service}\") private String serverURL; @GetMapping(\"/consumer/payment/nacos/{id}\") public String paymentInfo(@PathVariable(\"id\") Long id){ return restTemplate.getForObject(serverURL+\"/payment/nacos/\"+id,String.class); } } 测试 启动 Nacos 控制台启动 9001、9002、83 访问：http://localhost:83/consumer/payment/nacos/111 完成！ 各种注册中心进一步对比 前面只是简单对比了一下，下面会更深层的对比 Nacos全景图 Nacos 和 CAP Nacos支持AP和CP模式的切换 C是所有节点在同一时间看到的数据是一致的 A的定义是所有的请求都会收到响应。 一般来说，如果不需要存储服务级别的信息且服务实例是通过nacos-client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如 Sping cloud和Dubbo服务，都适用于AP模式，AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。 如果需要在服务级别编辑或者存储配置信息，那么CP是必须，K8S服务和DNS服务则适用于CP模式.CP模式下则支持注册持久化实例，此时则是以Raft协议为集群运行模式，该模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。 切换命令 ： curl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&amp;value=CP' 配置中心基础配置 nacos 还可以作为服务配置中心，下面是案例，创建一个模块，从nacos上读取配置信息。 nacos 作为配置中心，不需要像springcloud config 一样做一个Server端模块。 新建模块 cloudalibaba-nacos-config3377 pom依赖： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-nacos-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- springboot整合Web组件 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 日常通用jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类： @SpringBootApplication @EnableDiscoveryClient public class CloudAlibabaConfigMain3377 { public static void main(String[] args) { SpringApplication.run(CloudAlibabaConfigMain3377.class,args); } } bootstrap.yml 配置： server: port: 3377 spring: application: name: nacos-config-client cloud: nacos: discovery: server-addr: localhost:8848 # nacos作为服务注册中心 config: server-addr: localhost:8848 # nacos作为服务配置中心 file-extension: yaml # 指定yaml 格式的配置 controller 层进行读取配置测试： @RestController @RefreshScope //支持nacos的动态刷新功能 public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/config/info\") public String getConfigInfo(){ return configInfo; } } 下面在 Nacos 中添加配置文件，需要遵循如下规则： 官网地址：https://nacos.io/zh-cn/docs/quick-start-spring-cloud.html 在Nacos Spring Cloud中，dataId的完整格式如下： ${prefix}-${spring.profile.active}.${file-extension} prefix 默认为 spring.application.name 的值，也可以通过配置项 spring.cloud.nacos.config.prefix来配置。 spring.profiles.active 即为当前环境对应的 profile，详情可以参考 Spring Boot文档。 注意：当 spring.profiles.active 为空时，对应的连接符 - 也将不存在，dataId 的拼接格式变成 ${prefix}.${file-extension} file-exetension 为配置内容的数据格式，可以通过配置项 spring.cloud.nacos.config.file-extension 来配置。目前只支持 properties 和 yaml 类型。 从上面可以看到重要的一点，配置文件的名称第二项，spring.profiles.active 是依据当前环境的profile属性值的，也就是这个值如果是 dev，即开发环境，它就会读取 dev 的配置信息，如果是test，测试环境，它就会读取test的配置信息，就是从 spring.profile.active 值获取当前应该读取哪个环境下的配置信息。 所以要配置spring.profiles.active，新建application.yml文件，添加如下配置： spring: profiles: active: dev # 表示开发环境 综合以上说明，和下面的截图，Nacos 的dataid（类似文件名）应为： nacos-config-client-dev.yaml (必须是yaml) 当修改配置值，会发现 3377 上也已经修改，Nacos自带自动刷新功能！ 分类配置存在的问题 问题1 ： 实际开发中，通常─个系统会准备: dev开发环境 test测试环境 prod生产环境 如何保证指定环境启动时服务能正确读取到Nacos上相应环境的配置文件呢? 问题2: 一个大型分布式微服务系统会有很多微服务子项目，每个微服务项目又都会有相应的开发环境、测试环境、预发环境、正式环境…那怎么对这些微服务配置进行管理呢? nacos中的设计： Nacos 的 Group ,默认创建的配置文件，都是在DEFAULT_GROUP中，可以在创建配置文件时，给文件指定分组。 yml 配置如下，当修改开发环境时，只会从同一group中进行切换。 Nacos 的namespace ,默认的命名空间是public ,这个是不允许删除的，可以创建一个新的命名空间，会自动给创建的命名空间一个流水号。 在yml配置中，指定命名空间： 最后，dataid、group、namespace 三者关系如下：（不同的dataid，是相互独立的，不同的group是相互隔离的，不同的namespace也是相互独立的） Nacos集群和持久化概述 官方文档：https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html 集群架构图 对上图的理解 数据存储 搭建集群必须持久化，不然多台机器上的nacos的配置信息不同，造成系统错乱。它不同于单个springcloud config，没有集群一说，而且数据保存在github上，也不同于eureka，配置集群就完事了，没有需要保存的配置信息。 Nacos默认使用它自带的嵌入式数据库derby: Nacos持久化配置： 在 nacos的 conf目录下，有个nacos-mysql.sql 的sql文件，创建一个名为【nacos_config】的数据库，执行里面内容，在nacos_config数据库里面创建数据表。 找到conf/application.properties 文件，尾部追加如下内容： spring.datasource.platform=mysql db.num=1 db.url.0=jdbc:mysql://localhost:3306/nacos_config?characterEncoding=utf-8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true db.user=root db.password=123456 重启nacos，即完成持久化配置。 Linux版Nacos+MySQL生产环境配置 现在进行企业中真正需要的nacos集群配置，而不是上面的单机模式，需要准备如下： 一台linux虚拟机：nginx服务器，3个nacos服务，一个mysql数据库。 nacos下载linux版本的 tar.gz 包：https://github.com/alibaba/nacos/releases/download/1.1.4/nacos-server-1.1.4.tar.gz Nacos集群配置 1.首先对 nacos 进行持久化操作，操作如上面一致。 2.修改 nacos/conf 下的cluster文件，最好先复制一份 查看本机的IP hostname -i 编写 cluster.conf 前缀 IP 必须为上一步查到的 IP 地址 ​ 保存退出 3.模拟三台nacos服务，编辑nacos的startup启动脚本，使他能够支持不同的端口启动多次。 进入nacos/bin，找到startup.sh，最好先复制一份 编辑startup.sh ​ ​ ​ ​ 保存退出 4.nginx配置负载均衡： 进入/usr/local/nginx/conf，找到nginx.conf，最好先复制一份 编辑nginx.conf ​ -保存退出 5.启动集群 进入 /usr/local/nginx/sbin/目录 使用刚刚修改的配置文件启动 Nginx ./nginx -c /usr/local/nginx/conf/nginx.conf 进入nacos/bin目录 启动nacos集群（3333、4444、5555） 6.测试完成！ 使用 9002模块注册进Nacos Server 并获取它上面配置文件的信息，进行测试。 小总结","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：Sleuth","slug":"cloud9","date":"2021-03-21T03:52:43.000Z","updated":"2022-04-18T12:48:45.644Z","comments":true,"path":"posts/975bdb00.html","link":"","permalink":"http://mjean.life/posts/975bdb00.html","excerpt":"","text":"Sleuth 分布式请求链路跟踪，超大型系统。需要在微服务模块极其多的情况下，比如80调用8001的，8001调用8002的，这样就形成了一个链路，如果链路中某环节出现了故障，我们可以使用Sleuth进行链路跟踪，从而找到出现故障的环节。 概述分布式系统中存在的问题在微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成─条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。 Sleuth简介 官网 Spring Cloud Sleuth提供了一套完整的服务跟踪的解决方案 在分布式系统中提供追踪解决方案并且兼容支持了 zipkin sleuth 负责跟踪，而zipkin负责展示。 zipkin SpringCloud从F版起已不需要自己构建Zipkin server了，只需要调用jar包即可 zipkin 下载地址： http://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/2.12.9/zipkin-server-2.12.9-exec.jar 1.下载 zipkin ​ 选择zipkin-server-version.exec.jar 2.运行 zipkin ​ 使用 CMD 进入存放 zipkin.jar 的目录，并输入 java -jar zipkin-server-2.12.9-exec.jar 3.查看仪表盘 ​ 访问：http://localhost:9411/zipkin/ 完整的调用链路 表示一条请求链路，一条链路通过 Trace ID 唯一标识，Span 标识发起的请求信息，各 Span 通过 parent id 关联起来 上图简化 Trace : 类似于树结构的Span集合，表示一条调用链路，存在唯一标识 span ：表示调用链路来源，通俗的理解span就是一次请求信息 案例 使用之前的 提供者8001 和 消费者80 分别给他们引入依赖： &lt;!-- 引入sleuth + zipkin --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt; &lt;/dependency&gt; yml增加配置： spring: zipkin: base-url: http://localhost:9411 # zipkin 地址 sleuth: sampler: # 采样率值 介于0-1之间 ，1表示全部采集 probability: 1 8001模块的Controller添加一个方法 @GetMapping(\"payment/zipkin\") public String paymentZipkin(){ return \"hi , i am paymentzipkin server fall back, welcome!\"; } 80模块的Controller添加一个方法 //=========================&gt; zipkin+sleuth @GetMapping(\"/consumer/payment/zipkin\") public String paymentZipkin(){ String result = restTemplate.getForObject(\"http://localhost:8001\"+\"/payment/zipkin/\",String.class); return result; } 测试： 启动以下服务 调用服务消费者 80 端(多请求几次) ：http://localhost/consumer/payment/zipkin 查看 zipkin 的监控界面","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：消息驱动-Stream","slug":"cloud8","date":"2021-03-20T03:54:13.000Z","updated":"2022-04-18T12:48:45.642Z","comments":true,"path":"posts/96125f52.html","link":"","permalink":"http://mjean.life/posts/96125f52.html","excerpt":"","text":"消息驱动Stream概述什么是SpringCloud Stream？ Spring Cloud Stream 是一个用来为微服务应用构建消息驱动能力的框架。 应用程序通过 Inputs或者 outputs来与 Spring Cloud Stream中 binder对象交互。 通过我们配置来 **binding(绑定)**，而 Spring Cloud Stream的 binder对象负责与消息中间件交互。 所以我们只需要搞清楚如何与 Spring Cloud Stream交互就可以方便使用消息驱动的方式。 通过使用 Spring Integration来连接消息代理中间件以实现消息事件驱动。 Spring Cloud Stream 为一些供应商的消息中间件产品提供了个性化的自动化配置实现，并引入了发布-订阅、消费组、分区这三个核心概念。 通过使用 Spring Cloud Stream，可以有效简化开发人员对消息中间件的使用复杂度，让系统开发人员可以有更多的精力关注于核心业务逻辑的处理。 目前仅支持 RabbitMQ 和 Kafka 的自动化配置。 概括：屏蔽底层消息中间件的差异，降低切换版本，统一消息的编程模型 Spring Cloud Stream中文指导手册 设计思想 ​ 1.标准MQ 生产者/消费者之间靠消息媒介传递信息内容 —— Message 消息必须走特定的通道 —— 消息通道 MessageChannel 消息通道里的消息如何被消费呢，谁负责收发处理 —— 消息通道 MessageChannel 的子接口 SubscribableChannel,由 MessageHandler 消息处理器订阅 ​ 2.为什么要引入SpringCloud Stream 比方说我们用到了 RabbitMQ 和 Kafka ，由于这两个消息中间件的架构上的不同，像 RabbitMQ 有 exchange， kafka 有 Topic 和 Partitions 分区， 这些中间件的差异性导致我们实际项目开发给我们造成了一定的困扰，我们如果用了两个消息队列的其中一种，后面的业务需求，我想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候 springcloud Stream 给我们提供了—种解耦合的方式。 ​ 3.SpringCloud Stream屏蔽差异 在没有绑定器这个概念的情况下，我们的 SpringBoot 应用要直接与消息中间件进行信息交互的时候,由于各消息中间件构建的初衷不同，它们的实现细节上会有较大的差异性 通过定义绑定器binder作为中间层，完美地实现了应用程序与消息中间件细节之间的隔离。 通过向应用程序暴露统一的Channel通道，使得应用程序不需要再考虑各种不同的消息中间件实现。 INPUT对应于生产者 OUTPUT对应于消费者 ​ 4.Stream中的消息通信方式遵循了 发布-订阅 模式 在 RabbitMQ 就是 Exchange 交换机 在kafka中就是Topic Spring Cloud Stream标准流程套路 1.Binder：很方便的连接中间件，屏蔽差异 2.Channel：通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过对Channel对队列进行配置 3.Source和Sink：简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接收消息就是输入 编码API和常用注解 消息生产者新建模块 cloud-stream-rabbitmq-provider8801 pom依赖： &lt;!-- stream-rabbit --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client 目前，这个不是必须的--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; yml 配置： server: port: 8801 spring: application: name: cloud-stream-provider cloud: stream: binders: # 在次配置要绑定的rabbitMQ的服务信息 defaultRabbit: # 表示定义的名称，用于和binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 output: # 表示是生产者，向rabbitMQ发送消息 destination: studyExchange # 表示要使用的Exchange名称 content-type: application/json # 设置消息类型，本次是json，文本是 \"text/plain\" binder: defaultRabbit # 设置要绑定的消息服务的具体配置 eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ instance: lease-renewal-interval-in-seconds: 2 # 设置心跳时间，默认是30秒 lease-expiration-duration-in-seconds: 5 # 最大心跳间隔不能超过5秒,默认90秒 instance-id: send-8801.com # 在信息列表显示主机名称 prefer-ip-address: true # 访问路径变为ip地址 主启动类: @SpringBootApplication public class StreamMQProvider8801 { public static void main(String[] args) { SpringApplication.run(StreamMQProvider8801.class, args); } } 业务类：（此业务类不是以前的service，而是负责推送消息的服务类） 发送消息接口 public interface IMessageProvider { /** * @title send * @Description 发送消息 **/ public void send(); } 发送消息接口实现类 package com.xhc.springcloud.service; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.messaging.Source; import org.springframework.messaging.MessageChannel; import org.springframework.messaging.support.MessageBuilder; import javax.annotation.Resource; import java.util.UUID; @EnableBinding(Source.class) // 不是和controller打交道的service,而是发送消息的推送服务类 public class IMessageProviderImpl implements IMessageProvider { //上面是自定义的接口 @Resource private MessageChannel output; @Override public String send() { String serial = UUID.randomUUID().toString(); output.send(MessageBuilder.withPayload(serial).build()); System.out.println(\"******serial: \" + serial); return null; } } controller: @RestController public class SendMessageController { @Resource private IMessageProvider messageProvider; @GetMapping(\"/sendMessage\") public String sendMessage(){ return messageProvider.send(); } } 启动Eureka Server 7001，再启动8801，进行测试，看是否rabbitMQ中有我们发送的消息。 消息消费者新建模块 cloud-stream-rabbitmq-consumer8802 pom依赖和生产者一样。 yml配置: 在 stream的配置上，和生产者只有一处不同的地方，output 改成 input server: port: 8802 spring: application: name: cloud-stream-provider cloud: stream: binders: # 在次配置要绑定的rabbitMQ的服务信息 defaultRabbit: # 表示定义的名称，用于和binding整合 type: rabbit # 消息组件类型 environment: # 设置rabbitmq的相关环境配置 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest bindings: # 服务的整合处理 input: # 表示是消费者，这里是唯一和生产者不同的地方，向rabbitMQ发送消息 destination: studyExchange # 表示要使用的Exchange名称 content-type: application/json # 设置消息类型，本次是json，文本是 \"text/plain\" binder: defaultRabbit # 设置要绑定的消息服务的具体配置 eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ instance: lease-renewal-interval-in-seconds: 2 # 设置心跳时间，默认是30秒 lease-expiration-duration-in-seconds: 5 # 最大心跳间隔不能超过5秒,默认90秒 instance-id: receive-8802.com # 在信息列表显示主机名称 prefer-ip-address: true # 访问路径变为ip地址 接收消息的业务类： import org.springframework.beans.factory.annotation.Value; import org.springframework.cloud.stream.annotation.EnableBinding; import org.springframework.cloud.stream.annotation.StreamListener; import org.springframework.cloud.stream.messaging.Sink; import org.springframework.messaging.Message; import org.springframework.stereotype.Component; @Component @EnableBinding(Sink.class) public class ConsumerController { @Value(\"${server.port}\") private String serverPort; @StreamListener(Sink.INPUT) public void input(Message&lt;String&gt; message){ System.out.println(\"消费者1号，serverport: \" + serverPort + \"，接受到的消息：\" + message.getPayload()); } } 配置分组消费新建 cloud-stream-rabbitmq-consumer8803 模块： 8803 就是 8802 clone出来的。 启动两个消费者之后出现了问题： 有重复消费问题(即两个消费者都接收到了消息，这属于重复消费。例如，消费者进行订单创建，这样就创建了两份订单，会造成系统错误。) 消息持久化问题 Stream默认不同的微服务是不同的组 对于重复消费这种问题，导致的原因是默认每个微服务是不同的group，组流水号不一样，所以被认为是不同组，两个都可以消费。 解决的办法就是自定义配置分组： 消费者 yml 文件配置： # 8802 的消费者 bindings: input: destination: studyExchange content-type: application/json binder: defaultRabbit group: xhcA # 自定义分组配置 # 8803 的消费者 bindings: input: destination: studyExchange content-type: application/json binder: defaultRabbit group: xhcB # 自定义分组配置 到现在只是自定义了分组 这两个服务还是在两个不同的组中，所以还是存在重复消费 重复消费解决方案 8802 / 8803 实现轮询分组，每次只有一个消费者 8801 模块的发的消息只能被 8802 或 8803 其中一个接收到，这样避免了重复消费 将 8803 的分组修改为 xhcA 当两个消费者配置的 group 都为 xhcA 时，就属于同一组，就不会被重复消费。 消息持久化 加上group配置，就已经实现了消息的持久化。 下面演示一下持久化的效果 先停止 8802、8803 服务 删去 8802 的 YML 中 Group，8803 的不删 8801 生产者先发送几条消息 http://localhost:8801/sendMessage 启动 8802 ，并观察控制台 控制台无输出，因为没有配置 Group，没有开启持久化，所以没有接收到消息 启动 8803 ，并观察控制台 控制台有输出，因为配置了 Group，开启了持久化，所以接收到了消息","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：服务配置-Config、消息总线-Bus","slug":"cloud7","date":"2021-03-18T04:46:23.000Z","updated":"2022-04-18T12:48:45.789Z","comments":true,"path":"posts/411dcfac.html","link":"","permalink":"http://mjean.life/posts/411dcfac.html","excerpt":"","text":"服务配置Config SpringCloud Config 分布式配置中心 概述在分布式系统中，由于服务数量巨多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。Spring Cloud Config项目是就是这样一个解决分布式系统的配置管理方案。它包含了Client和Server两个部分，server提供配置文件的存储、以接口的形式将配置文件的内容提供出去，client通过接口获取数据、并依据此数据初始化自己的应用。 作用： 1.集中统一管理配置文件; 2.不同环境不同配置，动态化的配置更新，分环境部署; 3.运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息; 4.当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置; 5.将配置信息以REST接口的形式暴露; 与github整合配置： 由于SpringCloud Config默认使用Git来存储配置文件（也有其它方式，比如支持svn和本地文件，但最推荐的还是Git，而且使用的是http/https访问的形式） 1.在github上新建一个Repository：springcloud-config 2.获取新建仓库地址：git@github.com:XXXX/springcloud-config.git 3.本地磁盘新建git仓库并clone mkdir SpringCloud2020 git clone git@github.com:XXXX/springcloud-config.git 服务端配置新建 cloud-config-center3344 模块： pom文件： &lt;dependencies&gt; &lt;!-- config Server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client config Server也要注册进服务中心--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 配置： server: port: 3344 spring: application: name: cloud-config-center #注册进Eureka服务器的微服务名 cloud: config: server: git: uri: https://github.com/HChan-X/springcloud-config.git #Github上面的git仓库名字 ####搜索目录 search-paths: - springcloud-config ####读取分支 label: main eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ 注意： yml中 uri: git@github.com:HChan-X/springcloud-config.git 配置远程仓库访问时会报错 Cannot clone or checkout repository: git@github.com:HChan-X/springcloud-config.git 修改成 https://github.com/HChan-X/springcloud-config.git 即可 主启动类： @SpringBootApplication @EnableConfigServer //关键注解 public class ConfigCenterMain3344 { public static void main(String[] args) { SpringApplication.run(ConfigCenterMain3344.class,args); } } 添加映射：【C:\\Windows\\System32\\drivers\\etc\\hosts】文件中添加： 127.0.0.1 config-3344.com 测试通过Config微服务是否可以从Github上获取配置内容 1）启动7001 2）启动3344 3）访问http://config-3344.com:3344/main/config-dev.yml 文件（注意，要提前在git上弄一个这文件） 4）成功实现了用SpringCloud Config 通过GitHub获取配置信息 配置读取规则1)/{label}/{application}-{profile}.yml（最推荐使用这种方式） 2)/{application}-{profile}.yml 3)/{application}-{profile}[/{label}] 总结： {application} 就是应用名称，对应到配置文件上来，就是配置文件的名称部分，例如我上面创建的配置文件。 {profile} 就是配置文件的版本，我们的项目有开发版本、测试环境版本、生产环境版本，对应到配置文件上来就是以 application-{profile}.yml 加以区分，例如application-dev.yml、application-sit.yml、application-prod.yml。 {label} 表示 git 分支，默认是 main 分支，如果项目是以分支做区分也是可以的，那就可以通过不同的 label 来控制访问不同的配置文件了。 只要格式正确，还是能正常访问，但如果不存在配置，是没有配置数据出现的，如果输入的不是正确的格式，乱输入，是会出现404的。 客户端配置 这里的客户端指的是，使用 Config Server 统一配置文件的项目。既有之前说的消费者，又有提供者 新建 cloud-config-client-3355 模块： pom文件： &lt;dependencies&gt; &lt;!-- config Client 和 服务端的依赖不一样 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client config Server也要注册进服务中心--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; bootstrap.yml文件: server: port: 3355 spring: application: name: config-client cloud: # config 客户端配置 config: label: main # 分支名称 name: config # 配置文件名称，文件也可以是client-config-dev.yml这种格式的，这里就写 client-config profile: dev # 使用配置环境 uri: http://config-3344.com:3344 # config Server 地址 # 综合上面四个 即读取配置文件地址为： http://config-3344.com:3344/master/config-dev.yml eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ 说明： applicaiton.yml 是用户级的资源配置项 bootstrap.yml 是系统级的，优先级更加高 Spring Cloud 会创建一个 Bootstrap Context ，作为 Spring 应用的 Application Context 的父上下文。初始化的时候，BootstrapContext 负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的 Environment Bootstrap 属性有高优先级，默认情况下，它们不会被本地配置覆盖。Bootstrap context 和 Application Context 有着不同的约定，所以新增了一个 bootstrap.yml 文件，保证 Bootstrap Context 和 Application Context 配置的分离 要将 Client 模块下的 application.yml 文件改为 bootstrap.yml ,这是很关键的，因为 bootstrap.yml 是比 application.yml 先加载的。bootstrap.yml 优先级高于 application.yml 主启动类： @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3355 public static void main(String[] args) { SpringApplication.run(ConfigClientMain3355.class, args); } } controller层，测试读取配置信息 package com.xhc.springcloud.controller; import org.springframework.beans.factory.annotation.Value; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class ConfigClientController { @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String getConfigInfo(){ return configInfo; } } 启动测试完成！如果报错，注意github上的 yml 格式有没有写错！ 动态刷新问题： 1）修改GitHub上的配置文件内容：config: info: “master branch,springcloud-config/config-dev.yml version=2” 2）刷新3344，发现ConfigServer配置中心立刻响应 3）刷新3355，发现ConfigServer客户端没有任何响应 4）3355没有变化除非自己重启或者重新加载 就是github上面配置更新了，config Server 项目上是动态更新的，但是，client端的项目中的配置，目前还是之前的，它不能动态更新，必须重启才行。 解决： client端一定要有如下依赖： &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; client 端增加 yml 配置如下，即在 bootstrap.yml 文件中： # 暴露监控端点 management: endpoints: web: exposure: include: \"*\" 在controller 上添加注解：@RefreshScope 到此为止，配置已经完成，但是测试仍然不能动态刷新，需要下一步。 发送Post请求刷新3355 （必须是post请求。打开命令行窗口执行以下命令） curl -X POST “http://localhost:3355/actuator/refresh\" 两个必须：1.必须是 POST 请求，2.请求地址：http://localhost:3355/actuator/refresh 成功！ 但是又有一个问题，就是如果多个客户端该怎么解决？不可能每一个都去发送post请求刷新！ 就有下面的消息总线！ 消息总线Bus概述Spring Cloud Bus 是用来将分布式系统的节点与轻量级消息系统链接起来的框架，整合了java的事件处理机制和消息中间件功能。 目前支持RabbitMQ和Kafka两种消息代理。 能管理和传播分布式系统间的消息，就像是一个分布式执行器，可用于广播状态更改、事件推送等，也可以当做微服务间的通信通道。 1.分布式自动刷新配置功能 2.Spring Cloud Bus配合Spring Cloud Config使用可以实现配置的动态刷新 3.Bus支持两种消息代理：RabbitMQ和Kafka 安装RabbitMQ 在windows 上安装RabbitMQ 安装RabbitMQ的依赖环境 Erlang 下载地址： http://erlang.org/download/otp_win64_21.3.exe 安装RabbitMQ 下载地址： http://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.14/rabbitmq-server-3.7.14.exe 进入 rabbitMQ安装目录的sbin目录下，打开cmd窗口，执行 【rabbitmq-plugins enable rabbitmq_management】 可视化插件，rabbitMQservice - start 点击启动服务 访问【http://localhost:15672/】，输入密码和账号：默认都为 guest 广播式刷新配置设计思想： 两种方式： 1.利用消息总线触发一个客户端/bus/refresh,从而刷新所有客户端的配置 2.利用消息总线触发一个服务端ConfigServer的/bus/refresh端点,而刷新所有客户端的配置（更加推荐） 第一种方式不适合的原因： 1.打破了微服务的职责单一性，因为微服务本身是业务模块，它本不应该承担配置刷新职责 2.破坏了微服务各节点的对等性 3.有一定的局限性。例如，微服务在迁移时，它的网络地址常常会发生变化，此时如果想要做到自动刷新，那就会增加更多的修改 按照之前的 3344（config Server）和 3355（config client）,在原有的基础上增加一个config client：3366模块（直接copy3355就行了）。 pom文件： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; bootstrap.yml文件： server: port: 3366 spring: application: name: config-client cloud: #config客户端配置 config: label: main #分支名称 name: config #配置文件名称 profile: dev #读取后缀名称 上述3个综合：main分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/main/config-dev.yml uri: http://localhost:3344 #配置中心地址 #服务注册到Eureka地址 eureka: client: service-url: defaultZone: http://localhost:7001/eureka #暴露监控端点 management: endpoints: web: exposure: include: \"*\" 主启动类： @SpringBootApplication @EnableEurekaClient public class ConfigClientMain3366 { public static void main(String[] args) { SpringApplication.run(ConfigClientMain3366.class,args); } } controller层，测试读取配置信息: @RestController @RefreshScope public class ConfigClientController { @Value(\"${server.port}\") private String serverPort; @Value(\"${config.info}\") private String configInfo; @GetMapping(\"/configInfo\") public String configInfo(){ return \"serverPort: \"+serverPort+\"\\t\\n\\n configInfo: \"+configInfo; } } 给config Server 和 config client添加消息总线支持 在 config Server 和 config client 都添加如下依赖： &lt;!-- 添加rabbitMQ的消息总线支持包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-bus-amqp&lt;/artifactId&gt; &lt;/dependency&gt; config Server 的yml文件增加如下配置： # rabbitMq的相关配置 rabbitmq: host: localhost port: 5672 # 这里没错，虽然rabbitMQ网页是 15672 username: guest password: guest # rabbitmq 的相关配置2 暴露bus刷新配置的端点 management: endpoints: web: exposure: include: 'bus-refresh' config Client 的yml文件修改成如下配置：（注意对齐方式，和config Server不一样） spring: application: name: config-client cloud: # config 客户端配置 config: label: main # 分支名称 name: config # 配置文件名称 profile: dev # 使用配置环境 uri: http://config-3344.com:3344 # config Server 地址 # 综合上面四个 即读取配置文件地址为： http://config-3344.com:3344/master/config-dev.yml # rabbitMq的相关配置 rabbitmq: host: localhost port: 5672 username: guest password: guest 可在github上修改yml文件进行测试，修改完文件，向 config server 发送 请求： 【curl -X POST “http://localhost:3344/actuator/bus-refresh\"】 注意，之前是向config client 一个个发送请求，但是这次是向 config Server 发送请求，而所有的config client 的配置也都全部更新。 定点通知指定具体某一个实例生效而不是全部 公式：http://localhost:配置中心的端口号/actuator/bus-refresh/{destination} /bus/refresh请求不再发送到具体的服务实例上，而是发给config server并通过destination参数类指定需要更新配置的服务实例 我们在这里以刷新运行在3355端口上的config-client为例（只通知3355，不通知3366） curl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\" 上面的config-client:3355 就是 微服务名称+端口号","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：服务网关-Gateway","slug":"cloud6","date":"2021-03-16T06:09:31.000Z","updated":"2022-04-18T12:48:45.634Z","comments":true,"path":"posts/a62febd7.html","link":"","permalink":"http://mjean.life/posts/a62febd7.html","excerpt":"","text":"服务网关Gateway简介Spring Cloud Gateway是 Spring Cloud的一个全新项目，基于 Spring5.0+Spring Boot2.0和 Project Reactor等技术开发的网关,它旨在为微服务架构提供一种简单有效的统的API路由管理方式。 Spring Cloud Gateway作为 Spring Cloud生态系统中的网关，目标是替代Zuul,、，在 Spring Cloud2.0以上版本中,没有对新版本的Zuul2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 1.x非 Reactor模式的老版本。而为了提升网关的性能, SpringCloud Gateway是基于 Webfluxi框架实现的,而 Webflux框架底层则使用了高性能的 Reactor模式通信框架Netty。 Spring Cloud Gateway的目标提供统一的路由方式且基于 Filter 链的方式提供了网关基本的功能,例如:安全,监控/指标,和限流。 SpringCloud Gateway使用的Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。 Gateway特性： 基于 Spring Framework 5, Project Reactor和 Spring Boot2.0进行构建; 动态路由：能够匹配任何请求属性; 可以对路由指定 Predicate(断言) 和 Filter(过滤器); 集成 Hystrix的断路器功能; 集成 Spring cloud 服务发现功能 易于编写的 Predicate(断言) 和 Filter(过滤器); 请求限流功能; 支持路径重写。 三大核心概念： Route路由：路由是构建网关的基本模块，它由ID、目标URI、一系列的断言和过滤器组成，如果断言为true则匹配该路由 Predicate断言：开发人员可以匹配Http请求中的所有内容（例如请求头、请求参数）如果请求与断言相匹配则进行路由（参考:Java8:java.util.function.Predicate） Filter过滤：指的是Spring框架中GatewayFilter的实例，使用过滤器，可以在请求被路由之前或者之后对请求进行修改 一句话概述： web请求，通过一些匹配条件，定位到真正的服务节点，并在这个转发过程的前后进行一些精细化控制。predicate就是我们的匹配条件，而filter就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了 工作流程： 客户端向SpringCloud Gateway发出请求，然后在GateWay HandlerMapping中找到与请求相匹配的路由，将其发送到Gateway Web Hander； Handler再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑 Filter在“pre”类型的过滤器中可以做参数校验、权限校验、流量监控、日志输出、协议转换等；在“post”类型的过滤器中可以做响应内容、响应头的修改、日志输出、流量监控等有着非常重要的作用。 核心逻辑：路由转发+执行过滤器链 入门配置新建模块 cloud-gateway-gateway9527 现在实现，通过Gateway (网关) 来访问其它项目，这里选择之前8001项目，要求注册进Eureka Server 。 pom文件： &lt;dependencies&gt; &lt;!--gateway--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--eureka-client gateWay作为网关，也要注册进服务中心--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- gateway和web不能同时存在，即web相关jar包不能导入 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!-- 引入自己定义的api通用包，可以使用Payment支付Entity --&gt; &lt;groupId&gt;com.xhc.cloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml文件： server: port: 9527 spring: application: name: cloud-gateway ## GateWay配置 cloud: gateway: routes: - id: payment_routh # 路由ID ， 没有固定的规则但要求唯一，建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 # 路由ID ， 没有固定的规则但要求唯一，建议配合服务名 uri: http://localhost:8001 # 匹配后提供服务的路由地址 predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 # 注册进 eureka Server eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ register-with-eureka: true fetch-registry: true 主启动类： @SpringBootApplication @EnableEurekaClient public class GateWayMain9527 { public static void main(String[] args) { SpringApplication.run(GateWayMain9527.class,args); } } 访问测试：1 启动eureka Server7001，2 启动 8001 项目，3 启动9527（Gateway项目） 可见，当我们访问 http://localhost:9527/payment/get/1 时，即访问网关地址时，会给我们转发到 8001 项目的请求地址，以此作出响应。 加入网关前：http://localhost:8001/payment/get/1 加入网关后：http://localhost:9527/payment/get/1 上面是以 yml 文件配置的路由，也有使用config类配置的方式： @Configuration public class GateWayConfig { @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder){ RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes(); routes.route(\"path_route\", r -&gt; r.path(\"/guonei\") .uri(\"http://news.baidu.com/guonei\")).build(); return routes.build(); } } 动态配置 这里所谓的动态配置就是利用服务注册中心，来实现 负载均衡 的调用 多个微服务。 注意，这是Gateway 的负载均衡 对yml进行配置： spring: application: name: cloud-gateway cloud: gateway: discovery: locator: enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由 routes: - id: payment_routh # 路由ID ， 没有固定的规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 # 匹配后提供服务的路由地址 uri: lb://CLOUD-PROVIDER-SERVICE predicates: - Path=/payment/get/** # 断言，路径相匹配的进行路由 - id: payment_routh2 # 路由ID ， 没有固定的规则但要求唯一，建议配合服务名 # uri: http://localhost:8001 # 匹配后提供服务的路由地址 uri: lb://CLOUD-PROVIDER-SERVICE predicates: - Path=/payment/lb/** # 断言，路径相匹配的进行路由 # uri: lb://CLOUD-PROVIDER-SERVICE 解释：lb 属于GateWay 的关键字，代表是动态uri，即代表使用的是服务注册中心的微服务名，它默认开启使用负载均衡机制 下面可以开启 8002 模块，并将它与8001同微服务名，注册到 Eureka Server 进行测试。 Predicate 常用的Predicate：官方文档 部分代码示例： 修改yml gateway的配置 predicates: # 断言，路径相匹配的进行路由 - Path=/payment/get/** #- After=2020-08-03T15:45:34.102+08:00[Asia/Shanghai] #- Before=2017-01-20T17:42:47.789-07:00[America/Denver] #- Cookie=username,zzyy #- Header=X-Request-Id, \\d+ #请求头要有X-Request-Id属性，并且值为正数 #- Host=**.atguigu.com #- Method=GET #- Query=username, \\d+ # 要有参数名username并且值还要是正整数才能路由 说明： After=2020-08-03T15:45:34.102+08:00[Asia/Shanghai]：需要在这个时间之后生效。Before同理！ Cookie：Cookie Route Predicate 需要两个参数，一个是Cookie name，一个是正则表达式。路由规则会通过获取对应的Cookie name 值和正则表达式去匹配，如果匹配上就会执行路由。 Header：两个参数：一个是属性名称和一个正则表达式，这个属性值和正则表达式匹配则执行。 Host：Host Route Predicate 接收一组参数，一组匹配的域名列表，这个模板是一个ant分隔的模板，用.号作为分隔符。它通过参数中的主机地址作为匹配规则。 配置错误页面: 注意，springboot默认/static/error/ 下错误代码命名的页面为错误页面，即 404.html 而且不需要导入额外的包，Gateway 里面都有。 Filter 官方文档 Filter分类：Gateway Fliter（单一31种）、Global Filter（全局–10种） 自定义过滤器类实现GlobalFilter，Orderd接口即可 可以全局日志记录、统一网关鉴权 自定义全局过滤器配置类： @Component public class GateWayFilter implements GlobalFilter, Ordered { @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { System.out.println(\"------come in MyGlobalFilter : \"+ new Date()); String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\"); //合法性检验 if(uname == null){ System.out.println(\"----用户名为null,非法用户，请求不被接受\"); //设置 response 状态码 因为在请求之前过滤的，所以就算是返回NOT_FOUND 也不会返回错误页面 exchange.getResponse().setStatusCode(HttpStatus.NOT_FOUND); //完成请求调用 return exchange.getResponse().setComplete(); } return chain.filter(exchange); } //返回值是加载顺序，一般全局的都是第一位加载 @Override public int getOrder() { return 0; } } 运行结果：","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：Hystrix断路器","slug":"cloud5","date":"2021-03-05T12:55:32.917Z","updated":"2022-04-18T12:48:45.783Z","comments":true,"path":"posts/8c98e87.html","link":"","permalink":"http://mjean.life/posts/8c98e87.html","excerpt":"","text":"Hystrix 断路器 官方地址：https://github.com/Netflix/Hystrix/wiki/How-To-Use 概述服务雪崩多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C,微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出“。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃,所谓的“雪崩效应”。 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 Hystrix是一个用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败,比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。 ”断路器”本身是一种开关装置,当某个服务单元发生故障之后,通过断路器的故障监控(类似熔断保险丝)，向调用方返回个符合预期的、可处理的备选响应(Fallback)，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延,乃至雪崩。 Hystrix的作用 对通过第三方客户端库访问的依赖项（通常是通过网络）的延迟和故障进行保护和控制。 在复杂的分布式系统中阻止级联故障。 快速失败，快速恢复。 回退，尽可能优雅地降级。 启用近实时监控、警报和操作控制。 服务降级： 服务器忙碌或者网络拥堵时，不让客户端等待并立刻返回一个友好提示，fallback发生的情况有： 程序运行异常 超时 服务熔断触发服务降级 线程池/信号量打满也会导致服务降级 服务熔断： 类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示就是保险丝。服务的降级-&gt;进而熔断-&gt;恢复调用链路 服务限流： 秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟n个，有序进行 可见，上面的技术不论是消费者还是提供者，根据真实环境都是可以加入配置的。 案例 首先构建一个eureka作为服务中心的单机版微服务架构 ，这里使用之前eureka Server 7001模块，作为服务中心 新建 提供者 cloud-provider-hystrix-payment8001 模块： pom 文件： &lt;dependencies&gt; &lt;!--hystrix--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 下面主启动类、service、和controller 主启动类： @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableEurekaClient public class PaymentMain8001 { public static void main(String[] args) { SpringApplication.run(PaymentMain8001.class,args); } } service层： @Service public class PaymentService { /** * 正常访问，肯定OK * @param id * @return */ public String paymentInfo_OK(Integer id){ return \"线程池： \"+Thread.currentThread().getName()+\" paymentInfo_OK,id: \"+id+\"\\t\"+\"哈哈\"; } @HystrixCommand(fallbackMethod = \"paymentInfo_TimeOutHandler\", commandProperties = {@HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\",value = \"5000\")}) public String paymentInfo_TimeOut(Integer id){ //暂停几秒钟线程 try { TimeUnit.MILLISECONDS.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } return \"线程池： \"+Thread.currentThread().getName()+\" paymentInfo_TimeOut,id: \"+id+\"\\t\"+\"哈哈\"; } controller层： @RestController @Slf4j public class PaymentController { @Resource private PaymentService paymentService; @Value(\"${server.port}\") private String serverPort; @GetMapping(\"/payment/hystrix/ok/{id}\") public String paymentInfo_OK(@PathVariable(\"id\") Integer id){ String result = paymentService.paymentInfo_OK(id); log.info(\"*******result: \"+result); return result; } @GetMapping(\"/payment/hystrix/timeout/{id}\") public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id){ String result = paymentService.paymentInfo_TimeOut(id); log.info(\"*******result: \"+result); return result; } } 模拟高并发 这里使用一个新工具 JMeter 压力测试器 下载压缩包，解压，双击 /bin/ 下的 jmeter.bat 即可启动 ctrl + S 保存。 从测试可以看出，当模拟的超长请求被高并发以后，访问普通的小请求速率也会被拉低。 新建消费者 cloud-customer-feign-hystrix-order80 模块：以feign为服务调用，eureka为服务中心的模块，yml、pom等文件不再赘写。 测试可见，当启动高并发测试时，消费者访问也会变得很慢，甚至出现超时报错。 解决思路： 服务降级 一般服务降级放在客户端，即 消费者端 ，但是提供者端一样能使用。 首先提供者，即8001 先从自身找问题，设置自身调用超时的峰值，峰值内正常运行，超出峰值需要有兜底的方法处理，作服务降级fallback 首先 对 8001 的service进行配置（对容易超时的方法进行配置) : @HystrixCommand(fallbackMethod = \"paymentInfo_timeoutHandler\", commandProperties = { //设置峰值，超过 3 秒，就会调用兜底方法，这个时间也可以由feign控制 @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) public String paymentinfo_Timeout(Integer id){ ......会执行5秒..... } //兜底方法，根据上述配置，程序内发生异常、或者运行超时，都会执行该兜底方法 public String paymentInfo_timeoutHandler(Integer id){ ....... } } 主启动类添加注解： @EnableCircuitBreaker 然后对 80 进行服务降级：很明显 service 层是接口，所以我们对消费者，在它的 controller 层进行降级 @HystrixCommand(fallbackMethod = \"paymentInfo_timeoutHandler\", commandProperties = { //设置峰值，超过 3 秒，就会调用兜底方法 @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) @GetMapping(\"/customer/payment/hystrix/timeout/{id}\") public String paymentInfo_Timeout(@PathVariable(\"id\")Integer id){ log.info(\"paymentInfo_timeout\"); return orderService.paymentInfo_Timeout(id); } //兜底方法，注意，兜底方法参数随意 public String paymentInfo_timeoutHandler(@PathVariable(\"id\")Integer id){ log.info(\"paymentInfo_timeout--handler\"); return \"访问 payment 失败\"; } 主启动类添加注解： @EnableCircuitBreaker 完成测试！ 注意，消费者降级设置的超时时间和提供者的没有任何关系，就算提供者峰值是 5 秒，而消费者峰值是 3秒，那么消费者依然报错。就是每个模块在服务降级上，都是独立的。 全局服务降级 上面的降级策略，很明显造成了两个问题： 1、每个方法有一个对应的处理方法，代码膨胀。 2、处理方法和主业务逻辑混合在一起。 解决方案：将降级处理方法（兜底方法）做一个全局的配置，设置共有的兜底方法和独享的兜底方法。 问题1：每个方法有一个对应的处理方法，代码膨胀。解决： @RestController @Slf4j //全局配置降级方法的注解 @DefaultProperties(defaultFallback = \"paymentInfo_timeoutHandler\") public class OrderController { ..... // 不写自己的 fallbackMethod 属性，就使用全局默认的 @HystrixCommand(commandProperties = { @HystrixProperty(name=\"execution.isolation.thread.timeoutInMilliseconds\", value = \"3000\") }) @GetMapping(\"/customer/payment/hystrix/timeout/{id}\") public String paymentInfo_Timeout(@PathVariable(\"id\")Integer id){ ...... } //兜底方法 public String paymentInfo_timeoutHandler(){ log.info(\"paymentInfo_timeout--handler\"); return \"访问 payment 失败\"; } } 问题2：处理方法和主业务逻辑混合在一起。解决（解耦）： 在这种方式一般是在客户端，即消费者端，首先上面再controller中添加的 @HystrixCommand 和 @DefaultProperties 两个注解去掉。就是保持原来的controller yml文件配置 server: port: 80 spring: application: name: cloud-customer-feign-hystrix-service eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/ # 用于服务降级 在注解@FeignClient 中添加 fallback 属性值 feign: hystrix: enabled: true # 在feign中开启 hystrix 修改service 接口： @Component // 这里是重点 @FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\", fallback = OrderFallbackService.class) public interface OrderService { @GetMapping(\"/payment/hystrix/{id}\") public String paymentInfo_OK(@PathVariable(\"id\")Integer id); @GetMapping(\"/payment/hystrix/timeout/{id}\") public String paymentInfo_Timeout(@PathVariable(\"id\")Integer id); } fallback 指向的类： package com.xhc.springcloud.service; import org.springframework.stereotype.Component; @Component //注意这里，它实现了service接口 public class OrderFallbackService implements OrderService{ @Override public String paymentInfo_OK(Integer id) { return \"OrderFallbackService --发生异常\"; } @Override public String paymentInfo_Timeout(Integer id) { return \"OrderFallbackService --发生异常--paymentInfo_Timeout\"; } } 那么，如何设置超时时间？ 首先要知道 下面两个 yml 配置项： hystrix.command.default.execution.timeout.enable=true ## 默认值 ## 为false则超时控制有ribbon控制，为true则hystrix超时和ribbon超时都使用，但是谁小谁生效，默认为true hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=1000 ## 默认值 ## 熔断器的超时时长默认1秒，最常修改的参数 所以： 只需要在yml配置里面配置 Ribbon 的 超时时长即可。注意：hystrix 默认自带 ribbon包。 ribbon: ReadTimeout: xxxx ConnectTimeout: xxx 服务熔断 实际上服务熔断 和 服务降级 没有任何关系，就像 java 和 javaScript 熔断机制概述熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇岀链路的某个微服务岀错不可用或者响应时间太长时，会进行服务的降级,进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后,恢复调用链路。 在Spring Cloud框架里,熔断机制通过Hystrix实现。 Hystrix会监控微服务间调用的状况,当失败的调用到定阈值,缺省是5秒内20次调用失败,就会启动熔断机制。熔断机制的注解是@HystrixCommand。 Hystrix断路器使用时最常用的三个重要参数： circuitBreaker.sleepWindowInMilliseconds（快照时间窗） 断路器确定是否打开需要统计一些请求和错误数据，而统计的时间范围就是快照时间窗，默认为最近的10秒。 circuitBreaker.requestVolumeThreshold（请求总数阀值） 在快照时间窗内，必须满足请求总数阀值才有资格熔断。默认为20，意味着在10秒内，如果该hystrix命令的调用次数不足20次，即使所有的请求都超时或其他原因失败，断路器都不会打开。 circuitBreaker.errorThresholdPercentage（错误百分比阀值） 当请求总数在快照时间窗内超过了阀值，比如发生了30次调用，如果在这30次调用中，有15次发生了超时异常，也就是超过50%的错误百分比，在默认设定50%阀值情况下，这时候就会将断路器打开。 综上所述，在以上三个参数缺省的情况下，Hystrix断路器触发的默认策略为： 在10秒内，发生20次以上的请求时，假如错误率达到50%以上，则断路器将被打开。（当一个窗口期过去的时候，断路器将变成半开（HALF-OPEN）状态，如果这时候发生的请求正常，则关闭，否则又打开） 以 8001 项目为示例： service层的方法设置服务熔断: //=====服务熔断 @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\", commandProperties = { @HystrixProperty(name=\"circuitBreaker.enabled\", value=\"true\"), // 是否开启断路器 @HystrixProperty(name=\"circuitBreaker.requestVolumeThreshold\", value=\"10\"), //请求次数 @HystrixProperty(name=\"circuitBreaker.sleepWindowInMilliseconds\", value=\"10000\"), // 时间窗口期 @HystrixProperty(name=\"circuitBreaker.errorThresholdPercentage\", value=\"60\"), // 失败率达到多少后跳闸 //整体意思：10秒内 10次请求，有6次失败，就跳闸 }) public String paymentCircuitBreaker(Integer id){ //模拟发生异常 if(id &lt; 0){ throw new RuntimeException(\"*****id，不能为负数\"); } String serialNumber = IdUtil.simpleUUID(); return Thread.currentThread().getName() + \"\\t\" + \"调用成功，流水号：\" + serialNumber; } public String paymentCircuitBreaker_fallback(Integer id){ return \"id 不能为负数，请稍后再试....\"; } controller: //====服务熔断 @GetMapping(\"/payment/circuit/{id}\") public String paymentCircuitBreaker(@PathVariable(\"id\")Integer id){ return paymentService.paymentCircuitBreaker(id); } 关于解耦以后的全局配置说明： 例如上面提到的全局服务降级，并且是feign+hystrix整合，即 service 实现类的方式，如何做全局配置？ 上面有 做全局配置时，设置超时时间的方式，我们可以从中获得灵感，即在yml文件中 进行熔断配置： hystrix: command: default: circuitBreaker: enabled: true requestVolumeThreshold: 10 sleepWindowInMilliseconds: 10000 errorThresholdPercentage: 60 Hystrix DashBoard除了隔离依赖服务的调用以外， Hystrix还提供了准实时的调用监控( Hystrix Dashboard)，Hystrix会持续地记录所有通过 Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。 Netflix通过hystrix-metrics-event- stream项目实现了对以上指标的监控。 Spring Cloud也提供了 Hystrix Dashboard的整合,对监控内容转化成可视化界面。 新建模块 cloud-hystrix-dashboard9001 ： pom 文件： &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml文件只需要配置端口号，主启动类加上这样注解：@EnableHystrixDashboard 启动测试：访问 http://ocalhost:9001/hystrix 监控实战 下面使用上面 9001 Hystrix Dashboard 项目，来监控 8001 项目 Hystrix 的实时情况： 注意：新版本Hystrix需要在主启动类中指定监控路径 @Bean public ServletRegistrationBean getServlet(){ HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(streamServlet); servletRegistrationBean.setLoadOnStartup(1); servletRegistrationBean.addUrlMappings(\"/hystrix.stream\"); servletRegistrationBean.setName(\"HystrixMetricsStreamServlet\"); return servletRegistrationBean; }","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：服务调用","slug":"cloud4","date":"2021-03-01T12:41:25.000Z","updated":"2022-04-18T12:48:45.639Z","comments":true,"path":"posts/e74c79f1.html","link":"","permalink":"http://mjean.life/posts/e74c79f1.html","excerpt":"","text":"服务调用 都是使用在 client端，即有 ”消费者“ 需求的模块中。 Ribbon简介Spring Cloud Ribbon是基于 Netflix Ribbon实现的一套客户端一一负载均衡的工具。 简单的说, Ribbon是Netflix发布的开源项目,主要功能是提供客户端的软件负载均衡算法和服务调用。 Ribbon客户端组件提供一系列完善的配置项如连接超时,重试等。简单的说,就是在配置文件中列出Load Balancer(筒称LB)后面所有的机器, Ribbon会自动的帮助你基于某种规则(如简单轮询,随机连接等)去连接这些机器。我们很容易使用Ribbon实现自定义的负载均衡算法。 LB负载均衡(Load Balance)是什么简单的说就是将用户的请求平摊的分配到多个服务上,从而达到系统的HA(高可用)。常见的负载均衡有软件Nginx,LVS,硬件F5等。 Ribbon本地负载均衡客户端 VS Nginx服务端负载均衡区别Nginx是服务器负载均衡,客户端所有请求都会交给nginx,然后由nginx实现转发请求。即负载均衡是由服务端实现的。 Ribbon本地负载均衡,在调用微服务接口时候,会在注册中心上获取注册信息服务列表之后缓存到JVM本地,从而在本地实现RPC远程服务调用技术。 Ribbon在工作时分成两步第一步先选择 Eurekaserver,它优先选择在同一个区域内负载较少的server。第二步再根据用户指定的策略，在从server取到的服务注册列表中选择一个地址。其中Ribbon提供了多种策略:比如轮询、随机和根据响应时间加权。 上面在eureka时，确实实现了负载均衡机制，那是因为 eureka-client包里面自带着ribbon： 一句话，Ribbon 就是 负载均衡 + RestTemplate 调用。实际上不止eureka的jar包有，zookeeper的jar包，还有consul的jar包都包含了他，就是上面使用的服务调用。 如果自己添加，在 模块的 pom 文件中引入： &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;/dependency&gt; 对于RestTemplate 的一些说明： 有两种请求方式：post和get ,还有两种返回类型：object 和 Entity 例如getForObject返回对象为响应体中数据转化为的对象，基本上可以理解为JsongetForEntity返回对象为ResponseEntity对象，包含了响应中的一些重要信息，比如响应头、响应状态码、响应体等 RestTemplate 的 ForEntity 相比 ForObject特殊的地方: 就是 如果使用 ForObject 得到的就是提供者返回的对象，而如果要使用 ForEntity 得到时 ResponstEntity对象，使用getBody()才能得到提供者返回的数据。 负载均衡Ribbon 负载均衡规则类型： com.netflix.loadbalancer.RoundRobinRule: 轮询 com.netflix.loadbalancer.RandomRule: 随机 com.netflix.loadbalancer.RetryRule: 先按照RoundRobinRule的策略获取服务,如果获取服务失败则在指定时间内会进行重试,获取可用的服务 WeightedResponseTimeRule: 对RoundRobinRule的扩展,响应速度越快的实例选择权重越大,越容易被选择 BestAvailableRule: 先过滤掉由于多次访问故障而处于断路器跳闻状态的服务,然后选择一个并发量最小的服务 AvailabilityFilteringRule: 先过滤掉故障实例,再选择并发较小的实例 ZoneAvoidanceRule: 默认规则,复合判断server所在区域的性能和server的可用性选择服务器 配置负载均衡规则： 官方文档明确给出了警告: 这个自定义配置类不能放在@ComponentScan所扫描的当前包下以及子包下,&nbsp; 否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享,达不到特殊化定制的目的了。 注意上面说的，而Springboot主启动类上的 @SpringBootApplication 注解，相当于加了@ComponentScan注解，会自动扫描当前包及子包，所以注意不要放在SpringBoot主启动类的包内。 创建包： 在这个包下新建 MySelfRule类： package com.xhc.myrule; import com.netflix.loadbalancer.IRule; import com.netflix.loadbalancer.RandomRule; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; /** * @author xhc * @date 2021/3/1 10:04 */ @Configuration public class MySelfRule { @Bean public IRule myRule(){ return new RandomRule();//负载均衡规则定义为随机 } } 然后在主启动类上添加如下注解 @RibbonClient： package com.xhc.springcloud; import com.dkf.myrule.MySelfRule; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; import org.springframework.cloud.netflix.eureka.EnableEurekaClient; import org.springframework.cloud.netflix.ribbon.RibbonClient; @SpringBootApplication @EnableEurekaClient @EnableDiscoveryClient //指定该负载均衡规则对哪个提供者服务使用 加载自定义规则的配置类 @RibbonClient(name=\"CLOUD-PROVIDER-SERVICE\", configuration = MySelfRule.class) public class OrderMain80 { public static void main(String[] args){ SpringApplication.run(OrderMain80.class, args); } } 轮询算法原理负载均衡算法:rest接口第几次请求数 % 服务器集群总数量=实际调用服务器位置下标,毎次服务重启动后rest接口计数从1开始。 List&lt;ServiceInstance&gt; instances= discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); 如： List[0] instances = 127.0.0.1:8002List[1] instances = 127.0.0.1:8001 8001+8002组合成为集群,它们共计2台机器,集群总数为2,按照轮询算法原理： 当总请求数为1时:1 % 2 = 1对应下标位置为1,则获得服务地址为127.0.0.1:8001 当总请求数位2时:2 % 2 = 0对应下标位置为0,则获得服务地址为127.0.0.1:8002 当总请求数位3时:3 % 2 = 1对应下标位置为1,则获得服务地址为127.0.0.1:8001 当总请求数位4时:4 % 2 = 0对应下标位置为0,则获得服务地址为127.0.0.1:8002 如此类推…. ribbon部分源码 private int incrementAndGetModulo(int modulo) { int current; int next; do { current = this.nextServerCyclicCounter.get(); next = (current + 1) % modulo; } while(!this.nextServerCyclicCounter.compareAndSet(current, next)); return next; } 手写一个负载的算法:CAS+自旋锁 首先8001、8002服务controller层加上 @GetMapping(\"/payment/lb\") public String getPaymentLB() { return SERVER_PORT; } LoadBalancer接口: package com.xhc.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import java.util.List; public interface LoadBalancer { ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances); } 实现类： package com.xhc.springcloud.lb; import org.springframework.cloud.client.ServiceInstance; import org.springframework.stereotype.Component; import java.util.List; import java.util.concurrent.atomic.AtomicInteger; /** * @author xhc * @date 2021/3/1 11:13 */ @Component public class MyLB implements LoadBalancer{ private AtomicInteger atomicInteger = new AtomicInteger(0); public final int getAndIncrement(){ int current; int next; do{ current=this.atomicInteger.get(); next = current &gt;= 2147483647 ? 0 : current+1; }while (!this.atomicInteger.compareAndSet(current,next)); System.out.println(\"*******第几次访问，次数next:\"+next); return next; } @Override public ServiceInstance instances(List&lt;ServiceInstance&gt; serviceInstances) { int index = getAndIncrement() % serviceInstances.size(); return serviceInstances.get(index); } } controller类中添加: @GetMapping(\"/consumer/payment/lb\") public String getPaymentLB(){ List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\"); if(instances == null || instances.size() &lt;=0){ return null; } ServiceInstance serviceInstance=loadBalancer.instances(instances); URI uri = serviceInstance.getUri(); return restTemplate.getForObject(uri+\"/payment/lb\",String.class); } OpenFeign概述 这里和之前学的dubbo很像，例如消费者的controller 可以调用提供者的 service层方法，但是不一样，它貌似只能调用提供者的 controller，即写一个提供者项目的controller的接口，消费者来调用这个接口方法，就还是相当于是调用提供者的 controller ，和RestTemplate 没有本质区别。 Feign能干什么Feign旨在使编写Java Http客户端变得更容易。前面在使用Ribbon+RestTemplate时,利用RestTemplate对http请求的封装处理,形成了一套模版化的调用方法。但是在实际开发中,由于对服务依赖的调用可能不止一处,往往一个接口会被多处调用,所以通常都会针对每个微服务自行封装珰客户端类来包装这些依赖服务的调用.所以,Feign在此基础上做了进一步封装,由他来帮助我们定义和实现依赖服务接口的定义。在Feigη的实现下,我们只需创建一个接口并使用注解的方式来配置它(以前是Dao接口上面标注Mappe注解，现在是一个微服务接口上面标注一个Feign注解即可),即可完成对服务提供方的接口绑定,简化了使用 Spring cloud Ribbon时,自动封装服务调用客户端的开发量。 Feign集成了Ribbon利用Ribbon维护了Payment的服务列表信息,并且通过轮询实现了客户端的负载均衡。而与Ribbon不同的是,通过feign只需要定义服务绑定接口且以声明式的方法,优雅而简单的实现了服务调用. 使用 新建一个消费者募模块。feign自带负载均衡配置，所以不用手动配置 pom ： &lt;dependencies&gt; &lt;!--OpenFeign--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类： @SpringBootApplication @EnableFeignClients //关键注解 public class CustomerFeignMain80 { public static void main(String[] args) { SpringApplication.run(CustomerFeignMain80.class, args); } } 新建一个service 这个service还是 customer 模块的接口，和提供者没有任何关系，不需要包类名一致。它使用起来就相当于是普通的service。 大致原理，对于这个service 接口，读取它某个方法的注解（GET或者POST注解不写报错），知道了请求方式和请求地址，而抽象方法，只是对于我们来讲，调用该方法时，可以进行传参等。 @Component @FeignClient(value = \"CLOUD-PROVIDER-SERVICE\") //服务名称，要和eureka上面的一致才行 public interface PaymentFeignService { //这个就是provider 的controller层的方法定义。 @GetMapping(value = \"/payment/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\")Long id); } Controller层： //使用起来就相当于是普通的service。 @RestController public class CustomerFeignController { @Resource private PaymentFeignService paymentFeignService; @GetMapping(\"customer/feign/payment/{id}\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\") Long id){ return paymentFeignService.getPaymentById(id); } } 超时控制首先来模拟feign超时 service层加上： @GetMapping(\"/payment/feign/timeout\") public String paymentFeignTimeOut(); Controller层加上： @GetMapping(\"/consumer/payment/feign/timeout\") public String paymentFeignTimeOut(){ //openFeign-ribbon,客户端默认等待一秒 return paymentFeignService.paymentFeignTimeOut(); } 测试出现访问超时错误，原因是，feign客户端默认超时时间是1秒，超时就出现异常。 解决办法：yml配置中添加 Openfeign日志增强openfeign提供了日志打印功能。 Logger有四种类型：NONE(默认)、BASIC、HEADERS、FULL，通过注册Bean来设置日志记录级别 首先写一个config配置类： @Configuration public class FeignConfig { @Bean Logger.Level feignLoggerLevel(){ // 请求和响应的头信息,请求和响应的正文及元数据 return Logger.Level.FULL; } } 然后在yml文件中开启日志打印配置： logging: level: #feign日志以什么级别监控哪个接口 com.xhc.springcloud.service.PaymentFeignService: debug","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：服务注册中心之Zookeeper&Consul","slug":"cloud3","date":"2021-02-28T13:50:08.000Z","updated":"2022-04-18T12:48:45.695Z","comments":true,"path":"posts/2672e38f.html","link":"","permalink":"http://mjean.life/posts/2672e38f.html","excerpt":"","text":"服务注册中心Zookeeper springCloud 整合 zookeeper zookeeper是一个分布式协调工具，可以实现中心功能 测试时先关闭linux服务器防火墙后再启动zookeeper服务器 zookeeper服务器取代Eureka服务器，zookeeper作为服务中心 提供者 创建一个提供者，和之前的一样即可，使用 8004端口 pom文件如下： &lt;artifactId&gt;cloud-provider-payment8004&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot整合zookeeper客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!--先排除自带的zookeeper3.5.3--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--添加zookeeper3.4.9版本--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类： import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.cloud.client.discovery.EnableDiscoveryClient; @SpringBootApplication @EnableDiscoveryClient public class PaymentMain8004 { public static void main(String[] args){ SpringApplication.run(PaymentMain8004.class, args); } } Controller 打印信息： @RestController @Slf4j public class PaymentController { @Resource private PaymentService paymentService; @Value(\"${server.port}\") private String serverPort; @RequestMapping(\"/payment/zk\") public String paymentzk(){ return \"springcloud with zookeeper :\" + serverPort + \"\\t\" + UUID.randomUUID().toString(); } } 如果 zookeeper 的版本和导入的jar包版本不一致，启动就会报错，由jar包冲突的问题。 解决这种冲突，需要在 pom 文件中，排除掉引起冲突的jar包，添加和服务器zookeeper版本一致的 jar 包， 但是新导入的 zookeeper jar包 又有 slf4j 冲突问题，于是再次排除引起冲突的jar包 &lt;!--springcloud 整合 zookeeper 组件--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zookeeper-discovery&lt;/artifactId&gt; &lt;!-- 排除与zookeeper版本不一致到导致 冲突的 jar包 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!-- 添加对应版本的jar包 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.9&lt;/version&gt; &lt;!-- 排除和 slf4j 冲突的 jar包 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; yml文件： server: port: 8004 spring: application: name: cloud-provider-service cloud: zookeeper: connect-string: 192.168.40.100:2181 启动测试： 消费者 创建测试zookeeper作为服务注册中心的 消费者 模块 cloud-customerzk-order80 主启动类、pom文件、yml文件和提供者的类似 config类，注入 RestTemplate @SpringBootConfiguration public class ApplicationContextConfig { @Bean @LoadBalanced public RestTemplate getTemplate(){ return new RestTemplate(); } } controller层也是和之前类似： @RestController @Slf4j public class CustomerZkController { public static final String INVOKE_URL=\"http://cloud-provider-service\"; @Resource private RestTemplate restTemplate; @RequestMapping(\"/customer/payment/zk\") public String paymentInfo(){ String result = restTemplate.getForObject(INVOKE_URL + \"/payment/zk\",String.class); return result; } } 关于 zookeeper 的集群搭建，目前使用较少，而且在 yml 文件中的配置也是类似，以列表形式写入 zookeeper 的多个地址即可，而且zookeeper 集群，在 hadoop的笔记中也有记录。总而言之，只要配合zookeeper集群，以及yml文件的配置就能完成集群搭建,。 问题:zookeeper中的节点是持久还是临时的？ 答：临时的。 Consul Consul是什么 Consul是一个服务网格（微服务间的 TCP/IP，负责服务之间的网络调用、限流、熔断和监控）解决方案，它是一个一个分布式的，高度可用的系统，而且开发使用都很简便。它提供了一个功能齐全的控制平面，主要特点是：服务发现、健康检查、键值存储、安全服务通信、多数据中心。 与其它分布式服务注册与发现的方案相比，Consul 的方案更“一站式”——内置了服务注册与发现框架、分布一致性协议实现、健康检查、Key/Value 存储、多数据中心方案，不再需要依赖其它工具。Consul 本身使用 go 语言开发，具有跨平台、运行高效等特点，也非常方便和 Docker 配合使用。 官网地址： https://www.consul.io/intro 中文地址： https://www.springcloud.cc/spring-cloud-consul.html 安装并运行 下载地址：https://www.consul.io/downloads.html 打开下载的压缩包，只有一个exe文件，实际上是不用安装的，在exe文件所在目录打开dos窗口使用即可。 使用开发模式启动：consul agent -dev 访问8500端口，即可访问首页 提供者 新建提供者模块：cloud-providerconsul-payment8006 pom 文件： &lt;artifactId&gt;cloud-providerconsul-payment8006&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--springcloud consul server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-consul-discovery&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; yml 文件： server: port: 8006 spring: application: name: consul-provider-payment cloud: consul: host: localhost port: 8500 discovery: # 指定注册对外暴露的服务名称 service-name: ${spring.application.name} 主启动类： @SpringBootApplication @EnableDiscoveryClient public class PaymentMain8006 { public static void main(String[] args) { SpringApplication.run(PaymentMain8006.class,args); } } controller也是简单 controller层： @RestController @Slf4j public class PaymentController { @Value(\"${server.port}\") private String serverPort; @RequestMapping(\"/payment/consul\") public String paymentConsul(){ return \"springcloud with consul: \"+serverPort+\"\\t\"+ UUID.randomUUID().toString(); } } 消费者 新建 一个 在80端口的 消费者模块。pom和yml和提供者的类似，主启动类不用说，记得注入RestTemplate controller层： @RestController @Slf4j public class OrderConsulController { public static final String INVOKE_URL=\"http://consul-provider-payment\"; @Resource private RestTemplate restTemplate; @GetMapping(\"/consumer/payment/consul\") public String paymentInfo(){ String result=restTemplate.getForObject(INVOKE_URL+\"/payment/consul\",String.class); return result; } } 总结Eureka、Zookeeper、Consul三个注册中心的异同点 组件名 语言 健康检查 对外暴露接口 CAP Spring Cloud 集成 Eureka Java 可配支持 HTTP AP 集成 Consul Go 支持 HTTP/DFS CP 集成 Zookeeper java 支持 客户端 CP 集成 CAP C:Consistency (强一致性) A:Availability (可用性) P:Partition tolerance (分区容错性) CAP理论关注粒度是数据，而不是整体系统设计的。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：服务注册中心之Eureka","slug":"cloud2","date":"2021-02-28T02:51:44.000Z","updated":"2022-04-18T12:48:45.781Z","comments":true,"path":"posts/2d6777ae.html","link":"","permalink":"http://mjean.life/posts/2d6777ae.html","excerpt":"","text":"服务注册中心 如果是像之前只有两个微服务，通过 RestTemplate ，是可以相互调用的，但是当微服务项目的数量增大，就需要服务注册中心。目前没有学习服务调用相关技术，所以使用 SpringCloud 自带的 RestTemplate 来实现RPC。 Eureka 官方停更不停用，以后可能用的越来越少。 概念和理论 它是用来服务治理，以及服务注册和发现，服务注册如下图： Eureka采用了CS的设计构, Eureka Servert 作为服务注册功能的服务器,它是服务注册中心、而系统中的其他微服务,使用 Eureka的客户端连接到 Eureka Serve并维持心跳连接.这样系统的维护人员就可以通过 Eureka Server 来监控系统中各个微服务是否正第运行。(这点和zookeeper很相似)在服务注册与发现中,有一个注册中心。当服务器启动的时候,会把当前自己服务器的信息 比如 服务地址通讯地址等以別名方式注册到注册中心上。另一方(消费者服务提供者),以该别名的方式去注册中心上获取到实际的服务通讯地址,然后再实现本地RPC调用，RPC远程调用框架核心设计思想在于注册中心,因为使用注册中心管理每个服务与服务之间的个依赖关系(服务治理概念)。在任何RPC远程框架中,都会有一个注册中心(存放服务地址相关信息(接口地址)) Eureka包含两个组件: Eureka Server和 Eureka Client Eureka Serve提供服务注册服务各个微服务节点通过配置启动后,会在 EurekaServer中进行注册,这样EurekaServerl中的服务注册表中将会存储所有可用服务节点信息,服务节点的信息可以在界面中直观看到。 EurekaClient通过注册中心进行访问是个Java客户端,用于简化 Eureka Server的交互,客户端同时也具备个内置的、使用轮迿 (round-robin)负载算法的负载均衡器在应用启动后,将会向 Eureka Server发送心跳(默认周期为30秒)。如果 Eureka Server在多个心跳周期内没有接收到某个节点的心跳, EurekaServer将会从服务注册表中把这个服务节点移除(默认90秒) 版本说明： 1.X和2.X的对比说明 以前的老版本(当前使用2018) &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; 现在新版本(当前使用2020.2) &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; 原理说明： 服务注册：将服务信息注册到注册中心 服务发现：从注册中心获取服务信息 实质：存key服务名，取value调用地址 步骤： 先启动eureka注册中心 启动服务提供者payment支付服务 支付服务启动后，会把自身信息注册到eureka 消费者order服务在需要调用接口时，使用服务别名去注册中心获取实际的远程调用地址 消费者获得调用地址后，底层实际是调用httpclient技术实现远程调用 消费者获得服务地址后会缓存在本地jvm中，默认每30秒更新异常服务调用地址 Server模块 server 模块使用 7001端口，下面是pom文件需要的依赖： &lt;artifactId&gt;cloud-eureka-server7001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--引入自己定义的api通用包，可以使用Payment支付Entity--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--boot web actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 下面配置 yml 文件： server: port: 7001 eureka: instance: hostname: localhost # eureka 服务器的实例名称 client: # false 代表不向服务注册中心注册自己，因为它本身就是服务中心 register-with-eureka: false # false 代表自己就是服务注册中心，自己的作用就是维护服务实例，并不需要去检索服务 fetch-registry: false service-url: # 设置与 Eureka Server 交互的地址，查询服务 和 注册服务都依赖这个地址 defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/ 最后写主启动类，如果启动报错，说没有配置 DataSource ，就在 主启动类的注解加上 这样的配置： // exclude ：启动时不启用 DataSource的自动配置检查 @SpringBootApplication(exclude = DataSourceAutoConfiguration.class) @EnableEurekaServer // 表示它是服务注册中心 public class EurekaServerMain7001 { public static void main(String[] args){ SpringApplication.run(EurekaServerMain7001.class, args); } } 启动测试，访问 7001 端口 提供者 这里的提供者，还是使用 之前的 cloud-provider-payment8001 模块，做如下修改： 在 pom 文件的基础上引入 eureka 的client包，pom 的全部依赖如下所示： &lt;artifactId&gt;cloud-provider-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql-connector-java--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 加上注解 ： @EnableEurekaClient yml 文件添加关于 Eureka 的配置： eureka: client: # 注册进 Eureka 的服务中心 register-with-eureka: true # 检索 服务中心 的其它服务 fetch-registry: true service-url: # 设置与 Eureka Server 交互的地址 defaultZone: http://localhost:7001/eureka/ 应用名称： 消费者 这里的消费者 也是之前 的 cloud-customer-order80 模块 修改 pom 文件，加入Eureka 的有关依赖， 全部 pom 依赖如下： &lt;artifactId&gt;cloud-customer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 主启动类 加上注解 ： @EnableEurekaClient yml 文件必须添加的内容： eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://localhost:7001/eureka/ spring: application: name: cloud-order-service 问题：微服务RPC远程调用最核心的是说明？ 高可用，如果注册中心只有一个，出现故障就麻烦了。会导致整个服务环境不可用。 解决办法：搭建eureka注册中心集群，实现负载均衡+故障容错 Eureka 集群 Eureka 集群的原理就是 相互注册，互相守望 模拟多个 Eureka Server 在不同机器上 ： 进入C:\\Windows\\System32\\drivers\\etc\\hosts 末尾添加： 127.0.0.1 eureka7001.com 127.0.0.1 eureka7002.com 现在创建 cloud-eureka-server7002 ，也就是第二个 Eureka 服务注册中心，pom 文件和 主启动类，与第一个Server一致。 现在修改这两个 Server 的 yml 配置： 7001 端口的Server yml文件： server: port: 7001 eureka: instance: hostname: eureka7001.com # eureka 服务器的实例地址 client: register-with-eureka: false fetch-registry: false service-url: ## 一定要注意这里的地址，这是搭建集群的关键 defaultZone: http://eureka7002.com:7002/eureka/ 7002 端口的Server yml文件： server: port: 7002 eureka: instance: hostname: eureka7002.com # eureka 服务器的实例地址 client: register-with-eureka: false fetch-registry: false service-url: ## 一定要注意这里的地址 这是搭建集群的关键 defaultZone: http://eureka7001.com:7001/eureka/ eureka.instance.hostname 才是启动以后 本 Server 的注册地址，而 service-url 是 map 类型，只要保证 key:value 格式就行，它代表 本Server 指向了那些 其它Server 。利用这个，就可以实现Eureka Server 相互之间的注册，从而实现集群的搭建。 EurekaServer集群效果 将 提供者 和 消费者 注册进两个Eureka Server 中，下面是 消费者和提供者的 yml 文件关于Eureka的配置： eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 从这里可以看出，也可以使用列表形式进行Server之间的关联注册。 提供者集群 为提供者，即 cloud-provider-payment8001 模块创建集群，新建模块为 cloud-provider-payment8002 最终实现： 注意在 Controller 返回不同的消息，从而区分者两个提供者的工作状态。 其余配置都一致，需要配置集群的配置如下： 配置区别：只要保证消费者项目对服务注册中心提供的名称一致，即完成集群。 server: port: 8001 # 端口号不一样 spring: application: name: cloud-provider-service # 这次重点是这里，两个要写的一样，这是这个集群的关键 datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/cloud2020?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.dkf.springcloud.entities eureka: client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/ 消费者的配置 就是消费者如何访问 由这两个提供者组成的集群？ Eureka Server 上的提供者的服务名称如下： @RestController @Slf4j public class OrderController { // 重点是这里，改成 提供者在Eureka 上的名称，而且无需写端口号 public static final String PAYMENY_URL = \"http://CLOUD-PROVIDER-SERVICE\"; @Resource private RestTemplate restTemplate; @PostMapping(\"customer/payment/create\") public CommonResult&lt;Payment&gt; create (Payment payment){ return restTemplate.postForObject(PAYMENY_URL + \"/payment/create\", payment, CommonResult.class); } @GetMapping(\"customer/payment/{id}\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\")Long id){ return restTemplate.getForObject(PAYMENY_URL + \"/payment/\" + id, CommonResult.class); } } 测试之后会出现以下报错信息： There was an unexpected error (type=Internal Server Error, status=500). I/O error on GET request for \"http://CLOUD-PAYMENT-SERVICE/payment/get/1\": CLOUD-PAYMENT-SERVICE; nested exception is java.net.UnknownHostException: CLOUD-PAYMENT-SERVICE org.springframework.web.client.ResourceAccessException: I/O error on GET request for \"http://CLOUD-PAYMENT-SERVICE/payment/get/1\": CLOUD-PAYMENT-SERVICE; nested exception is java.net.UnknownHostException: CLOUD-PAYMENT-SERVICE 原因是，我们配置了以服务名的方式访问，但不能确定是哪一个服务。 我们需要给restTemplate开启负载均衡，默认是轮循。 对RestTemplate配置的config文件，需要更改成如下：（就是加一个注解 @LoadBalanced） package com.dkf.springcloud.config; import org.springframework.cloud.client.loadbalancer.LoadBalanced; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; @Configuration public class ApplicationContextConfig { @Bean @LoadBalanced //这个注解，就赋予了RestTemplate 负载均衡的能力 public RestTemplate getRestTemplate(){ return new RestTemplate(); } } 测试，完成！ actuator信息配置修改 在Eureka 注册中心显示的 主机名： 显示微服务所在 的主机地址： 服务发现Discovery 对于注册进eureka里面的微服务，可以通过服务发现来获得该服务的信息 在主启动类上添加注解：@EnableDiscoveryClient 在 Controller 里面打印信息： @Resource private DiscoveryClient discoveryClient; @GetMapping(\"/customer/discovery\") public Object discovery(){ List&lt;String&gt; services = discoveryClient.getServices(); for(String service: services){ log.info(\"*****service: \" + service); } List&lt;ServiceInstance&gt; instances = discoveryClient.getInstances(\"CLOUD-ORDER-SERVICE\"); for(ServiceInstance serviceInstance:instances){ log.info(serviceInstance.getServiceId() + \"\\t\" + serviceInstance.getHost() + \"\\t\" + serviceInstance.getPort() + \"\\t\" + serviceInstance.getUri()); } return this.discoveryClient; } Eureka 自我保护机制 一句话:某时刻某一个微服务不可用了, Eureka不会立刻清理,依旧会对该微服务的信息进行保存，属于CAP里面的AP分支。 概述保护模式主要用于一组客户端和 Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式,Eureka Server将会尝试保护其服务注册表中的信息,下不再删服务注册表中的数据,也就是不会注销任何微服务。 如果在 Eureka Server的首页看到以下这段提示,则说明 Eureka进入了保护模式:EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE. 为什么会产生Eeka自我保护机制?为了防止 Eurekaclient可以正常运行,但是与 Eurekaserver网络不通情况下, EurekaServer不会立刻EurekaClient服务剔除 什么是自我保护模式?默认情况下,如果 EurekaServer在一定时间内没有接收到某个微服务实例的心跳,EurekaServer将会注销该实例(默认90秒)。但是当网络分区故障发生烻时、卡顿、拥挤)时,微服务与 Eurekaserver之间无法正常通信,以上行为可能变得非常危险了——因为微服务本身其实是健康的,此时本不应该注销这个微服务。 Eureka通过“自我保扩模式”来解决这个问题——当 EurekaServer节点在短时间内丟失过多客户端时(可能发生了网络分区故障),那么这个节点就会进入自我保护模式。 如何禁止自我保护机制: 在 Eureka Server 的模块中的 yml 文件进行配置： 修改 Eureka Client 模块的 心跳间隔时间：","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"SpringCloud笔记：工程建造","slug":"cloud1","date":"2021-02-26T14:51:13.000Z","updated":"2022-04-18T12:48:45.777Z","comments":true,"path":"posts/fb0b2c40.html","link":"","permalink":"http://mjean.life/posts/fb0b2c40.html","excerpt":"","text":"前言​ 本次学习是从周阳老师的SpringCloud(H版&amp;alibaba)框架开发教程中进行的，一步一步跟着老师来，将目前学习的笔记整理，供自己日后的复习。 什么是微服务架构： SpringCloud 是微服务一站式服务解决方案，微服务全家桶。它是微服务开发的主流技术栈。它采用了名称，而非数字版本号。 springCloud 和 springCloud Alibaba 目前是最主流的微服务框架组合。 版本选择： SpringBoot 2.0版和SpringCloud H版 强烈建议使用SpringBoot 2.0以上 SpringBoot和SpringCloud之间版本有约束 H版对应2.2 G版对应2.1 课程版本约束: cloud:Hoxton.SR1 boot:2.2.2.RELEASE cloud alibaba:2.1.0.RELEASE java：java8 Maven 3.5以上 Mysql:5.7以上 工程建造构建父工程，后面的项目模块都在此工程中： 设置编码：Settings -&gt; File Encodings 注解激活： Java版本确定： 父工程pom配置&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud2020&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--第一步--&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;cloud-provider-payment8001&lt;/module&gt; &lt;module&gt;cloud-consumer-order80&lt;/module&gt; &lt;module&gt;cloud-api-commons&lt;/module&gt; &lt;module&gt;cloud-eureka-server7001&lt;/module&gt; &lt;module&gt;cloud-eureka-server7002&lt;/module&gt; &lt;/modules&gt; &lt;!--统一管理jar包版本--&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;lombok.version&gt;1.16.18&lt;/lombok.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.16&lt;/druid.version&gt; &lt;mybatis.spring.boot.version&gt;1.3.0&lt;/mybatis.spring.boot.version&gt; &lt;/properties&gt; &lt;!--子模块继承之后，提供作用：锁定版本+子module不用写groupId和version--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-project-info-reports-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring boot 2.2.2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud Hoxton.SR1--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR1&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring cloud 阿里巴巴--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--mysql--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;${mysql.version}&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- druid--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;${druid.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${mybatis.spring.boot.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;${junit.version}&lt;/version&gt; &lt;/dependency&gt; &lt;!--log4j--&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;${log4j.version}&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 上面配置的解释： 首先要加 pom 这个。 聚合版本依赖，dependencyManagement 只声明依赖，并不实现引入，所以子项目还需要写要引入的依赖。 如果不在子项目中声明依赖,是不会从父项目中继承下来的;只有在子项目中写了该依赖项,井且没有指定具体版本オ会从父项目中继承该项,并且 version和 scoper都读取自父pom；如果子项目中指定了版本号,那么会使用子项目中指定的jar版本。 dependencyManagement: Maven使用 dependencyManagement元素来提供了一种管理依赖版本号的方式。通常会在一个组织或者项目的最顶层的父POM中看到 dependencyManagement元素。 使用pom.xml中的 dependencyManagement元素能让所有在子项目中引用个依赖而不用显式的列出版本号。Maven会沿着父子层次向上走,直到找到个拥有 dependencyManagement元素的项目,然后它就会使用这个dependencyManagement元素中指定的版本号。 例如在父项目里:xml代码 &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.2&lt;/version&gt; ... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; 然后在子项目里就可以在添加 mysql-connector时可以不指定版本号,例如: xml代码 &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 这样做的好处就是:如果有多个子项目都引用同样依赖,则可以避免在每个使用的子项目里都声明一个版本号,这样当想升级或切换到另一个版本时，只需要在父项目中修改即可。 第一个微服务架构 建模块 module 改 pom 写yml 主启动 业务类 提供者cloud-provider-payment8001 子工程的pom文件： 这里面的 lombok 这个包，引入以后，实体类不用再写set 和 get 可以如下写实体类： package com.xhc.springcloud.entities; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; /** * @author xhc * @date 2021/2/25 17:06 */ @Data @AllArgsConstructor @NoArgsConstructor public class Payment { private long id; private String serial; } &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020&lt;/artifactId&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-provider-payment8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql-connector-java--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jdbc--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; cloud-provider-payment8001 子工程的yml文件： server: port: 8001 spring: application: name: cloud-payment-service datasource: type: com.alibaba.druid.pool.DruidDataSource #当前数据源操作类型 driver-class-name: com.mysql.jdbc.Driver #mysql驱动包 url: jdbc:mysql://localhost:3306/db2020?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false username: root password: 123456 mybatis: mapper-locations: classpath:mapper/*.xml type-aliases-package: com.xhc.springcloud.entities # 所有entity别名类所在包 cloud-provider-payment8001 子工程的主启动类： package com.xhc.springcloud; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class PaymentMain8001 { public static void main(String[] args){ SpringApplication.run(PaymentMain8001.class, args); } } 下面的常规操作： 1.建表SQL2.entities3.dao4.service5.controller 建表SQL： CREATE TABLE `payment` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'ID', `serial` varchar(200) COLLATE utf8_unicode_ci DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8 COLLATE=utf8_unicode_ci; dao层开发 新建PaymentDao接口 package com.xhc.springcloud.dao; import com.xhc.springcloud.entities.Payment; import org.apache.ibatis.annotations.Mapper; import org.apache.ibatis.annotations.Param; /** * @author xhc */ @Mapper public interface PaymentDao { public int create(Payment payment); public Payment getPaymentById(@Param(\"id\")Long id); } mapper.xml resource下创建mapper文件夹，新建PaymentMapper.xml &lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt; &lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.xhc.springcloud.dao.PaymentDao\"&gt; &lt;insert id=\"create\" parameterType=\"Payment\" useGeneratedKeys=\"true\" keyProperty=\"id\"&gt; insert into payment(serial) values(#{serial}); &lt;/insert&gt; &lt;resultMap id=\"BaseResultMap\" type=\"com.xhc.springcloud.entities.Payment\"&gt; &lt;id column=\"id\" property=\"id\" jdbcType=\"INTEGER\"/&gt; &lt;id column=\"serial\" property=\"serial\" jdbcType=\"VARCHAR\"/&gt; &lt;/resultMap&gt; &lt;select id=\"getPaymentById\" parameterType=\"Long\" resultMap=\"BaseResultMap\"&gt; select * from payment where id=#{id}; &lt;/select&gt; &lt;/mapper&gt; Service层 service接口 package com.xhc.springcloud.service; import com.xhc.springcloud.entities.Payment; import org.apache.ibatis.annotations.Param; /** * @author xhc */ public interface PaymentService { public int create(Payment payment); public Payment getPaymentById(@Param(\"id\")Long id); } service实现类 package com.xhc.springcloud.service.impl; import com.xhc.springcloud.dao.PaymentDao; import com.xhc.springcloud.entities.Payment; import com.xhc.springcloud.service.PaymentService; import org.springframework.stereotype.Service; import javax.annotation.Resource; /** * @author xhc * @date 2021/2/24 16:18 */ @Service public class PaymentServiceImpl implements PaymentService{ @Resource private PaymentDao paymentDao; @Override public int create(Payment payment){ return paymentDao.create(payment); } @Override public Payment getPaymentById(Long id){ return paymentDao.getPaymentById(id); } } 下面记录一个特殊的Entity类，和Controller CommonResult: package com.xhc.springcloud.entities; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; /** * 如果前后端分离，这个是提供给前端信息和数据的类 * @param &lt;T&gt; */ @Data @AllArgsConstructor @NoArgsConstructor public class CommonResult&lt;T&gt; { private Integer code; private String messgae; private T data; /** * 查询为空的时候使用的构造器 * @param code * @param messgae */ public CommonResult(Integer code, String messgae){ this(code, messgae, null); } } Controller： package com.xhc.springcloud.controller; import com.dkf.springcloud.entities.CommonResult; import com.dkf.springcloud.entities.Payment; import com.dkf.springcloud.service.PaymentService; import lombok.extern.slf4j.Slf4j; import org.springframework.web.bind.annotation.*; import javax.annotation.Resource; @RestController //必须是这个注解，因为是模拟前后端分离的restful风格的请求，要求每个方法返回 json @Slf4j public class PaymentController { @Resource private PaymentService paymentService; @PostMapping(value = \"/payment/create\") // 注意这里的 @RequestBody 是必须要写的，虽然 MVC可以自动封装参数成为对象， // 但是当消费者项目调用，它传参是 payment 整个实例对象传过来的， 即Json数据，因此需要写这个注解 public CommonResult create(@RequestBody Payment payment){ int result = paymentService.create(payment); log.info(\"****插入结果：\" + result); if(result &gt; 0){ return new CommonResult(200, \"插入数据库成功\", result); } return new CommonResult(444, \"插入数据库失败\", null); } @GetMapping(value = \"/payment/{id}\") public CommonResult getPaymentById(@PathVariable(\"id\")Long id){ Payment result = paymentService.getPaymentById(id); log.info(\"****查询结果：\" + result); if(result != null){ return new CommonResult(200, \"查询成功\", result); } return new CommonResult(444, \"没有对应id的记录\", null); } } 测试： get测试：浏览器输入：http://浏览器输入：http://localhost:8001/payment/get/31 结果： post测试：使用postman工具 热部署配置 具体模块里添加Jar包到工程中，上面的pom文件已经添加上了 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 添加plus到父工程的pom文件中：上面也已经添加好了 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;addResources&gt;true&lt;/addResources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; ​ 3. ​ 4.shift + ctrl + alt + / 四个按键一块按，选择Reg项： 消费者 消费者现在只模拟调用提供者的Controller方法，没有持久层配置，只有Controller和实体类 当然也要配置主启动类和启动端口 pom文件： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020&lt;/artifactId&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-consumer-order80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-client--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 把CommonResult 和 Payment 两个 实体类也创建出来。 RestTemplate RestTemplate提供了多种便捷访问远程Http服务的方法，是一种简单便捷的访问restful服务的模板类，是spring提供的用于访问Rest服务的客户端模板工具集。 配置类 ApplicationContextConfig 内容： package com.xhc.springcloud.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.web.client.RestTemplate; /** * @author xhc * @date 2021/2/25 17:21 */ @Configuration public class ApplicationContextConfig { @Bean public RestTemplate getRestTemplate(){ return new RestTemplate(); } } Controller ： package com.dkf.springcloud.controller; import com.dkf.springcloud.entities.CommonResult; import com.dkf.springcloud.entities.Payment; import lombok.extern.slf4j.Slf4j; import org.springframework.stereotype.Controller; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.PathVariable; import org.springframework.web.bind.annotation.PostMapping; import org.springframework.web.bind.annotation.RestController; import org.springframework.web.client.RestTemplate; import javax.annotation.Resource; @RestController @Slf4j public class OrderController { //远程调用的 地址 public static final String PAYMENY_URL = \"http://localhost:8001\"; @Resource private RestTemplate restTemplate; @PostMapping(\"customer/payment/create\") public CommonResult&lt;Payment&gt; create (Payment payment){ /** param1 请求地址，param2 请求参数， param3 返回类型 */ return restTemplate.postForObject(PAYMENY_URL + \"/payment/create\", payment, CommonResult.class); } @GetMapping(\"customer/payment/{id}\") public CommonResult&lt;Payment&gt; getPaymentById(@PathVariable(\"id\")Long id){ return restTemplate.getForObject(PAYMENY_URL + \"/payment/\" + id, CommonResult.class); } } RunDashBroad 运用spring cloud框架基于springboot构建微服务，一般需要启动多个应用程序，在idea开发工具中，多个同时启动的应用，需要在RunDashBoard运行仪表盘中可以更好的管理，但有时候idea中的RunDashBoard窗口没有显示出来，也找不到直接的开启按钮。 idea中打开Run Dashboard的方法如下 view &gt; Tool Windows &gt; Run Dashboard 如果上述列表找不到Run Dashboard,则可以在工程目录下找到.idea文件夹下的workspace.xml，在其中相应位置加入以下代码（替换）即可： &lt;component name=\"RunDashboard\"&gt; &lt;option name=\"configurationTypes\"&gt; &lt;set&gt; &lt;option value=\"SpringBootApplicationConfigurationType\"/&gt; &lt;/set&gt; &lt;/option&gt; &lt;option name=\"ruleStates\"&gt; &lt;list&gt; &lt;RuleState&gt; &lt;option name=\"name\" value=\"ConfigurationTypeDashboardGroupingRule\"/&gt; &lt;/RuleState&gt; &lt;RuleState&gt; &lt;option name=\"name\" value=\"StatusDashboardGroupingRule\"/&gt; &lt;/RuleState&gt; &lt;/list&gt; &lt;/option&gt; &lt;/component&gt; 关闭重启后出现。 工程重构 上面 两个子项目，有多次重复的 导入 jar，和重复的 Entity 实体类。可以把 多余的部分，加入到一个独立的模块中，将这个模块打包，并提供给需要使用的 module 新建一个 cloud-api-commons 子模块 将 entities 包里面的实体类放到这个子模块中，也将 pom 文件中，重复导入的 jar包放到这个新建的 模块的 pom 文件中。如下： &lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;cloud2020&lt;/artifactId&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.1.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/project&gt; 将此项目打包 install 到 maven仓库。 将 提供者 和 消费者 两个项目中的 entities 包删除，并删除掉加入到 cloud-api-commons 模块的 依赖配置。 将 打包到 maven 仓库的 cloud-api-commons 模块，引入到 提供者 和 消费者的 pom 文件中，如下所示 &lt;dependency&gt;&lt;!--引入自己定义的api通用包，可以使用Payment 支付 Entity--&gt; &lt;groupId&gt;com.xhc.springcloud&lt;/groupId&gt; &lt;artifactId&gt;cloud-api-commons&lt;/artifactId&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;/dependency&gt; 完成！","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"}]},{"title":"Vue笔记：实战练习","slug":"vue12","date":"2021-02-19T13:11:00.000Z","updated":"2022-04-18T12:48:45.768Z","comments":true,"path":"posts/115a7514.html","link":"","permalink":"http://mjean.life/posts/115a7514.html","excerpt":"","text":"实战练习通过结合 ElementUI 组件库，将所需知识点应用到实际中，加深对 Vue 的使用; 建立工程注意： 命令行都要使用管理员模式运行 一、建立一个名为 hello-vue 的工程 vue init webpack hello-vue二、安装依赖，需要安装 vue-router、element-ui、sass-loader 和 node-sass 四个插件 # 进入工程目录 cd hello-vue # 安装 vue-router npm install vue-router --save-dev # 安装 element-ui npm i element-ui -S # 安装依赖 npm install # 安装 SASS 加载器 cnpm install sass-loader node-sass --save-dev # 启动测试 npm run dev 三、Npm命令解释： npm install moduleName：安装模块到项目目录下 npm install -g moduleName：-g 的意思是将模块安装到全局，具体安装到磁盘哪一个位置，要看 npm config prefix 的位置 npm install -save moduleName：–save 的意思是将模块安装到项目目录下，并在 package 文件的 dependencies 节点写入依赖，-S 为该命令的缩写 npm install -save-dev moduleName：–save-dev 的意思是将模块安装到项目目录下，并在 package 文件的 devDependencies 节点写入依赖，-D 为该命令的缩写 建立登陆页面把没有用的初始化东西删掉！ 在源码目录中建立以下结构： assets：用于存放资源文件 components：用于存放 Vue 功能组件 views：用于存放 Vue 视图组件 router：用于存放 vue-router 配置 建立首页视图，在 views 目录下建立一个名为 Main.vue 的视图组件； &lt;template&gt; &lt;div&gt; 首页 &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"Main\" } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt; 建立登陆页视图在 views 目录下建立一个名为 Login.vue 的视图组件，其中 el-* 的元素为 ElementUI 组件； &lt;template&gt; &lt;div&gt; &lt;el-form ref=\"loginForm\" :model=\"form\" :rules=\"rules\" label-width=\"80px\" class=\"login-box\"&gt; &lt;h3 class=\"login-title\"&gt;欢迎登陆&lt;/h3&gt; &lt;el-form-item label=\"帐号\" prop=\"username\"&gt; &lt;el-input type=\"text\" placeholder=\"请输入帐号\" v-model=\"form.username\"/&gt; &lt;/el-form-item&gt; &lt;el-form-item label=\"密码\" prop=\"password\"&gt; &lt;el-input type=\"password\" placeholder=\"请输入密码\" v-model=\"form.password\"/&gt; &lt;/el-form-item&gt; &lt;el-form-item&gt; &lt;el-button type=\"primary\" v-on:click=\"onSubmit('loginForm')\"&gt;登陆&lt;/el-button&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;el-dialog title=\"舒适提示\" :visible.sync=\"dialogVisible\" width=\"30%\" :before-close=\"handleClose\"&gt; &lt;span&gt;请输入帐号和密码&lt;/span&gt; &lt;span slot=\"footer\" class=\"dialog-footer\"&gt; &lt;el-button type=\"primary\" @click=\"dialogVisible = false\"&gt;确 定&lt;/el-button&gt; &lt;/span&gt; &lt;/el-dialog&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"Login\", data() { return { form: { username: '', password: '' }, // 表单验证，须要在 el-form-item 元素中增长 prop 属性 rules: { username: [ {required: true, message: '帐号不可为空', trigger: 'blur'} ], password: [ {required: true, message: '密码不可为空', trigger: 'blur'} ] }, // 对话框显示和隐藏 dialogVisible: false } }, methods: { onSubmit(formName) { // 为表单绑定验证功能 this.$refs[formName].validate((valid) =&gt; { if (valid) { // 使用 vue-router 路由到指定页面，该方式称之为编程式导航 this.$router.push(\"/main\"); } else { this.dialogVisible = true; return false; } }); } } } &lt;/script&gt; &lt;style lang=\"scss\" scoped&gt; .login-box { border: 1px solid #DCDFE6; width: 350px; margin: 180px auto; padding: 35px 35px 15px 35px; border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; box-shadow: 0 0 25px #909399; } .login-title { text-align: center; margin: 0 auto 40px auto; color: #303133; } &lt;/style&gt; 建立路由,在 router 目录下建立一个名为 index.js 的 vue-router 路由配置文件 import Vue from 'vue' import Router from 'vue-router' import Login from \"../views/Login\" import Main from '../views/Main' Vue.use(Router); export default new Router({ routes: [ { // 登陆页 path: '/login', name: 'Login', component: Login }, { // 首页 path: '/main', name: 'Main', component: Main } ] }); 配置路由，修改入口代码，修改 main.js 入口代码 import Vue from 'vue' import VueRouter from 'vue-router' import router from './router' // 导入 ElementUI import ElementUI from 'element-ui' import 'element-ui/lib/theme-chalk/index.css' import App from './App' // 安装路由 Vue.use(VueRouter); // 安装 ElementUI Vue.use(ElementUI); new Vue({ el: '#app', // 启用路由 router, // 启用 ElementUI render: h =&gt; h(App) }); 修改 App.vue 组件代码 &lt;template&gt; &lt;div id=\"app\"&gt; &lt;router-view/&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'App', } &lt;/script&gt; 测试 ： 在浏览器打开 http://localhost:8080/#/login 若是出现错误: 多是由于sass-loader的版本太高致使的编译错误，须要退回到7.3.1 ； 去package.json文件里面的 “sass-loader”的版本更换成7.3.1，而后重新cnpm install就能够使用了； 路由嵌套嵌套路由又称子路由，在实际应用中，一般由多层嵌套的组件组合而成。一样地，URL 中各段动态路径也按某种结构对应嵌套的各层组件，例如： /user/foo/profile /user/foo/posts +------------------+ +-----------------+ | User | | User | | +--------------+ | | +-------------+ | | | Profile | | +------------&gt; | | Posts | | | | | | | | | | | +--------------+ | | +-------------+ | +------------------+ +-----------------+ 一、用户信息组件，在 views/user 目录下建立一个名为 Profile.vue 的视图组件； &lt;template&gt; &lt;div&gt; 我的信息 &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"UserProfile\" } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt; 二、用户列表组件在 views/user 目录下建立一个名为 List.vue 的视图组件； &lt;template&gt; &lt;div&gt; 用户列表 &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"UserList\" } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt; 三、配置嵌套路由修改 router 目录下的 index.js 路由配置文件，代码如下： import Vue from 'vue' import Router from 'vue-router' import Login from \"../views/Login\" import Main from '../views/Main' // 用于嵌套的路由组件 import UserProfile from '../views/user/Profile' import UserList from '../views/user/List' Vue.use(Router); export default new Router({ routes: [ { // 登陆页 path: '/login', name: 'Login', component: Login }, { // 首页 path: '/main', name: 'Main', component: Main, // 配置嵌套路由 children: [ {path: '/user/profile', component: UserProfile}, {path: '/user/list', component: UserList}, ] } ] }); 说明：主要在路由配置中增加了 children 数组配置，用于在该组件下设置嵌套路由 四、修改首页视图，修改 Main.vue 视图组件，此处使用了 ElementUI 布局容器组件，代码如下： &lt;template&gt; &lt;div&gt; &lt;el-container&gt; &lt;el-aside width=\"200px\"&gt; &lt;el-menu :default-openeds=\"['1']\"&gt; &lt;el-submenu index=\"1\"&gt; &lt;template slot=\"title\"&gt;&lt;i class=\"el-icon-caret-right\"&gt;&lt;/i&gt;用户管理&lt;/template&gt; &lt;el-menu-item-group&gt; &lt;el-menu-item index=\"1-1\"&gt; &lt;router-link to=\"/user/profile\"&gt;我的信息&lt;/router-link&gt; &lt;/el-menu-item&gt; &lt;el-menu-item index=\"1-2\"&gt; &lt;router-link to=\"/user/list\"&gt;用户列表&lt;/router-link&gt; &lt;/el-menu-item&gt; &lt;/el-menu-item-group&gt; &lt;/el-submenu&gt; &lt;el-submenu index=\"2\"&gt; &lt;template slot=\"title\"&gt;&lt;i class=\"el-icon-caret-right\"&gt;&lt;/i&gt;内容管理&lt;/template&gt; &lt;el-menu-item-group&gt; &lt;el-menu-item index=\"2-1\"&gt;分类管理&lt;/el-menu-item&gt; &lt;el-menu-item index=\"2-2\"&gt;内容列表&lt;/el-menu-item&gt; &lt;/el-menu-item-group&gt; &lt;/el-submenu&gt; &lt;/el-menu&gt; &lt;/el-aside&gt; &lt;el-container&gt; &lt;el-header style=\"text-align: right; font-size: 12px\"&gt; &lt;el-dropdown&gt; &lt;i class=\"el-icon-setting\" style=\"margin-right: 15px\"&gt;&lt;/i&gt; &lt;el-dropdown-menu slot=\"dropdown\"&gt; &lt;el-dropdown-item&gt;我的信息&lt;/el-dropdown-item&gt; &lt;el-dropdown-item&gt;退出登陆&lt;/el-dropdown-item&gt; &lt;/el-dropdown-menu&gt; &lt;/el-dropdown&gt; &lt;/el-header&gt; &lt;el-main&gt; &lt;router-view /&gt; &lt;/el-main&gt; &lt;/el-container&gt; &lt;/el-container&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"Main\" } &lt;/script&gt; &lt;style scoped lang=\"scss\"&gt; .el-header { background-color: #B3C0D1; color: #333; line-height: 60px; } .el-aside { color: #333; } &lt;/style&gt; 说明： 在 元素中配置了 用于展现嵌套路由,主要使用 我的信息 展现嵌套路由内容 参数传递通常需要把某种模式匹配到的全部路由，全都映射到同个组件。例如，有一个 User 组件，对于全部 ID 各不相同的用户，都要使用这个组件来渲染。此时就需要传递参数了； 一、修改路由配置, 主要是在 path 属性中增加了 :id 这样的占位符 {path: '/user/profile/:id', name:'UserProfile', component: UserProfile} 二、传递参数 此时将 to 改成了 :to，是为了将这一属性当成对象使用，注意 router-link 中的 name 属性名称 必定要和 路由中的 name 属性名称 匹配，由于这样 Vue 才能找到对应的路由路径； &lt;router-link :to=\"{name: 'UserProfile', params: {id: 1}}\"&gt;我的信息&lt;/router-link&gt; 三、接收参数, 在目标组件中 {{ $route.params.id }} 使用 props 的方式一、修改路由配置 , 主要增加了 props: true 属性 {path: '/user/profile/:id', name:'UserProfile', component: UserProfile, props: true} 二、传递参数和以前同样三、接收参数为目标组件增长 props 属性 &lt;template&gt; &lt;div&gt; 我的信息 {{ id }} &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { props: ['id'], name: \"UserProfile\" } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt; 组件重定向Vue 中的重定向是作用在路径不一样但组件相同的状况下，好比： { path: '/main', name: 'Main', component: Main }, { path: '/goHome', redirect: '/main' } 说明：这里定义了两个路径，一个是 /main ，一个是 /goHome，其中 /goHome 重定向到了 /main 路径，由此能够看出重定向不须要定义组件； 使用的话，只须要设置对应路径便可； &lt;el-menu-item index=\"1-3\"&gt; &lt;router-link to=\"/goHome\"&gt;回到首页&lt;/router-link&gt; &lt;/el-menu-item&gt; 路由模式与 404路由模式有两种 hash：路径带 # 符号，如 http://localhost/#/login history：路径不带 # 符号，如 http://localhost/login 修改路由配置，代码以下： export default new Router({ mode: 'history', routes: [ ] }); 处理 404 建立一个名为 NotFound.vue 的视图组件，代码以下： &lt;template&gt; &lt;div&gt; 页面不存在，请重试！ &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"NotFount\" } &lt;/script&gt; &lt;style scoped&gt; &lt;/style&gt; 修改路由配置，代码以下： import NotFound from '../views/NotFound' { path: '*', component: NotFound } 路由钩子与异步请求beforeRouteEnter：在进入路由前执行beforeRouteLeave：在离开路由前执行 代码： export default { props: ['id'], name: \"UserProfile\", beforeRouteEnter: (to, from, next) =&gt; { console.log(\"准备进入我的信息页\"); next(); }, beforeRouteLeave: (to, from, next) =&gt; { console.log(\"准备离开我的信息页\"); next(); } } 参数说明： to：路由将要跳转的路径信息 from：路径跳转前的路径信息 next：路由的控制参数 next() 跳入下一个页面 next(’/path’) 改变路由的跳转方向，使其跳到另外一个路由 next(false) 返回原来的页面 next((vm)=&gt;{}) 仅在 beforeRouteEnter 中可用，vm 是组件实例 在钩子函数中使用异步请求 一、安装 Axios cnpm install --save vue-axios二、main.js引用 Axios import axios from 'axios' import VueAxios from 'vue-axios' Vue.use(VueAxios, axios) 三、准备数据 ： 只有在 static 目录下的文件是能够被访问到的，所以把静态文件放入该目录下。 // 静态数据存放的位置 static/mock/data.json 四、在 beforeRouteEnter 中进行异步请求 export default { props: ['id'], name: \"UserProfile\", beforeRouteEnter: (to, from, next) =&gt; { console.log(\"准备进入我的信息页\"); // 注意，必定要在 next 中请求，由于该方法调用时 Vue 实例尚未建立，此时没法获取到 this 对象，在这里使用官方提供的回调函数拿到当前实例 next(vm =&gt; { vm.getData(); }); }, beforeRouteLeave: (to, from, next) =&gt; { console.log(\"准备离开我的信息页\"); next(); }, methods: { getData: function () { this.axios({ method: 'get', url: 'http://localhost:8080/static/mock/data.json' }).then(function (repos) { console.log(repos); }).catch(function (error) { console.log(error); }); } } }","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：vue-router路由","slug":"vue11","date":"2021-02-09T12:33:27.000Z","updated":"2022-04-18T12:48:45.765Z","comments":true,"path":"posts/b72a857c.html","link":"","permalink":"http://mjean.life/posts/b72a857c.html","excerpt":"","text":"vue-router路由Vue Router 是 Vue.js 官方的路由管理器。它和 Vue.js 的核心深度集成，让构建单页面应用变得易如反掌。包含的功能有： 嵌套的路由/视图表 模块化的、基于组件的路由配置 路由参数、查询、通配符 基于 Vue.js 过渡系统的视图过渡效果 细粒度的导航控制 带有自动激活的 CSS class 的连接 HTML5 历史模式或 hash 模式，在 IE9 中自动降级 自定义的滚动条行为 安装基于第一个vue-cli进行测试学习;先查看node_modules中是否存在 vue-router vue-router 是一个插件包，因此咱们仍是须要用 npm/cnpm 来进行安装的。打开命令行工具，进入你的项目目录，输入下面命令。 npm install vue-router --save-dev 若是在一个模块化工程中使用它，必需要经过 Vue.use() 明确地安装路由功能： import Vue from 'vue' import VueRouter from 'vue-router' Vue.use(VueRouter); 测试一、先删除没有用的东西二、components目录下存放自己编写的组件三、定义一个Content.vue 的组件 &lt;template&gt; &lt;div&gt; &lt;h1&gt;内容页&lt;/h1&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: \"Content\" } &lt;/script&gt; 四、 安装路由,在src目录下,新建一个文件夹 : router,专门存放路由 import Vue from 'vue' // 导入路由插件 import Router from 'vue-router' // 导入上面定义的组件 import Content from '../components/Content' import main from '../components/main' // 安装路由 Vue.use(Router); // 配置路由 export default new Router({ routes: [ { // 路由路径 path: '/content', // 路由名称 name: 'Content', // 跳转到组件 component: Content }, { // 路由路径 path: '/main', // 路由名称 name: 'main', // 跳转到组件 component: main } ] }); 五、在main.js 中配置路由 import Vue from 'vue' import App from './App' // 导入上面建立的路由配置目录 import router from './router' //来关闭生产模式下给出的提示 Vue.config.productionTip = false; new Vue({ el: '#app', // 配置路由 router, components: { App }, template: '&lt;App/&gt;' }); 六、在App.vue中使用路由 &lt;template&gt; &lt;div id=\"app\"&gt; &lt;!-- router-link： 默认会被渲染成一个 &lt;a&gt; 标签，to 属性为指定连接 router-view： 用于渲染路由匹配到的组件 --&gt; &lt;router-link to=\"/\"&gt;首页&lt;/router-link&gt; &lt;router-link to=\"/content\"&gt;内容&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; export default { name: 'App' } &lt;/script&gt; &lt;style&gt; #app { font-family: 'Avenir', Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } &lt;/style&gt; 启动测试一下 ： npm run dev","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：Webpack","slug":"vue10","date":"2021-02-09T12:32:01.000Z","updated":"2022-04-18T12:48:45.750Z","comments":true,"path":"posts/53d4ec0e.html","link":"","permalink":"http://mjean.life/posts/53d4ec0e.html","excerpt":"","text":"WebpackWebPack 是一款模块加载器兼打包工具，它能把各类资源，如 JS、JSX、ES6、SASS、LESS、图片等都做为模块来处理和使用。 安装:npm install webpack -g npm install webpack-cli -g 测试安装成功: webpack -v webpack-cli -v 配置建立 webpack.config.js 配置文件 entry：入口文件，指定 WebPack 用哪一个文件做为项目的入口 output：输出，指定 WebPack 把处理完成的文件放置到指定路径 module：模块，用于处理各类类型的文件 plugins：插件，如：热更新、代码重用等 resolve：设置路径指向 watch：监听，用于设置文件改动后直接打包 module.exports = { entry: \"\", output: { path: \"\", filename: \"\" }, module: { loaders: [ {test: /\\.js$/, loader: \"\"} ] }, plugins: {}, resolve: {}, watch: true } 直接运行 webpack 命令打包 使用webpack 建立项目 建立一个名为 modules 的目录，用于放置 JS 模块等资源文件 在modules下建立模块文件，如 hello.js，用于编写 JS 模块相关代码 //暴露一个方法:sayHi exports.sayHi = function () { document.write(\"&lt;div&gt;Hello WebPack&lt;/div&gt;\"); }; 在modules下建立一个名为 main.js 的入口文件，用于打包时设置 entry 属性 //require 导入一个模块,就能够调用这个模块中的方法了 var hello = require(\"./hello\"); hello.sayHi(); 在项目目录下建立 webpack.config.js 配置文件，使用 webpack 命令打包 module.exports = { entry: \"./modules/main.js\", output: { filename: \"./js/bundle.js\" } }; 在项目目录下建立 HTML 页面，如 index.html，导入 WebPack 打包后的 JS 文件 &lt;!doctype html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;xhc&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;script src=\"dist/js/bundle.js\"&gt;&lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 在IDEA控制台中直接执行webpack;若是失败的话,就使用管理员权限运行便可! 运行 HTML 看效果 说明: # 参数 --watch 用于监听变化 webpack --watch","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：vue-cli","slug":"vue09","date":"2021-02-09T12:30:05.000Z","updated":"2022-04-18T12:48:45.749Z","comments":true,"path":"posts/d89d7e5f.html","link":"","permalink":"http://mjean.life/posts/d89d7e5f.html","excerpt":"","text":"vue-cli vue-cli 官方提供的一个脚手架,用于快速生成一个 vue 的项目模板; 有着预先定义好的目录结构及基础代码，就好比在创建 Maven 项目时可以选择模板创建一个骨架项目，这个骨架项目就是脚手架,使我们的开发更加的快速;主要的功能: 统一的目录结构 本地调试 热部署 单元测试 集成打包上线 需要的环境 Node.js : http://nodejs.cn/download/ 安装就无脑下一步就好,安装在自己的环境目录下 Git : https://git-scm.com/downloads镜像:https://npm.taobao.org/mirrors/git-for-windows/ 确认nodejs安装成功: cmd 下输入 node -v,查看是否能够正确打印出版本号即可! cmd 下输入 npm -v,查看是否能够正确打印出版本号即可! 这个npm,就是一个软件包管理工具,就和linux下的apt软件安装差不多!安装 Node.js 淘宝镜像加速器（cnpm）这样子的话,下载会快很多 # -g 就是全局安装 npm install cnpm -g # 或使用如下语句解决 npm 速度慢的问题 npm install --registry=https://registry.npm.taobao.org 安装 vue-cli#在命令台输入 cnpm install vue-cli -g #查看是否安装成功 vue list 1234 第一个 vue-cli 应用程序 建立一个Vue项目,可以在电脑上随便创建一个空的文件夹,我这里在D盘下新建一个目录E:\\IdeaProjects\\vue; 建立一个基于 webpack 模板的 vue 应用程序 # 这里的 myvue 是项目名称，能够根据本身的需求起名 vue init webpack myvue 一路都选择no便可; 说明: Project name：项目名称，默认 回车 便可 Project description：项目描述，默认 回车 便可 Author：项目做者，默认 回车 便可 Install vue-router：是否安装 vue-router，选择 n 不安装（后期须要再手动添加） Use ESLint to lint your code：是否使用 ESLint 作代码检查，选择 n 不安装（后期须要再手动添加） Set up unit tests：单元测试相关，选择 n 不安装（后期须要再手动添加） Setup e2e tests with Nightwatch：单元测试相关，选择 n 不安装（后期须要再手动添加） Should we run npm install for you after the project has been created：建立完成后直接初始化，选择 n，咱们手动执行;运行结果! 初始化并运行cd myvue npm install npm run dev 安装并运行成功后在浏览器输入：http://localhost:8080 即可 Vue-cli目录结构用IDEA,open刚才的项目! build 和 config：WebPack 配置文件 node_modules：用于存放 npm install 安装的依赖文件 src： 项目源码目录 static：静态资源文件 .babelrc：Babel 配置文件，主要做用是将 ES6 转换为 ES5 .editorconfig：编辑器配置 eslintignore：须要忽略的语法检查配置文件 .gitignore：git 忽略的配置文件 .postcssrc.js：css 相关配置文件，其中内部的 module.exports 是 NodeJS 模块化语法 index.html：首页，仅做为模板页，实际开发时不使用 package.json：项目的配置文件 name：项目名称 version：项目版本 description：项目描述 author：项目做者 scripts：封装经常使用命令 dependencies：生产环境依赖 devDependencies：开发环境依赖 src 目录src 目录是项目的源码目录，全部代码都会写在这里 main.js项目的入口文件，咱们知道全部的程序都会有一个入口 // The Vue build version to load with the `import` command // (runtime-only or standalone) has been set in webpack.base.conf with an alias. import Vue from 'vue' import App from './App' Vue.config.productionTip = false; /* eslint-disable no-new */ new Vue({ el: '#app', components: { App }, template: '&lt;App/&gt;' }); import Vue from 'vue'：ES6 写法，会被转换成 require(“vue”); （require 是 NodeJS 提供的模块加载器） import App from './App'：意思同上，可是指定了查找路径，./ 为当前目录 Vue.config.productionTip = false：关闭浏览器控制台关于环境的相关提示 new Vue({...})：实例化 Vue el: '#app'：查找 index.html 中 id 为 app 的元素 template: '&lt;App/&gt;'：模板，会将 index.html 中 components: { App }：引入组件，使用的是 import App from ‘./App’ 定义的 App 组件; App.vue&lt;template&gt; &lt;div id=\"app\"&gt; &lt;img src=\"./assets/logo.png\"&gt; &lt;HelloWorld/&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import HelloWorld from './components/HelloWorld' export default { name: 'App', components: { HelloWorld } } &lt;/script&gt; &lt;style&gt; #app { font-family: 'Avenir', Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; -moz-osx-font-smoothing: grayscale; text-align: center; color: #2c3e50; margin-top: 60px; } &lt;/style&gt; template：HTML 代码模板，会替换 中的内容 import HelloWorld from ‘./components/HelloWorld’：引入 HelloWorld 组件，用于替换 template 中的 export default{…}：导出 NodeJS 对象，做用是能够经过 import 关键字导入 name: ‘App’：定义组件的名称 components: { HelloWorld }：定义子组件","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：内容分发、自定义事件","slug":"vue08","date":"2021-02-08T12:48:19.000Z","updated":"2022-04-18T12:48:45.746Z","comments":true,"path":"posts/1af7d7d7.html","link":"","permalink":"http://mjean.life/posts/1af7d7d7.html","excerpt":"","text":"内容分发 在Vue.js中我们使用 元素作为承载分发内容的出口，作者称其为插槽，可以应用在组合组件的场景中;代码demo9 插槽理解练习 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;todo&gt; &lt;todo-title slot=\"todo-title\" :title=\"title\"&gt;&lt;/todo-title&gt; &lt;todo-items slot=\"todo-item\" v-for=\"item in todoItems\" :item=\"item\"&gt;&lt;/todo-items&gt; &lt;/todo&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; //slot：插槽 Vue.component(\"todo\",{ template: '&lt;div&gt;\\ &lt;slot name=\"todo-title\"&gt;&lt;/slot&gt;\\ &lt;ul&gt;\\ &lt;slot name=\"todo-item\"&gt;&lt;/slot&gt;\\ &lt;/ul&gt;\\ &lt;/div&gt;' }); Vue.component(\"todo-title\",{ props: ['title'], template: '&lt;div&gt;{{title}}&lt;/div&gt;' }); Vue.component(\"todo-items\",{ props: ['item'], template: '&lt;li&gt;{{item}}&lt;/li&gt;' }); var vm = new Vue({ el:\"#app\", data: { title: '列表', todoItems: ['java','python','mysql'] } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 自定义事件 通过以上代码不难发现，数据项在Vue的实例中，但删除操作要在组件中完成，那么组件如何才能删除Vue实例中的数据呢?此时就涉及到参数传递与事件分发了，Vue为我们提供了自定义事件的功能很好的帮助我们解决了这个问题;使用this.$emit(‘自定义事件名’,参数) 图解 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;todo&gt; &lt;todo-title slot=\"todo-title\" :title=\"title\"&gt;&lt;/todo-title&gt; &lt;todo-items slot=\"todo-item\" v-for=\"(item,index) in todoItems\" :item=\"item\" v-bind:index=\"index\" v-on:remove=\"removeItems(index)\" :key=\"index\"&gt;&lt;/todo-items&gt; &lt;/todo&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; //slot：插槽 Vue.component(\"todo\",{ template: '&lt;div&gt;\\ &lt;slot name=\"todo-title\"&gt;&lt;/slot&gt;\\ &lt;ul&gt;\\ &lt;slot name=\"todo-item\"&gt;&lt;/slot&gt;\\ &lt;/ul&gt;\\ &lt;/div&gt;' }); Vue.component(\"todo-title\",{ props: ['title'], template: '&lt;div&gt;{{title}}&lt;/div&gt;' }); Vue.component(\"todo-items\",{ props: ['item','index'], template: '&lt;li&gt;{{index}}---{{item}} &lt;button @click=\"remove\"&gt;删除&lt;/button&gt;&lt;/li&gt;', methods: { remove: function (index) { //this.$emit 自定义事件分发 this.$emit('remove',index); } } }); var vm = new Vue({ el:\"#app\", data: { title: '列表', todoItems: ['java','python','mysql'] }, methods: { removeItems: function (index) { console.log(\"删除了\"+this.todoItems[index]+\"OK\"); this.todoItems.splice(index,1);//一次删除一个元素 } } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：计算属性","slug":"vue07","date":"2021-02-08T12:46:02.000Z","updated":"2022-04-18T12:48:45.718Z","comments":true,"path":"posts/fe4858ab.html","link":"","permalink":"http://mjean.life/posts/fe4858ab.html","excerpt":"","text":"什么是计算属性？ 从字面上看，计算属性是计算（动词）+属性（名词）组成的，不过计算属性的重点是在属性上，即说明它是个属性并且这个属性是有计算能力的，这里的计算就是个函数;简单点说，它就是一个能够将计算结果缓存起来的属性(将行为转化成了静态的属性);可以拿缓存来参考!代码 demo8.html 理解计算属性 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;p&gt;currentTime1 {{currentTime1()}}&lt;/p&gt; &lt;p&gt;currentTime2 {{currentTime2}}&lt;/p&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el:\"#app\", data: { message: \"hello\" }, methods: { currentTime1 :function () { return Date.now(); //返回一个时间戳 } }, computed: { //计算属性： methods，computed 方法名不能重名，重名之后，只会调用methods的方法 currentTime2 :function () { this.message; return Date.now(); //返回一个时间戳 } } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 注意：methods 和 computed 里的东西不能重名 说明： methods：定义方法，调用方法使用 currentTime1()，须要带括号 computed：定义计算属性，调用属性使用 currentTime2，不须要带括号；this.message 是为了可以让 currentTime2 观察到数据变化而变化 如何在方法中的值发生了变化，则缓存就会刷新！能够在控制台使用 vm.message=\"xhc\",改变下数据的值，再次测试观察效果！ 结论: 在调用方法时，每次都需要进行计算，而有计算过程则必定会产生系统开销，所以如果这个结果是不经常变化的，那么就可以考虑将这个结果缓存起来，采用计算属性就可以很方便的做到这一点,计算属性的主要特性就是为了将不经常变化的计算结果进行缓存，以节约我们的系统开销;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：Axios异步通信","slug":"vue06","date":"2021-02-08T12:40:20.000Z","updated":"2022-04-18T12:48:45.715Z","comments":true,"path":"posts/cc04742d.html","link":"","permalink":"http://mjean.life/posts/cc04742d.html","excerpt":"","text":"Axios异步通信(通信框架) Axios是一个开源的可以用在浏览器端和NodeJS 的异步通信框架，她的主要作用就是实现AJAX异步通信，其功能特点如下:●从浏览器中创建XMLHttpRequests●从node.js创建http请求●支持Promise API [JS中链式编程]●拦截请求和响应●转换请求数据和响应数据●取消请求●自动转换JSON数据●客户端支持防御XSRF (跨站请求伪造) GitHub: https://github.com/axios/axios中文文档: http://www.axios-js.com/ 为什么要使用Axios由于Vue.js是一个视图层框架且作者(尤雨溪) 严格准守SoC (关注度分离原则)，所以Vue.js并不包含AJAX的通信功能，为了解决通信问题，作者单独开发了一个名为vue-resource的插件，不过在进入2.0 版本以后停止了对该插件的维护并推荐了Axios 框架。少用jQuery，因为它操作Dom太频繁! Vue的生命周期 官方文档: https://cn.vuejs.org/v2/guide/instance.html#生命周期图示 Vue实例有一个完整的生命周期，也就是从开始创建、初始化数据、编译模板、挂载DOM、渲染→更新→渲染、卸载等一系列过程，我们称这是Vue的生命周期。通俗说就是Vue实例从创建到销毁的过程，就是生命周期。在Vue的整个生命周期中，它提供了一系列的事件，可以让我们在事件触发时注册JS方法,可以让我们用自己注册的JS方法控制整个大局，在这些事件响应方法中的this直接指向的是Vue的实例。 代码 初探axios先建立一个data.json { \"name\": \"java\", \"url\": \"http://blog.mjean.space/\", \"page\": 1, \"isNonProfit\": true, \"address\": { \"street\": \"普宁\", \"city\": \"揭阳\", \"country\": \"中国\" }, \"links\": [ { \"name\": \"aaaa\", \"url\": \"www.baidu.com\" }, { \"name\": \"bbbb\", \"url\": \"www.bilibili.com\" }, { \"name\": \"cccc\", \"url\": \"www.7k7k.com\" } ] } 测试 demo7.html &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;!--解决闪烁问题--&gt; &lt;style&gt; [v-clock]{ display: none; } &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"vue\" v-clock&gt; &lt;div&gt;{{info.name}}&lt;/div&gt; &lt;div&gt;{{info.address.street}}&lt;/div&gt; &lt;a v-bind:href=\"info.url\"&gt;点我&lt;/a&gt; &lt;/div&gt; &lt;!--引入JS文件--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt; &lt;script src=\"https://unpkg.com/axios/dist/axios.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; var vm = new Vue({ el: '#vue', //data: 属性 //data()方法 data(){ return{ info: { name: null, address: { street: null, city: null, country: null }, url: null } } }, mounted(){//钩子函数 链式编程 axios.get('../data.json').then(response=&gt;(this.info=response.data)); } }) &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 说明: 在这里使用了 v-bind 将 a:href 的属性值与 Vue 实例中的数据进行绑定 使用 axios 框架的 get 方法请求 AJAX 并自动将数据封装进了 Vue 实例的数据对象中 咱们在data中的数据结构必需要和Ajax响应回来的数据格式匹配！","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：组件","slug":"vue05","date":"2021-02-08T12:27:45.000Z","updated":"2022-04-18T12:48:45.697Z","comments":true,"path":"posts/c07a99f4.html","link":"","permalink":"http://mjean.life/posts/c07a99f4.html","excerpt":"","text":"第一个Vue组件什么是组件 组件是可复用的Vue实例，说白了就是一组可以重复使用的模板，跟JSTL的自定义标签、Thymeleaf的th:fragment 等框架有着异曲同工之妙。通常一个应用会以一棵嵌套的组件树的形式来组织: 注意:在实际开发中，我们并不会用以下方式开发组件，而是采用vue-cli创建.vue模板文件的方式开发，以下方法只是为了让大家理解什么是组件。 组件树 Vue.component()方法注册组件 &lt;script type=\"text/javascript\"&gt; // 先注册组件 Vue.component('my-component-li', { template: '&lt;li&gt;Hello li&lt;/li&gt;' }); // 再实例化 Vue var vm = new Vue({ el: '#vue' }); &lt;/script&gt; &lt;div id=\"vue\"&gt; &lt;ul&gt; &lt;my-component-li&gt;&lt;/my-component-li&gt; &lt;/ul&gt; &lt;/div&gt; 说明： Vue.component()：注册组件 my-component-li：自定义组件的名字 template：组件的模板 使用 props 属性传递参数 像上面那样用组件没有任何意义，因此咱们是须要传递参数到组件的，此时就须要使用 props 属性了！ 注意：默认规则下 props 属性里的值不能为大写； 代码 demo6.html 组件练习 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;!--组件:传递给组件中的值：props--&gt; &lt;xhc v-for=\"item in items\" v-bind:xx=\"item\"&gt;&lt;/xhc&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; //定义一个Vue组件 component Vue.component(\"xhc\",{ props: ['xx'], //接收参数 template: '&lt;li&gt;{{xx}}&lt;/li&gt;' }); var vm = new Vue({ el:\"#app\", data: { items: [\"java\",\"python\"] } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 说明： v-for=\"item in items\"：遍历 Vue 实例中定义的名为 items 的数组，并建立同等数量的组件 v-bind:item=\"item\"：将遍历的 item 项绑定到组件中 props 定义的名为 item 属性上；= 号左边的 item 为 props 定义的属性名，右边的为 item in items 中遍历的 item 项的值","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：双向数据绑定","slug":"vue04","date":"2021-02-08T12:23:35.000Z","updated":"2022-04-18T12:48:45.774Z","comments":true,"path":"posts/ff7abace.html","link":"","permalink":"http://mjean.life/posts/ff7abace.html","excerpt":"","text":"什么是双向数据绑定？​ Vue.js是一个MVVM框架，即数据双向绑定,即当数据发生变化的时候,视图也就发生变化，当视图发生变化的时候，数据也会跟着同步变化。 值得注意的是，我们所说的数据双向绑定，一定是对于UI控件来说的，非UI控件不会涉及到数据双向绑定。单向数据绑定是使用状态管理工具的前提。如果我们使用vuex，那么数据流也是单项的，这时就会和双向数据绑定有冲突。 为什么要实现数据的双向绑定 在Vue.js 中，如果使用vuex ，实际上数据还是单向的，之所以说是数据双向绑定，这是用的UI控件来说，对于我们处理表单，Vue.js的双向数据绑定用起来就特别舒服了。即两者并不互斥，在全局性数据流使用单项,方便跟踪;局部性数据流使用双向，简单易操作。 在表单中使用双向数据绑定 你可以用v-model 指令在表单 、 及 元素上创建双向数据绑定。它会根据控件类型自动选取正确的方法来更新元素。尽管有些神奇，但v-model本质上不过是语法糖。它负责监听户的输入事件以更新数据，并对一些极端场景进行一些特殊处理。代码 demo5.html 当输入框输入相应文字 在后面提示框会输入相同文字 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; 输入的文本： &lt;input type=\"text\" v-model=\"message\"&gt;{{message}} &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el:\"#app\", data: { message: \"123\" } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt;","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：基础语法","slug":"vue03","date":"2021-02-07T12:28:39.000Z","updated":"2022-04-18T12:48:45.693Z","comments":true,"path":"posts/90785ea8.html","link":"","permalink":"http://mjean.life/posts/90785ea8.html","excerpt":"","text":"Vue基础语法学习代码 demo2.html if else 语法 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;h1 v-if=\"ok\"&gt;yes&lt;/h1&gt; &lt;h1 v-else&gt;no&lt;/h1&gt; &lt;/div&gt; &lt;div id=\"app2\"&gt; &lt;h1 v-if=\"type==='A'\"&gt;A&lt;/h1&gt; &lt;h1 v-else-if=\"type==='B'\"&gt;B&lt;/h1&gt; &lt;h1 v-else-if=\"type==='D'\"&gt;D&lt;/h1&gt; &lt;h1 v-else&gt;C&lt;/h1&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el: \"#app\", data: { ok: true, } }); var vm2 = new Vue({ el: \"#app2\", data: { type: 'A' } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 代码 demo3.html for循环获取数据 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;li v-for=\"item in items\"&gt; {{item.message}} &lt;/li&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el:\"#app\", data: { items: [ {message: 'java'}, {message: 'python'} ] } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 注：items 是数组，item是数组元素迭代的别名。 代码 demo4.html 事件绑定 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; &lt;button v-on:click=\"sayHi\"&gt;click me&lt;/button&gt; &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el:\"#app\", data: { message: \"java\" }, methods: {// 方法必须定义在Vue的Method对象中 通过v-on来绑定事件 sayHi: function () { alert(this.message); } } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; v-on 监听事件 事件有Vue的事件、和前端页面自己的一些事件！这里的click是vue的事件，能够绑定到Vue中的methods中的方法事件！","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：第一个Vue程序(下)","slug":"vue02","date":"2021-02-07T12:21:41.000Z","updated":"2022-04-18T12:48:45.679Z","comments":true,"path":"posts/4736722.html","link":"","permalink":"http://mjean.life/posts/4736722.html","excerpt":"","text":"第一个Vue程序Vue.js常见的使用方式有： 直接引入，通过script标签引入完整的vue文件 webpack自定义打包 vue-cli脚手架，也是通过webpack进行打包 【说明】IDEA 能够安装 Vue 的插件！ 注意：Vue 不支持 IE8 及如下版本，由于 Vue 使用了 IE8 没法模拟的 ECMAScript 5 特性。但它支持全部兼容 ECMAScript 5 的浏览器。 下载地址 开发版本 包含完整的警告和调试模式：https://vuejs.org/js/vue.js 删除了警告，30.96KB min + gzip：https://vuejs.org/js/vue.min.js CDN &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.js\"&gt;&lt;/script&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; 代码编写 Vue.js 的核心是实现了 MVVM 模式，它扮演的角色就是 ViewModel 层，第一个Vue程序就是来初次体现 数据绑定，操作流程： 一、建立一个 HTML 文件 二、引入 Vue.js &lt;script src=\"https://unpkg.com/vue/dist/vue.js\"&gt;&lt;/script 三、建立一个 Vue 的实例 &lt;script type=\"text/javascript\"&gt; var vm = new Vue({ el: '#vue', data: { message: 'Hello Vue!' } }); &lt;/script&gt; 说明: el:\"#app\"：绑定元素的 ID data:{message: \"hello,vue\"}：数据对象中有一个名为 message 的属性，并设置了初始值 Hello Vue! 四、将数据绑定到页面元素 &lt;div id=\"app\"&gt; {{message}} &lt;/div&gt; 说明：只须要在绑定的元素中使用 双花括号 将 Vue 建立的名为 message 属性包裹起来，便可实现数据绑定功能，也就实现了 ViewModel 层所需的效果 代码 demo1.html 数据绑定 &lt;!DOCTYPE html&gt; &lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;!--view 层 模板--&gt; &lt;div id=\"app\"&gt; {{message}} &lt;/div&gt; &lt;!--1.导入vue.js--&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue@2.5.21/dist/vue.min.js\"&gt;&lt;/script&gt; &lt;script&gt; var vm = new Vue({ el:\"#app\", //Model ： 数据 data:{ message: \"hello,vue!\" } }); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; demo1中的绑定关系，是使用span标签中的v-bind:title属性来声明的。 测试 在浏览器上通过console测试的方式，可以更加清楚的感受数据绑定的功能。操作流程： 一、在浏览器上运行第一个 Vue 应用程序，进入 开发者工具 二、在控制台输入 vm.message = ‘hello,vue’ ，而后 回车，你会发现浏览器中显示的内容会直接变成hello,vue 此时就能够在控制台直接输入 vm.message 来修改值，中间是能够省略 data 的，在这个操做中，我并无主动操做 DOM，就让页面的内容发生了变化，这就是借助了 Vue 的 数据绑定 功能实现的；MVVM 模式中要求 ViewModel 层就是使用 观察者模式 来实现数据的监听与绑定，以作到数据与视图的快速响应。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"Vue笔记：第一个Vue程序(上)","slug":"vue01","date":"2021-02-07T11:42:18.000Z","updated":"2022-04-18T12:48:45.671Z","comments":true,"path":"posts/1d685663.html","link":"","permalink":"http://mjean.life/posts/1d685663.html","excerpt":"","text":"第一个Vue程序Vue Vue (读音/vju/, 类似于view)是一套用于构建用户界面的渐进式框架，发布于2014年2月。与其它大型框架不同的是，Vue被设计为可以自底向上逐层应用。Vue的核心库只关注视图层，不仅易于上手，还便于与第三方库(如: vue-router, vue-resource, vuex)或既有项目整合。 MVVM模式的实现者●Model:模型层，在这里表示JavaScript对象●View:视图层,在这里表示DOM (HTML操作的元素)●ViewModel:连接视图和数据的中间件，Vue.js就是MVVM中的ViewModel层的实现者在MVVM架构中，是不允许数据和视图直接通信的，只能通过ViewModel来通信，而ViewModel就是定义了一个Observer观察者●ViewModel能够观察到数据的变化，并对视图对应的内容进行更新●ViewModel能够监听到视图的变化，并能够通知数据发生改变综上，Vue.js 就是一个MVVM的实现者，他的核心就是实现了DOM监听与数据绑定 为什么要使用Vue.js●轻量级，体积小是一个重要指标。Vue.js 压缩后有只有20多kb (Angular 压缩后56kb+ ,React压缩后44kb+ )●移动优先。更适合移动端，比如移动端的Touch事件●易上手，学习曲线平稳,文档齐全●吸取了Angular (模块化)和React (虚拟DOM)的长处，并拥有自己独特的功能，如:计算属性●开源，社区活跃度高 什么是MVVM？MVVM 是Model-View-ViewModel（模型-视图-视图模型） 的缩写，是一种基于前端开发的架构模式，其核心是提供对View 和 ViewModel 的双向数据绑定，这使得ViewModel 的状态改变可以自动传递给 View，即所谓的数据双向绑定。 Model：代表数据模型，数据和业务逻辑都在Model层中定义 View：代表UI视图，负责数据显示 ViewModel：负责监听Model中数据的改变并且控制视图的更新 它有两个方向：一是将【模型】转化成【视图】，即将后端传递的数据转化成所看到的页面。实现的方式是：数据绑定。二是将【视图】转化成【模型】，即将所看到的页面转化成后端的数据。实现的方式是：DOM 事件监听。 总结： MVVM模式简化了界面与业务的依赖，解决了数据频繁更新。MVVM 在使用当中，利用双向绑定技术，使得 Model 变化时，ViewModel 会自动更新，而 ViewModel 变化时，View 也会自动变化。 为什么要使用MVVM？MVVM模式和MVC模式一样，主要目的是分离视图(View)\\和**模型(Model)**,有几大好处●低耦合:视图(View)可以独立于Model变化和修改,一个ViewModel可以绑定到不同的View上，当View变化的时候Model可以不变，当Model变化的时候View也可以不变。●可复用:你可以把一些视图逻辑放在一个ViewModel里面，让很多View重用这段视图逻辑。●独立开发:开发人员可以专注于业务逻辑和数据的开发(ViewModel),设计人员可以专注于页面设计。●可测试:界面素来是比较难于测试的，而现在测试可以针对ViewModel来写。","categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]},{"title":"第一篇博客，作为自己博客记录的开头吧！","slug":"第一篇博客，作为自己博客记录的开头吧！","date":"2020-12-12T17:27:22.948Z","updated":"2022-04-18T12:48:45.772Z","comments":true,"path":"posts/68923bdb.html","link":"","permalink":"http://mjean.life/posts/68923bdb.html","excerpt":"","text":"前言 从严格意义上来讲呢，这是我的第一篇博客！ 从上大学接触HelloWorld的那一刻开始，就开启了和代码打交到的旅程了；至今天是我在这趟旅途的第两个半的年头，回想起走过的这一段旅途，缺少了奋发向上的风景。一遇到难题就是想着如何去逃避，不敢去面对，松散的过着本该是充满活力的生活；从这一篇博客开始，将踏上新的旅程。 为什么想要写博客 这个想法源于我的室友，我了解到写博客能将自己的所见所想所学，以字面的形式记录下来，可以使现在，更是以后的自己有机会审视到自己的成长，从而从中取得更为长足的进步。好处很多，但是主要的还是： 可以作为一个学习记录很多时候我们花了很多时间找了N多教程才解决一个问题，当时可能对于这个问题已经看的明明白白的了，在接下来的一小段时间遇到同样的问题，还是能够清楚如何去解决的，但是过了很久很久之后再次遇到同样的问题，这时我们就可能会发现这个问题变成了一个全新的问题。写博客可以作为一个学习记录，而且还能用于复习。 促进自己学习当我们开始写博客之后，就会把写一篇有用的博客这件事放在一件比较重要的位置，而写有用博客的前提是有一定的知识技术储备，如果没有知识和技术，就没法去写好一篇好的博客，在这个原因的驱动下，我们会去学更多的东西，来丰富自己的知识面。 和别人一同分享交流相信很多学生（包括我）在学程序的时候，遇到技术难题的第一个反应就是上网找解决方案，但是我们会发现，很多都是源于CSDN或者是博客园上的博主，他们之所以会想那一篇文章，也是因为他们也遇到同样的问题，而他们把问题的解决方案通过博客分享给了其他人，相信他们的目的是同别人一同分享就交流，一起进步。 最后，分享一波鸡汤 人生的价值，即以其人对于当代所做的工作为尺度。——徐伟 人生最大的光荣，不在于永不失败，而在于能屡仆屡起。——拿破仑 坚强的信念能赢得强者的心，并使他们变得更加坚强。——白哲特 勿问成功的秘诀为何，且尽全力做你应该做的事吧。——美划钠 只有把抱怨环境的心情，化为上进的力量，才是成功的保证。——罗曼·罗兰","categories":[{"name":"日常","slug":"日常","permalink":"http://mjean.life/categories/%E6%97%A5%E5%B8%B8/"},{"name":"记录","slug":"日常/记录","permalink":"http://mjean.life/categories/%E6%97%A5%E5%B8%B8/%E8%AE%B0%E5%BD%95/"}],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2020-12-12T03:42:19.383Z","updated":"2022-04-18T12:48:45.669Z","comments":true,"path":"posts/4a17b156.html","link":"","permalink":"http://mjean.life/posts/4a17b156.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new \"My New Post\" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"笔记","slug":"笔记","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/"},{"name":"JUC","slug":"笔记/JUC","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/JUC/"},{"name":"jvm","slug":"笔记/jvm","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/jvm/"},{"name":"数据结构和算法","slug":"笔记/数据结构和算法","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"项目","slug":"项目","permalink":"http://mjean.life/categories/%E9%A1%B9%E7%9B%AE/"},{"name":"guli-college","slug":"项目/guli-college","permalink":"http://mjean.life/categories/%E9%A1%B9%E7%9B%AE/guli-college/"},{"name":"Nginx","slug":"笔记/Nginx","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Nginx/"},{"name":"Redis","slug":"笔记/Redis","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Redis/"},{"name":"SpringCloud","slug":"笔记/SpringCloud","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/SpringCloud/"},{"name":"Vue","slug":"笔记/Vue","permalink":"http://mjean.life/categories/%E7%AC%94%E8%AE%B0/Vue/"},{"name":"日常","slug":"日常","permalink":"http://mjean.life/categories/%E6%97%A5%E5%B8%B8/"},{"name":"记录","slug":"日常/记录","permalink":"http://mjean.life/categories/%E6%97%A5%E5%B8%B8/%E8%AE%B0%E5%BD%95/"}],"tags":[{"name":"JUC","slug":"JUC","permalink":"http://mjean.life/tags/JUC/"},{"name":"Java并发编程","slug":"Java并发编程","permalink":"http://mjean.life/tags/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"jvm","slug":"jvm","permalink":"http://mjean.life/tags/jvm/"},{"name":"java虚拟机","slug":"java虚拟机","permalink":"http://mjean.life/tags/java%E8%99%9A%E6%8B%9F%E6%9C%BA/"},{"name":"数据结构","slug":"数据结构","permalink":"http://mjean.life/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"算法","slug":"算法","permalink":"http://mjean.life/tags/%E7%AE%97%E6%B3%95/"},{"name":"项目总结","slug":"项目总结","permalink":"http://mjean.life/tags/%E9%A1%B9%E7%9B%AE%E6%80%BB%E7%BB%93/"},{"name":"Nginx","slug":"Nginx","permalink":"http://mjean.life/tags/Nginx/"},{"name":"Redis","slug":"Redis","permalink":"http://mjean.life/tags/Redis/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://mjean.life/tags/SpringCloud/"},{"name":"Vue","slug":"Vue","permalink":"http://mjean.life/tags/Vue/"}]}